{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "M8EnGFMvl6Wc",
        "outputId": "04e835f0-91ad-44c8-8d8a-70af191efc84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/cs229/mosei-data/mosei_senti_data.pkl\n",
            "/content/drive/MyDrive/cs229/CMU-MultimodalSDK-Tutorials\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/cs229/CMU-MultimodalSDK-Tutorials'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cs229/packages')\n",
        "\n",
        "data_file = \"/content/drive/MyDrive/cs229/mosei-data/mosei_senti_data.pkl\"\n",
        "%ls {data_file}\n",
        "\n",
        "model_dir = \"/content/drive/MyDrive/cs229/mosei-model\"\n",
        "%cd /content/drive/MyDrive/cs229/CMU-MultimodalSDK-Tutorials\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKxgQdVta8yz",
        "outputId": "b4a391bd-20b1-432a-e97b-2f51eb3893a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cmu_mosei_sdk_tutorial.ipynb  model.std    README.md\n",
            "constants\t\t      mosei-model  tutorial_interactive.ipynb\n",
            "data\t\t\t      optim.std\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W9tXRI8fncB3"
      },
      "outputs": [],
      "source": [
        "#import mmsdk\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "#from mmsdk import mmdatasdk as md\n",
        "from subprocess import check_call, CalledProcessError\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eDgQKhFQpnS9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MOSEIDataset(Dataset):\n",
        "    def __init__(self, data_split):\n",
        "        self.text = torch.tensor(data_split['text'], dtype=torch.float32)\n",
        "        self.audio = torch.tensor(data_split['audio'], dtype=torch.float32)\n",
        "        self.vision = torch.tensor(data_split['vision'], dtype=torch.float32)\n",
        "        self.labels = torch.tensor(data_split['labels'], dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'text': self.text[idx],\n",
        "            'audio': self.audio[idx],\n",
        "            'vision': self.vision[idx],\n",
        "            'label': self.labels[idx],\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3t2SVzZ-prdN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# load the pickle\n",
        "import pickle\n",
        "with open(data_file, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CDa8RLuyESXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18a5433-0883-41d3-bba5-c82de4e4caf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 16265, valid 1869, test 4643\n"
          ]
        }
      ],
      "source": [
        "train_set = MOSEIDataset(data['train'])\n",
        "valid_set = MOSEIDataset(data['valid'])\n",
        "test_set  = MOSEIDataset(data['test'])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=32)\n",
        "test_loader  = DataLoader(test_set, batch_size=32)\n",
        "\n",
        "print(f\"train {len(train_loader.dataset)}, valid {len(valid_loader.dataset)}, test {len(test_loader.dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wQ1MyyLgv2rv"
      },
      "outputs": [],
      "source": [
        "class MultiModal(nn.Module):\n",
        "  def __init__(self, input_dim, dim, nhead=8, nlayer=4):\n",
        "    super(MultiModal, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.dim = dim\n",
        "    self.nhead = nhead\n",
        "    self.nlayer = nlayer\n",
        "\n",
        "    self.input_proj = nn.Linear(input_dim, dim)\n",
        "    encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=self.nhead, batch_first=True)\n",
        "    self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=self.nlayer)\n",
        "    self.fc1 = nn.Linear(dim, 512)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "  def forward(self, text, audio, vision):\n",
        "    text[torch.isinf(text)] = 0.0\n",
        "    audio[torch.isinf(audio)] = 0.0\n",
        "    vision[torch.isinf(vision)] = 0.0\n",
        "\n",
        "    x_concat = torch.cat((text, audio, vision), dim=2)\n",
        "\n",
        "    if torch.isinf(x_concat).any():\n",
        "      inf_indices = torch.nonzero(torch.isinf(x_concat), as_tuple=False)\n",
        "      print(f\"infinities {inf_indices}\")\n",
        "      print(x_concat[inf_indices[0], inf_indices[1], :])\n",
        "\n",
        "    x_proj = self.input_proj(x_concat)\n",
        "    #print(f\"x_proj = {x_proj[2:4, 2:5, 5:8]}\")\n",
        "    encoder_output = self.encoder(x_proj)\n",
        "\n",
        "    #print(f\"encoder output {encoder_output[2:4, 2:5, 5:8]}\")\n",
        "    seq_mean = encoder_output.mean(dim=1)\n",
        "    #print(f\"seq mean {seq_mean.shape} {seq_mean[2:4, 5:8]}\")\n",
        "\n",
        "    pred = self.fc1(seq_mean)\n",
        "    pred = torch.relu(pred)\n",
        "    pred = self.dropout(pred)\n",
        "    pred = self.fc2(pred)\n",
        "    #print(f\"final pred ==== {pred[2:4, :].squeeze()}\")\n",
        "\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvcdXD8KrKCS",
        "outputId": "b21af78c-586b-445c-f648-5a7b30291dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, batch 10\n",
            "loss = 1.1659321784973145, avg loss = 1.2700236678123473\n",
            "epoch 0, batch 20\n",
            "loss = 1.891169548034668, avg loss = 1.3156824171543122\n",
            "epoch 0, batch 30\n",
            "loss = 0.9379133582115173, avg loss = 1.3066065589586893\n",
            "epoch 0, batch 40\n",
            "loss = 1.2557971477508545, avg loss = 1.2979706376791\n",
            "epoch 0, batch 50\n",
            "loss = 1.2434903383255005, avg loss = 1.2853982770442962\n",
            "epoch 0, batch 60\n",
            "loss = 0.7189827561378479, avg loss = 1.2825924187898636\n",
            "epoch 0, batch 70\n",
            "loss = 1.2519173622131348, avg loss = 1.2775922613484518\n",
            "epoch 0, batch 80\n",
            "loss = 1.3675386905670166, avg loss = 1.288374599069357\n",
            "epoch 0, batch 90\n",
            "loss = 1.4540151357650757, avg loss = 1.2853212104903327\n",
            "epoch 0, batch 100\n",
            "loss = 1.3032591342926025, avg loss = 1.2805800974369048\n",
            "epoch 0, batch 110\n",
            "loss = 1.2223310470581055, avg loss = 1.280404880913821\n",
            "epoch 0, batch 120\n",
            "loss = 0.826167106628418, avg loss = 1.2790079598625501\n",
            "epoch 0, batch 130\n",
            "loss = 0.8383549451828003, avg loss = 1.2753815352916718\n",
            "epoch 0, batch 140\n",
            "loss = 0.7235741019248962, avg loss = 1.2725820890494755\n",
            "epoch 0, batch 150\n",
            "loss = 1.8101364374160767, avg loss = 1.2808577795823415\n",
            "epoch 0, batch 160\n",
            "loss = 0.5696145296096802, avg loss = 1.2783448174595833\n",
            "epoch 0, batch 170\n",
            "loss = 1.875885009765625, avg loss = 1.277616932111628\n",
            "epoch 0, batch 180\n",
            "loss = 1.0989298820495605, avg loss = 1.2765001664559046\n",
            "epoch 0, batch 190\n",
            "loss = 1.5778348445892334, avg loss = 1.2741082853392551\n",
            "epoch 0, batch 200\n",
            "loss = 0.9106993079185486, avg loss = 1.2657461097836495\n",
            "epoch 0, batch 210\n",
            "loss = 1.1687344312667847, avg loss = 1.2679047842820486\n",
            "epoch 0, batch 220\n",
            "loss = 1.3570221662521362, avg loss = 1.2716694709929552\n",
            "epoch 0, batch 230\n",
            "loss = 0.5883668661117554, avg loss = 1.2669810266598411\n",
            "epoch 0, batch 240\n",
            "loss = 2.0258569717407227, avg loss = 1.2647014165918031\n",
            "epoch 0, batch 250\n",
            "loss = 1.3248273134231567, avg loss = 1.2710993316173553\n",
            "epoch 0, batch 260\n",
            "loss = 1.5455262660980225, avg loss = 1.2720678730652883\n",
            "epoch 0, batch 270\n",
            "loss = 1.288964033126831, avg loss = 1.2726863717591321\n",
            "epoch 0, batch 280\n",
            "loss = 1.2694664001464844, avg loss = 1.2719592107193811\n",
            "epoch 0, batch 290\n",
            "loss = 1.738692045211792, avg loss = 1.2731304927118894\n",
            "epoch 0, batch 300\n",
            "loss = 1.307420253753662, avg loss = 1.2751570016145706\n",
            "epoch 0, batch 310\n",
            "loss = 1.5715352296829224, avg loss = 1.2736846495059229\n",
            "epoch 0, batch 320\n",
            "loss = 1.744621992111206, avg loss = 1.2670411368831993\n",
            "epoch 0, batch 330\n",
            "loss = 1.1896946430206299, avg loss = 1.2645758704705672\n",
            "epoch 0, batch 340\n",
            "loss = 0.9606761932373047, avg loss = 1.2618585958200343\n",
            "epoch 0, batch 350\n",
            "loss = 1.4295381307601929, avg loss = 1.2608376216888428\n",
            "epoch 0, batch 360\n",
            "loss = 1.5940823554992676, avg loss = 1.2640081617567274\n",
            "epoch 0, batch 370\n",
            "loss = 0.8799352645874023, avg loss = 1.2606962595437023\n",
            "epoch 0, batch 380\n",
            "loss = 0.8303647041320801, avg loss = 1.2592001469511735\n",
            "epoch 0, batch 390\n",
            "loss = 1.2592191696166992, avg loss = 1.2581346655503298\n",
            "epoch 0, batch 400\n",
            "loss = 1.0638785362243652, avg loss = 1.255262241512537\n",
            "epoch 0, batch 410\n",
            "loss = 1.3562986850738525, avg loss = 1.2538206831711094\n",
            "epoch 0, batch 420\n",
            "loss = 1.1353375911712646, avg loss = 1.253760719583148\n",
            "epoch 0, batch 430\n",
            "loss = 0.9173469543457031, avg loss = 1.2523595193097758\n",
            "epoch 0, batch 440\n",
            "loss = 1.40923273563385, avg loss = 1.2498489264737476\n",
            "epoch 0, batch 450\n",
            "loss = 1.1061551570892334, avg loss = 1.24929802775383\n",
            "epoch 0, batch 460\n",
            "loss = 0.9690641760826111, avg loss = 1.2494774719943171\n",
            "epoch 0, batch 470\n",
            "loss = 1.0339043140411377, avg loss = 1.2508626093255713\n",
            "epoch 0, batch 480\n",
            "loss = 1.797534465789795, avg loss = 1.2496108720699945\n",
            "epoch 0, batch 490\n",
            "loss = 0.9811427593231201, avg loss = 1.2476223622049605\n",
            "epoch 0, batch 500\n",
            "loss = 1.0917742252349854, avg loss = 1.2442523996829986\n",
            "epoch 1, batch 510\n",
            "loss = 0.6506595611572266, avg loss = 1.2482952181030722\n",
            "epoch 1, batch 520\n",
            "loss = 0.9194048643112183, avg loss = 1.2483621874680886\n",
            "epoch 1, batch 530\n",
            "loss = 0.8820860385894775, avg loss = 1.245263745312421\n",
            "epoch 1, batch 540\n",
            "loss = 1.0300838947296143, avg loss = 1.2423439510442593\n",
            "epoch 1, batch 550\n",
            "loss = 1.0103319883346558, avg loss = 1.2409615927392785\n",
            "epoch 1, batch 560\n",
            "loss = 0.7386540174484253, avg loss = 1.2370077770735537\n",
            "epoch 1, batch 570\n",
            "loss = 1.1811003684997559, avg loss = 1.2374433062578503\n",
            "epoch 1, batch 580\n",
            "loss = 1.3268131017684937, avg loss = 1.2400251995900582\n",
            "epoch 1, batch 590\n",
            "loss = 1.4388997554779053, avg loss = 1.2410607018713224\n",
            "epoch 1, batch 600\n",
            "loss = 1.5284210443496704, avg loss = 1.2394035424788792\n",
            "epoch 1, batch 610\n",
            "loss = 1.5528615713119507, avg loss = 1.2406526835238347\n",
            "epoch 1, batch 620\n",
            "loss = 1.166652798652649, avg loss = 1.2386274751155608\n",
            "epoch 1, batch 630\n",
            "loss = 1.000319004058838, avg loss = 1.2387141835121882\n",
            "epoch 1, batch 640\n",
            "loss = 0.5773668885231018, avg loss = 1.2387767593376338\n",
            "epoch 1, batch 650\n",
            "loss = 1.2783372402191162, avg loss = 1.2375303827799284\n",
            "epoch 1, batch 660\n",
            "loss = 0.6347822546958923, avg loss = 1.2319593462077054\n",
            "epoch 1, batch 670\n",
            "loss = 1.7771973609924316, avg loss = 1.2313296475517217\n",
            "epoch 1, batch 680\n",
            "loss = 1.0737152099609375, avg loss = 1.2292532079360063\n",
            "epoch 1, batch 690\n",
            "loss = 1.0397905111312866, avg loss = 1.2292380713034368\n",
            "epoch 1, batch 700\n",
            "loss = 0.7405135631561279, avg loss = 1.226420349223273\n",
            "epoch 1, batch 710\n",
            "loss = 0.49146610498428345, avg loss = 1.2250853966659223\n",
            "epoch 1, batch 720\n",
            "loss = 1.0492178201675415, avg loss = 1.2223373185429307\n",
            "epoch 1, batch 730\n",
            "loss = 1.1547257900238037, avg loss = 1.2189408856711976\n",
            "epoch 1, batch 740\n",
            "loss = 0.9788312911987305, avg loss = 1.2165514114740732\n",
            "epoch 1, batch 750\n",
            "loss = 1.4657026529312134, avg loss = 1.2150072645346324\n",
            "epoch 1, batch 760\n",
            "loss = 0.6891183853149414, avg loss = 1.2116550466731975\n",
            "epoch 1, batch 770\n",
            "loss = 0.9132053852081299, avg loss = 1.209933524859416\n",
            "epoch 1, batch 780\n",
            "loss = 0.954132080078125, avg loss = 1.208761152319419\n",
            "epoch 1, batch 790\n",
            "loss = 1.0965511798858643, avg loss = 1.20654934093922\n",
            "epoch 1, batch 800\n",
            "loss = 1.2827047109603882, avg loss = 1.2042682192474603\n",
            "epoch 1, batch 810\n",
            "loss = 1.1114639043807983, avg loss = 1.2021229827845539\n",
            "epoch 1, batch 820\n",
            "loss = 1.3666656017303467, avg loss = 1.20150485932827\n",
            "epoch 1, batch 830\n",
            "loss = 0.840571939945221, avg loss = 1.197118496176708\n",
            "epoch 1, batch 840\n",
            "loss = 1.1264158487319946, avg loss = 1.1947079962917737\n",
            "epoch 1, batch 850\n",
            "loss = 0.9236372113227844, avg loss = 1.1903804957165438\n",
            "epoch 1, batch 860\n",
            "loss = 1.3701746463775635, avg loss = 1.1913454343413197\n",
            "epoch 1, batch 870\n",
            "loss = 1.2171982526779175, avg loss = 1.1894498702438399\n",
            "epoch 1, batch 880\n",
            "loss = 1.5510573387145996, avg loss = 1.1890814831988379\n",
            "epoch 1, batch 890\n",
            "loss = 1.1802421808242798, avg loss = 1.188398415118121\n",
            "epoch 1, batch 900\n",
            "loss = 1.2661325931549072, avg loss = 1.1872537574503157\n",
            "epoch 1, batch 910\n",
            "loss = 1.436572790145874, avg loss = 1.184742690016935\n",
            "epoch 1, batch 920\n",
            "loss = 1.0175895690917969, avg loss = 1.1831396276860133\n",
            "epoch 1, batch 930\n",
            "loss = 1.6386895179748535, avg loss = 1.1838706342443344\n",
            "epoch 1, batch 940\n",
            "loss = 0.9595195651054382, avg loss = 1.182639067826119\n",
            "epoch 1, batch 950\n",
            "loss = 0.9580590724945068, avg loss = 1.1833473778712122\n",
            "epoch 1, batch 960\n",
            "loss = 1.25938081741333, avg loss = 1.1834463235922157\n",
            "epoch 1, batch 970\n",
            "loss = 1.5391387939453125, avg loss = 1.1814783976557328\n",
            "epoch 1, batch 980\n",
            "loss = 1.0320987701416016, avg loss = 1.1793444425171735\n",
            "epoch 1, batch 990\n",
            "loss = 1.2622654438018799, avg loss = 1.1769181299390215\n",
            "epoch 1, batch 1000\n",
            "loss = 0.7955765724182129, avg loss = 1.1749326422512532\n",
            "epoch 1, batch 1010\n",
            "loss = 1.5554977655410767, avg loss = 1.1765844380796546\n",
            "epoch 2, batch 1020\n",
            "loss = 0.7632350921630859, avg loss = 1.1753294428481775\n",
            "epoch 2, batch 1030\n",
            "loss = 0.883952796459198, avg loss = 1.1735203252544681\n",
            "epoch 2, batch 1040\n",
            "loss = 1.7402502298355103, avg loss = 1.1725847723678902\n",
            "epoch 2, batch 1050\n",
            "loss = 0.757280170917511, avg loss = 1.171439291437467\n",
            "epoch 2, batch 1060\n",
            "loss = 1.0282502174377441, avg loss = 1.1702983457805975\n",
            "epoch 2, batch 1070\n",
            "loss = 1.1130726337432861, avg loss = 1.1670449634857267\n",
            "epoch 2, batch 1080\n",
            "loss = 1.0827839374542236, avg loss = 1.1659442168970904\n",
            "epoch 2, batch 1090\n",
            "loss = 0.9684607982635498, avg loss = 1.1650339030617967\n",
            "epoch 2, batch 1100\n",
            "loss = 0.742716908454895, avg loss = 1.1626242244514553\n",
            "epoch 2, batch 1110\n",
            "loss = 0.8624748587608337, avg loss = 1.1619921005792446\n",
            "epoch 2, batch 1120\n",
            "loss = 0.48322057723999023, avg loss = 1.1602238575528776\n",
            "epoch 2, batch 1130\n",
            "loss = 1.4834859371185303, avg loss = 1.159236106592997\n",
            "epoch 2, batch 1140\n",
            "loss = 1.504091739654541, avg loss = 1.1593901082350497\n",
            "epoch 2, batch 1150\n",
            "loss = 0.8000360727310181, avg loss = 1.1592547215326972\n",
            "epoch 2, batch 1160\n",
            "loss = 1.1409697532653809, avg loss = 1.1582051905321664\n",
            "epoch 2, batch 1170\n",
            "loss = 0.814791202545166, avg loss = 1.15784995670502\n",
            "epoch 2, batch 1180\n",
            "loss = 1.1379588842391968, avg loss = 1.15581130943561\n",
            "epoch 2, batch 1190\n",
            "loss = 0.6749756932258606, avg loss = 1.153949204487961\n",
            "epoch 2, batch 1200\n",
            "loss = 1.7804101705551147, avg loss = 1.1534526357303063\n",
            "epoch 2, batch 1210\n",
            "loss = 1.0063626766204834, avg loss = 1.1532949909937282\n",
            "epoch 2, batch 1220\n",
            "loss = 1.1020712852478027, avg loss = 1.1522062440143257\n",
            "epoch 2, batch 1230\n",
            "loss = 0.6357485055923462, avg loss = 1.1496898319420776\n",
            "epoch 2, batch 1240\n",
            "loss = 0.81150221824646, avg loss = 1.147423351604131\n",
            "epoch 2, batch 1250\n",
            "loss = 0.8029491901397705, avg loss = 1.1461922307252883\n",
            "epoch 2, batch 1260\n",
            "loss = 1.1932549476623535, avg loss = 1.144831928468886\n",
            "epoch 2, batch 1270\n",
            "loss = 1.0259240865707397, avg loss = 1.143161487954808\n",
            "epoch 2, batch 1280\n",
            "loss = 0.9479889869689941, avg loss = 1.1414673401974142\n",
            "epoch 2, batch 1290\n",
            "loss = 1.1562604904174805, avg loss = 1.1406623886537182\n",
            "epoch 2, batch 1300\n",
            "loss = 2.0671966075897217, avg loss = 1.141856037240762\n",
            "epoch 2, batch 1310\n",
            "loss = 0.8619116544723511, avg loss = 1.1416488538261589\n",
            "epoch 2, batch 1320\n",
            "loss = 0.5298004150390625, avg loss = 1.1402189580102762\n",
            "epoch 2, batch 1330\n",
            "loss = 1.0122779607772827, avg loss = 1.1394093737790458\n",
            "epoch 2, batch 1340\n",
            "loss = 1.3006032705307007, avg loss = 1.1380032473758086\n",
            "epoch 2, batch 1350\n",
            "loss = 0.7265515327453613, avg loss = 1.136762259161031\n",
            "epoch 2, batch 1360\n",
            "loss = 0.947810173034668, avg loss = 1.1352517375832094\n",
            "epoch 2, batch 1370\n",
            "loss = 1.631633996963501, avg loss = 1.1348384503683036\n",
            "epoch 2, batch 1380\n",
            "loss = 0.7421289682388306, avg loss = 1.1346073632438978\n",
            "epoch 2, batch 1390\n",
            "loss = 1.1399965286254883, avg loss = 1.132929178943737\n",
            "epoch 2, batch 1400\n",
            "loss = 0.6363208293914795, avg loss = 1.131061151857887\n",
            "epoch 2, batch 1410\n",
            "loss = 0.6613184809684753, avg loss = 1.130423519903041\n",
            "epoch 2, batch 1420\n",
            "loss = 0.817346453666687, avg loss = 1.1291323785840626\n",
            "epoch 2, batch 1430\n",
            "loss = 0.6574838161468506, avg loss = 1.1272433421203307\n",
            "epoch 2, batch 1440\n",
            "loss = 1.304686427116394, avg loss = 1.1265667012789182\n",
            "epoch 2, batch 1450\n",
            "loss = 0.5614325404167175, avg loss = 1.12516479995744\n",
            "epoch 2, batch 1460\n",
            "loss = 0.5163803696632385, avg loss = 1.124669866100566\n",
            "epoch 2, batch 1470\n",
            "loss = 0.9301265478134155, avg loss = 1.1229739841352515\n",
            "epoch 2, batch 1480\n",
            "loss = 1.0869618654251099, avg loss = 1.1207073027016343\n",
            "epoch 2, batch 1490\n",
            "loss = 1.0542030334472656, avg loss = 1.1201192248387626\n",
            "epoch 2, batch 1500\n",
            "loss = 0.4726428687572479, avg loss = 1.118802172899246\n",
            "epoch 2, batch 1510\n",
            "loss = 1.549081563949585, avg loss = 1.1176030717938152\n",
            "epoch 2, batch 1520\n",
            "loss = 0.9790787100791931, avg loss = 1.1170000454705014\n",
            "epoch 3, batch 1530\n",
            "loss = 1.0352394580841064, avg loss = 1.115481493441887\n",
            "epoch 3, batch 1540\n",
            "loss = 1.0898715257644653, avg loss = 1.1135431616337268\n",
            "epoch 3, batch 1550\n",
            "loss = 0.930483341217041, avg loss = 1.1128768112198\n",
            "epoch 3, batch 1560\n",
            "loss = 0.9843883514404297, avg loss = 1.111077586733378\n",
            "epoch 3, batch 1570\n",
            "loss = 0.6084475517272949, avg loss = 1.1093932994232056\n",
            "epoch 3, batch 1580\n",
            "loss = 0.8189107179641724, avg loss = 1.1073189766346654\n",
            "epoch 3, batch 1590\n",
            "loss = 0.8942286968231201, avg loss = 1.1070209260631658\n",
            "epoch 3, batch 1600\n",
            "loss = 0.8955309391021729, avg loss = 1.1053534059226513\n",
            "epoch 3, batch 1610\n",
            "loss = 0.9753075838088989, avg loss = 1.1044549396319419\n",
            "epoch 3, batch 1620\n",
            "loss = 0.9931355714797974, avg loss = 1.1023087612272782\n",
            "epoch 3, batch 1630\n",
            "loss = 0.6621319651603699, avg loss = 1.1014554043854672\n",
            "epoch 3, batch 1640\n",
            "loss = 0.6048169136047363, avg loss = 1.0997828542822745\n",
            "epoch 3, batch 1650\n",
            "loss = 0.8147981762886047, avg loss = 1.098568071343682\n",
            "epoch 3, batch 1660\n",
            "loss = 0.6361508369445801, avg loss = 1.0969914729336658\n",
            "epoch 3, batch 1670\n",
            "loss = 1.286245584487915, avg loss = 1.0957979536698963\n",
            "epoch 3, batch 1680\n",
            "loss = 1.1485049724578857, avg loss = 1.0952342656041896\n",
            "epoch 3, batch 1690\n",
            "loss = 1.2398030757904053, avg loss = 1.094560627612842\n",
            "epoch 3, batch 1700\n",
            "loss = 1.1660549640655518, avg loss = 1.0945450586080552\n",
            "epoch 3, batch 1710\n",
            "loss = 1.0948833227157593, avg loss = 1.0937726028481423\n",
            "epoch 3, batch 1720\n",
            "loss = 1.4261966943740845, avg loss = 1.0939209817453872\n",
            "epoch 3, batch 1730\n",
            "loss = 0.6257132291793823, avg loss = 1.091600797389973\n",
            "epoch 3, batch 1740\n",
            "loss = 1.3794708251953125, avg loss = 1.0911969471251828\n",
            "epoch 3, batch 1750\n",
            "loss = 0.9609869718551636, avg loss = 1.0910694039208548\n",
            "epoch 3, batch 1760\n",
            "loss = 0.9543333649635315, avg loss = 1.090366776558486\n",
            "epoch 3, batch 1770\n",
            "loss = 0.9348063468933105, avg loss = 1.0892873762354338\n",
            "epoch 3, batch 1780\n",
            "loss = 0.9666732549667358, avg loss = 1.0886246730437439\n",
            "epoch 3, batch 1790\n",
            "loss = 0.7039463520050049, avg loss = 1.0872042002291653\n",
            "epoch 3, batch 1800\n",
            "loss = 0.7218970060348511, avg loss = 1.0853580979175037\n",
            "epoch 3, batch 1810\n",
            "loss = 1.043055772781372, avg loss = 1.0838209788443633\n",
            "epoch 3, batch 1820\n",
            "loss = 0.6667932271957397, avg loss = 1.0830485259111111\n",
            "epoch 3, batch 1830\n",
            "loss = 1.0435364246368408, avg loss = 1.0828676290525114\n",
            "epoch 3, batch 1840\n",
            "loss = 1.0317599773406982, avg loss = 1.0830050747031752\n",
            "epoch 3, batch 1850\n",
            "loss = 0.6942495703697205, avg loss = 1.0818374431455458\n",
            "epoch 3, batch 1860\n",
            "loss = 0.5986871719360352, avg loss = 1.0808852286428534\n",
            "epoch 3, batch 1870\n",
            "loss = 0.7085360288619995, avg loss = 1.0797373650227\n",
            "epoch 3, batch 1880\n",
            "loss = 1.3591793775558472, avg loss = 1.079242081781651\n",
            "epoch 3, batch 1890\n",
            "loss = 0.7088569402694702, avg loss = 1.0781169896403318\n",
            "epoch 3, batch 1900\n",
            "loss = 1.209244728088379, avg loss = 1.0773202706010718\n",
            "epoch 3, batch 1910\n",
            "loss = 1.197411060333252, avg loss = 1.076129166992547\n",
            "epoch 3, batch 1920\n",
            "loss = 0.9395343065261841, avg loss = 1.0755190207312504\n",
            "epoch 3, batch 1930\n",
            "loss = 0.9607204794883728, avg loss = 1.0754512108051715\n",
            "epoch 3, batch 1940\n",
            "loss = 1.1554701328277588, avg loss = 1.0744067980149357\n",
            "epoch 3, batch 1950\n",
            "loss = 0.6822348833084106, avg loss = 1.074221077209864\n",
            "epoch 3, batch 1960\n",
            "loss = 1.0268070697784424, avg loss = 1.0731187079633986\n",
            "epoch 3, batch 1970\n",
            "loss = 1.0415881872177124, avg loss = 1.0714024315630724\n",
            "epoch 3, batch 1980\n",
            "loss = 0.7556298971176147, avg loss = 1.0702214702813313\n",
            "epoch 3, batch 1990\n",
            "loss = 0.6955047249794006, avg loss = 1.0688627834296107\n",
            "epoch 3, batch 2000\n",
            "loss = 0.8591146469116211, avg loss = 1.0679081202745437\n",
            "epoch 3, batch 2010\n",
            "loss = 0.7445981502532959, avg loss = 1.0661614331736493\n",
            "epoch 3, batch 2020\n",
            "loss = 0.5805380344390869, avg loss = 1.0652840887851054\n",
            "epoch 3, batch 2030\n",
            "loss = 0.7116712927818298, avg loss = 1.0641357040463997\n",
            "epoch 4, batch 2040\n",
            "loss = 1.3916828632354736, avg loss = 1.0644846597138573\n",
            "epoch 4, batch 2050\n",
            "loss = 1.3776776790618896, avg loss = 1.064075050819211\n",
            "epoch 4, batch 2060\n",
            "loss = 0.5986554622650146, avg loss = 1.063242982805354\n",
            "epoch 4, batch 2070\n",
            "loss = 0.8474317789077759, avg loss = 1.0626944529261566\n",
            "epoch 4, batch 2080\n",
            "loss = 0.982903778553009, avg loss = 1.0615026795663514\n",
            "epoch 4, batch 2090\n",
            "loss = 0.8959845900535583, avg loss = 1.0603221413193706\n",
            "epoch 4, batch 2100\n",
            "loss = 0.7954057455062866, avg loss = 1.0592854664864995\n",
            "epoch 4, batch 2110\n",
            "loss = 1.3529233932495117, avg loss = 1.0586663213810084\n",
            "epoch 4, batch 2120\n",
            "loss = 1.1353733539581299, avg loss = 1.0574790818370738\n",
            "epoch 4, batch 2130\n",
            "loss = 1.3833978176116943, avg loss = 1.056669297310668\n",
            "epoch 4, batch 2140\n",
            "loss = 0.5683947801589966, avg loss = 1.056435397114152\n",
            "epoch 4, batch 2150\n",
            "loss = 0.6614248752593994, avg loss = 1.0551577466864919\n",
            "epoch 4, batch 2160\n",
            "loss = 0.5519300699234009, avg loss = 1.0541619529878652\n",
            "epoch 4, batch 2170\n",
            "loss = 0.8083648681640625, avg loss = 1.0523483806766123\n",
            "epoch 4, batch 2180\n",
            "loss = 0.8445539474487305, avg loss = 1.0516365339723202\n",
            "epoch 4, batch 2190\n",
            "loss = 0.8323070406913757, avg loss = 1.0513306336043633\n",
            "epoch 4, batch 2200\n",
            "loss = 1.0861878395080566, avg loss = 1.0505158986286685\n",
            "epoch 4, batch 2210\n",
            "loss = 1.0042799711227417, avg loss = 1.0497215327364287\n",
            "epoch 4, batch 2220\n",
            "loss = 0.7267816066741943, avg loss = 1.048539818031294\n",
            "epoch 4, batch 2230\n",
            "loss = 0.6301645040512085, avg loss = 1.0472834134850266\n",
            "epoch 4, batch 2240\n",
            "loss = 0.7188185453414917, avg loss = 1.046286784538201\n",
            "epoch 4, batch 2250\n",
            "loss = 0.7765648365020752, avg loss = 1.0457651890118917\n",
            "epoch 4, batch 2260\n",
            "loss = 0.3816402554512024, avg loss = 1.044700247524059\n",
            "epoch 4, batch 2270\n",
            "loss = 0.8647366762161255, avg loss = 1.0440826739246098\n",
            "epoch 4, batch 2280\n",
            "loss = 1.0146288871765137, avg loss = 1.0432178176024505\n",
            "epoch 4, batch 2290\n",
            "loss = 0.8317751288414001, avg loss = 1.042211054701472\n",
            "epoch 4, batch 2300\n",
            "loss = 0.9579266905784607, avg loss = 1.0417176522768061\n",
            "epoch 4, batch 2310\n",
            "loss = 0.6912885904312134, avg loss = 1.0408355050917828\n",
            "epoch 4, batch 2320\n",
            "loss = 0.8535037040710449, avg loss = 1.0399056079315727\n",
            "epoch 4, batch 2330\n",
            "loss = 1.2681894302368164, avg loss = 1.0394189181757587\n",
            "epoch 4, batch 2340\n",
            "loss = 1.7927100658416748, avg loss = 1.0389312020097023\n",
            "epoch 4, batch 2350\n",
            "loss = 0.7917205095291138, avg loss = 1.0386002285302953\n",
            "epoch 4, batch 2360\n",
            "loss = 0.4848446846008301, avg loss = 1.0373178921134796\n",
            "epoch 4, batch 2370\n",
            "loss = 0.7761053442955017, avg loss = 1.0366655962502402\n",
            "epoch 4, batch 2380\n",
            "loss = 0.8119940757751465, avg loss = 1.0359100049408545\n",
            "epoch 4, batch 2390\n",
            "loss = 0.9083192944526672, avg loss = 1.035296536601737\n",
            "epoch 4, batch 2400\n",
            "loss = 0.8178079128265381, avg loss = 1.0342458574349682\n",
            "epoch 4, batch 2410\n",
            "loss = 0.6686187982559204, avg loss = 1.0331275796618204\n",
            "epoch 4, batch 2420\n",
            "loss = 1.0201584100723267, avg loss = 1.032659462402182\n",
            "epoch 4, batch 2430\n",
            "loss = 0.6092582941055298, avg loss = 1.0319984809729297\n",
            "epoch 4, batch 2440\n",
            "loss = 0.7811905741691589, avg loss = 1.030934506593669\n",
            "epoch 4, batch 2450\n",
            "loss = 0.962167501449585, avg loss = 1.0298842141944535\n",
            "epoch 4, batch 2460\n",
            "loss = 0.6982407569885254, avg loss = 1.029552497938881\n",
            "epoch 4, batch 2470\n",
            "loss = 1.2556157112121582, avg loss = 1.0289797582003752\n",
            "epoch 4, batch 2480\n",
            "loss = 1.1269254684448242, avg loss = 1.0282695836718043\n",
            "epoch 4, batch 2490\n",
            "loss = 0.7100433707237244, avg loss = 1.027151707544863\n",
            "epoch 4, batch 2500\n",
            "loss = 0.6106952428817749, avg loss = 1.0266281248092652\n",
            "epoch 4, batch 2510\n",
            "loss = 0.8756517171859741, avg loss = 1.0263549347797714\n",
            "epoch 4, batch 2520\n",
            "loss = 0.9184622764587402, avg loss = 1.0254135956603383\n",
            "epoch 4, batch 2530\n",
            "loss = 0.9272814989089966, avg loss = 1.0250965059745925\n",
            "epoch 4, batch 2540\n",
            "loss = 1.0481297969818115, avg loss = 1.0246342084421887\n",
            "epoch 5, batch 2550\n",
            "loss = 1.5968804359436035, avg loss = 1.0243435648492738\n",
            "epoch 5, batch 2560\n",
            "loss = 0.72053062915802, avg loss = 1.023523877945263\n",
            "epoch 5, batch 2570\n",
            "loss = 1.0078682899475098, avg loss = 1.0232419733523395\n",
            "epoch 5, batch 2580\n",
            "loss = 1.0538861751556396, avg loss = 1.0231597776791845\n",
            "epoch 5, batch 2590\n",
            "loss = 1.1054503917694092, avg loss = 1.0226825776937845\n",
            "epoch 5, batch 2600\n",
            "loss = 1.0946440696716309, avg loss = 1.0222949117651352\n",
            "epoch 5, batch 2610\n",
            "loss = 0.7006176710128784, avg loss = 1.0212288075708338\n",
            "epoch 5, batch 2620\n",
            "loss = 0.7191737294197083, avg loss = 1.020479803799673\n",
            "epoch 5, batch 2630\n",
            "loss = 0.8318213224411011, avg loss = 1.020187885679673\n",
            "epoch 5, batch 2640\n",
            "loss = 1.3998979330062866, avg loss = 1.0196740292351354\n",
            "epoch 5, batch 2650\n",
            "loss = 0.9332196712493896, avg loss = 1.018967794371101\n",
            "epoch 5, batch 2660\n",
            "loss = 0.9205189943313599, avg loss = 1.0181651037326434\n",
            "epoch 5, batch 2670\n",
            "loss = 0.7598262429237366, avg loss = 1.0180297986733333\n",
            "epoch 5, batch 2680\n",
            "loss = 0.8832986354827881, avg loss = 1.0170118099495546\n",
            "epoch 5, batch 2690\n",
            "loss = 1.0253596305847168, avg loss = 1.0168843648912296\n",
            "epoch 5, batch 2700\n",
            "loss = 0.7205194234848022, avg loss = 1.015997813421267\n",
            "epoch 5, batch 2710\n",
            "loss = 0.7693870067596436, avg loss = 1.0153778564995946\n",
            "epoch 5, batch 2720\n",
            "loss = 1.0943694114685059, avg loss = 1.0142473953721278\n",
            "epoch 5, batch 2730\n",
            "loss = 0.7476587295532227, avg loss = 1.013915118793428\n",
            "epoch 5, batch 2740\n",
            "loss = 0.6414180994033813, avg loss = 1.0129590433988258\n",
            "epoch 5, batch 2750\n",
            "loss = 0.8185719847679138, avg loss = 1.0121217994364826\n",
            "epoch 5, batch 2760\n",
            "loss = 0.9300210475921631, avg loss = 1.01187408098924\n",
            "epoch 5, batch 2770\n",
            "loss = 0.7205440998077393, avg loss = 1.0111632941969895\n",
            "epoch 5, batch 2780\n",
            "loss = 1.017878532409668, avg loss = 1.0110043550459602\n",
            "epoch 5, batch 2790\n",
            "loss = 0.7218347787857056, avg loss = 1.0102826948341075\n",
            "epoch 5, batch 2800\n",
            "loss = 1.2887941598892212, avg loss = 1.0097346920732941\n",
            "epoch 5, batch 2810\n",
            "loss = 0.5699363350868225, avg loss = 1.0087492634074968\n",
            "epoch 5, batch 2820\n",
            "loss = 0.9783509373664856, avg loss = 1.0081442506917826\n",
            "epoch 5, batch 2830\n",
            "loss = 1.7188310623168945, avg loss = 1.0080989784465662\n",
            "epoch 5, batch 2840\n",
            "loss = 0.9713507294654846, avg loss = 1.0077458540423656\n",
            "epoch 5, batch 2850\n",
            "loss = 0.8233486413955688, avg loss = 1.0067701471897594\n",
            "epoch 5, batch 2860\n",
            "loss = 1.0079929828643799, avg loss = 1.0060403474769393\n",
            "epoch 5, batch 2870\n",
            "loss = 0.9250186681747437, avg loss = 1.0051755666525106\n",
            "epoch 5, batch 2880\n",
            "loss = 0.6215584874153137, avg loss = 1.0043235714029934\n",
            "epoch 5, batch 2890\n",
            "loss = 1.2906585931777954, avg loss = 1.0038513574014485\n",
            "epoch 5, batch 2900\n",
            "loss = 0.8893024921417236, avg loss = 1.0032301712549967\n",
            "epoch 5, batch 2910\n",
            "loss = 0.9134981632232666, avg loss = 1.002328435088351\n",
            "epoch 5, batch 2920\n",
            "loss = 0.8552873134613037, avg loss = 1.0017511846676266\n",
            "epoch 5, batch 2930\n",
            "loss = 0.8544184565544128, avg loss = 1.0013191512623745\n",
            "epoch 5, batch 2940\n",
            "loss = 0.7274016737937927, avg loss = 1.0008140088952318\n",
            "epoch 5, batch 2950\n",
            "loss = 0.6373468637466431, avg loss = 1.0001191062038228\n",
            "epoch 5, batch 2960\n",
            "loss = 0.6477402448654175, avg loss = 0.9991807193470162\n",
            "epoch 5, batch 2970\n",
            "loss = 0.9188159704208374, avg loss = 0.9983159537969615\n",
            "epoch 5, batch 2980\n",
            "loss = 0.6929605007171631, avg loss = 0.9977317156107633\n",
            "epoch 5, batch 2990\n",
            "loss = 0.8193469643592834, avg loss = 0.996982079236005\n",
            "epoch 5, batch 3000\n",
            "loss = 1.3222943544387817, avg loss = 0.9967868728737036\n",
            "epoch 5, batch 3010\n",
            "loss = 0.6617311239242554, avg loss = 0.9959456217744421\n",
            "epoch 5, batch 3020\n",
            "loss = 0.5518561005592346, avg loss = 0.9949298291312938\n",
            "epoch 5, batch 3030\n",
            "loss = 0.7849879860877991, avg loss = 0.9941714746428795\n",
            "epoch 5, batch 3040\n",
            "loss = 0.5590510368347168, avg loss = 0.9932689171872641\n",
            "epoch 5, batch 3050\n",
            "loss = 0.9708422422409058, avg loss = 0.992397430070111\n",
            "epoch 6, batch 3060\n",
            "loss = 0.8689056634902954, avg loss = 0.9918910593281385\n",
            "epoch 6, batch 3070\n",
            "loss = 1.0184063911437988, avg loss = 0.9910020697776969\n",
            "epoch 6, batch 3080\n",
            "loss = 0.8787333965301514, avg loss = 0.9904593270320396\n",
            "epoch 6, batch 3090\n",
            "loss = 0.7956826686859131, avg loss = 0.989728337420229\n",
            "epoch 6, batch 3100\n",
            "loss = 0.6863322854042053, avg loss = 0.9890874108095323\n",
            "epoch 6, batch 3110\n",
            "loss = 0.8690623044967651, avg loss = 0.9887420044738764\n",
            "epoch 6, batch 3120\n",
            "loss = 1.053126573562622, avg loss = 0.9885751662441553\n",
            "epoch 6, batch 3130\n",
            "loss = 0.6908605694770813, avg loss = 0.9879362887943895\n",
            "epoch 6, batch 3140\n",
            "loss = 0.6394924521446228, avg loss = 0.9871678668507345\n",
            "epoch 6, batch 3150\n",
            "loss = 0.8552361726760864, avg loss = 0.9865416451011385\n",
            "epoch 6, batch 3160\n",
            "loss = 1.2208079099655151, avg loss = 0.9861912051899524\n",
            "epoch 6, batch 3170\n",
            "loss = 0.8373303413391113, avg loss = 0.9855062655469973\n",
            "epoch 6, batch 3180\n",
            "loss = 0.8577824831008911, avg loss = 0.9852331833644483\n",
            "epoch 6, batch 3190\n",
            "loss = 0.6262954473495483, avg loss = 0.984482495369956\n",
            "epoch 6, batch 3200\n",
            "loss = 0.7523815631866455, avg loss = 0.984183763563633\n",
            "epoch 6, batch 3210\n",
            "loss = 0.718920111656189, avg loss = 0.9833353035546537\n",
            "epoch 6, batch 3220\n",
            "loss = 1.1544957160949707, avg loss = 0.9827580284257853\n",
            "epoch 6, batch 3230\n",
            "loss = 1.2235093116760254, avg loss = 0.9824215086990097\n",
            "epoch 6, batch 3240\n",
            "loss = 1.0226439237594604, avg loss = 0.9823727881282935\n",
            "epoch 6, batch 3250\n",
            "loss = 0.8179873824119568, avg loss = 0.9816896091057704\n",
            "epoch 6, batch 3260\n",
            "loss = 0.679977297782898, avg loss = 0.9810215188133204\n",
            "epoch 6, batch 3270\n",
            "loss = 0.7514078617095947, avg loss = 0.9803982587035643\n",
            "epoch 6, batch 3280\n",
            "loss = 1.0694029331207275, avg loss = 0.980060778394705\n",
            "epoch 6, batch 3290\n",
            "loss = 0.9872226715087891, avg loss = 0.9798009932403506\n",
            "epoch 6, batch 3300\n",
            "loss = 0.643090009689331, avg loss = 0.9793292141141313\n",
            "epoch 6, batch 3310\n",
            "loss = 0.6296687722206116, avg loss = 0.9786701898650461\n",
            "epoch 6, batch 3320\n",
            "loss = 0.5370573997497559, avg loss = 0.9777741216392403\n",
            "epoch 6, batch 3330\n",
            "loss = 0.77455735206604, avg loss = 0.9771137305208155\n",
            "epoch 6, batch 3340\n",
            "loss = 1.1975780725479126, avg loss = 0.976788644983383\n",
            "epoch 6, batch 3350\n",
            "loss = 1.0246288776397705, avg loss = 0.9763216020100153\n",
            "epoch 6, batch 3360\n",
            "loss = 0.6498138308525085, avg loss = 0.9754478179450546\n",
            "epoch 6, batch 3370\n",
            "loss = 0.502807080745697, avg loss = 0.9746535884962592\n",
            "epoch 6, batch 3380\n",
            "loss = 0.8237271308898926, avg loss = 0.9742455157567058\n",
            "epoch 6, batch 3390\n",
            "loss = 1.449030876159668, avg loss = 0.9739789392656282\n",
            "epoch 6, batch 3400\n",
            "loss = 0.45387762784957886, avg loss = 0.9737970577881617\n",
            "epoch 6, batch 3410\n",
            "loss = 1.0129201412200928, avg loss = 0.9733015549060536\n",
            "epoch 6, batch 3420\n",
            "loss = 0.7792198657989502, avg loss = 0.972879185183355\n",
            "epoch 6, batch 3430\n",
            "loss = 0.617538332939148, avg loss = 0.9722238281464786\n",
            "epoch 6, batch 3440\n",
            "loss = 0.6665223240852356, avg loss = 0.971554524650754\n",
            "epoch 6, batch 3450\n",
            "loss = 0.7608575224876404, avg loss = 0.9712696603242902\n",
            "epoch 6, batch 3460\n",
            "loss = 1.0783823728561401, avg loss = 0.9708009418466188\n",
            "epoch 6, batch 3470\n",
            "loss = 0.7254405617713928, avg loss = 0.9704253942289682\n",
            "epoch 6, batch 3480\n",
            "loss = 0.8167897462844849, avg loss = 0.970039581610211\n",
            "epoch 6, batch 3490\n",
            "loss = 0.841792643070221, avg loss = 0.969361903836529\n",
            "epoch 6, batch 3500\n",
            "loss = 1.4318352937698364, avg loss = 0.9691034116234098\n",
            "epoch 6, batch 3510\n",
            "loss = 0.7289742231369019, avg loss = 0.9686151429373994\n",
            "epoch 6, batch 3520\n",
            "loss = 0.7004778385162354, avg loss = 0.9678972774862565\n",
            "epoch 6, batch 3530\n",
            "loss = 0.9287487268447876, avg loss = 0.9673175078360284\n",
            "epoch 6, batch 3540\n",
            "loss = 1.0863525867462158, avg loss = 0.967105518719234\n",
            "epoch 6, batch 3550\n",
            "loss = 0.850712239742279, avg loss = 0.9667160042154956\n",
            "epoch 6, batch 3560\n",
            "loss = 0.7254763245582581, avg loss = 0.9660762280979184\n",
            "epoch 7, batch 3570\n",
            "loss = 0.673885703086853, avg loss = 0.9660520340130777\n",
            "epoch 7, batch 3580\n",
            "loss = 0.7385455965995789, avg loss = 0.9655265618302968\n",
            "epoch 7, batch 3590\n",
            "loss = 0.9560994505882263, avg loss = 0.9651146970419499\n",
            "epoch 7, batch 3600\n",
            "loss = 0.797258198261261, avg loss = 0.96488855579661\n",
            "epoch 7, batch 3610\n",
            "loss = 0.7065732479095459, avg loss = 0.9643482218901537\n",
            "epoch 7, batch 3620\n",
            "loss = 1.0788073539733887, avg loss = 0.9641430733365248\n",
            "epoch 7, batch 3630\n",
            "loss = 1.1761873960494995, avg loss = 0.9635645899644568\n",
            "epoch 7, batch 3640\n",
            "loss = 0.6420342922210693, avg loss = 0.9630065461436471\n",
            "epoch 7, batch 3650\n",
            "loss = 0.4589790403842926, avg loss = 0.9624609771575013\n",
            "epoch 7, batch 3660\n",
            "loss = 0.567754328250885, avg loss = 0.9619468833009402\n",
            "epoch 7, batch 3670\n",
            "loss = 0.8688063621520996, avg loss = 0.9618834838636564\n",
            "epoch 7, batch 3680\n",
            "loss = 0.9135321378707886, avg loss = 0.9609695842246646\n",
            "epoch 7, batch 3690\n",
            "loss = 0.7245726585388184, avg loss = 0.9604814099264015\n",
            "epoch 7, batch 3700\n",
            "loss = 0.7684818506240845, avg loss = 0.9601043856627233\n",
            "epoch 7, batch 3710\n",
            "loss = 0.7329126596450806, avg loss = 0.9593223926433013\n",
            "epoch 7, batch 3720\n",
            "loss = 0.8774089217185974, avg loss = 0.9586683606909168\n",
            "epoch 7, batch 3730\n",
            "loss = 0.7984235882759094, avg loss = 0.9581765370458445\n",
            "epoch 7, batch 3740\n",
            "loss = 1.189558744430542, avg loss = 0.9578937455772716\n",
            "epoch 7, batch 3750\n",
            "loss = 0.6833101511001587, avg loss = 0.9570726474285126\n",
            "epoch 7, batch 3760\n",
            "loss = 0.922700047492981, avg loss = 0.9564906064658723\n",
            "epoch 7, batch 3770\n",
            "loss = 0.8986469507217407, avg loss = 0.9560180736710602\n",
            "epoch 7, batch 3780\n",
            "loss = 0.7899295091629028, avg loss = 0.9554724394802063\n",
            "epoch 7, batch 3790\n",
            "loss = 0.49484983086586, avg loss = 0.9550902348159171\n",
            "epoch 7, batch 3800\n",
            "loss = 0.4589402973651886, avg loss = 0.954842966842024\n",
            "epoch 7, batch 3810\n",
            "loss = 0.6598399877548218, avg loss = 0.9541412391140079\n",
            "epoch 7, batch 3820\n",
            "loss = 0.4949325919151306, avg loss = 0.9535293586981234\n",
            "epoch 7, batch 3830\n",
            "loss = 0.7281716465950012, avg loss = 0.9530009089811041\n",
            "epoch 7, batch 3840\n",
            "loss = 0.6340966820716858, avg loss = 0.9523754071909935\n",
            "epoch 7, batch 3850\n",
            "loss = 0.6107304096221924, avg loss = 0.9519066097519614\n",
            "epoch 7, batch 3860\n",
            "loss = 0.8103886842727661, avg loss = 0.9514301799585164\n",
            "epoch 7, batch 3870\n",
            "loss = 0.6529523134231567, avg loss = 0.9510013104178184\n",
            "epoch 7, batch 3880\n",
            "loss = 1.2327284812927246, avg loss = 0.9508374875276974\n",
            "epoch 7, batch 3890\n",
            "loss = 0.6093446612358093, avg loss = 0.9505732893867174\n",
            "epoch 7, batch 3900\n",
            "loss = 0.5610503554344177, avg loss = 0.9501654016589507\n",
            "epoch 7, batch 3910\n",
            "loss = 0.7862988710403442, avg loss = 0.9496522128963104\n",
            "epoch 7, batch 3920\n",
            "loss = 0.6368605494499207, avg loss = 0.9490911520029209\n",
            "epoch 7, batch 3930\n",
            "loss = 0.6695702075958252, avg loss = 0.9485277795382129\n",
            "epoch 7, batch 3940\n",
            "loss = 0.8172920346260071, avg loss = 0.9482410158829641\n",
            "epoch 7, batch 3950\n",
            "loss = 1.1903108358383179, avg loss = 0.9478728062518035\n",
            "epoch 7, batch 3960\n",
            "loss = 0.9609954357147217, avg loss = 0.9474284213675995\n",
            "epoch 7, batch 3970\n",
            "loss = 1.074946641921997, avg loss = 0.9472887349969494\n",
            "epoch 7, batch 3980\n",
            "loss = 0.6912594437599182, avg loss = 0.9467534184455871\n",
            "epoch 7, batch 3990\n",
            "loss = 0.9007227420806885, avg loss = 0.9461898099808466\n",
            "epoch 7, batch 4000\n",
            "loss = 0.7057590484619141, avg loss = 0.9461350092962384\n",
            "epoch 7, batch 4010\n",
            "loss = 0.5205738544464111, avg loss = 0.9457827255018334\n",
            "epoch 7, batch 4020\n",
            "loss = 1.46010160446167, avg loss = 0.9456829963928431\n",
            "epoch 7, batch 4030\n",
            "loss = 1.3943626880645752, avg loss = 0.9455789381162109\n",
            "epoch 7, batch 4040\n",
            "loss = 0.7999230027198792, avg loss = 0.9452570793504762\n",
            "epoch 7, batch 4050\n",
            "loss = 0.5222377777099609, avg loss = 0.944759687192646\n",
            "epoch 7, batch 4060\n",
            "loss = 0.49574851989746094, avg loss = 0.9441482391483678\n",
            "epoch 7, batch 4070\n",
            "loss = 1.1953271627426147, avg loss = 0.9439334905923731\n",
            "epoch 8, batch 4080\n",
            "loss = 0.7589902281761169, avg loss = 0.943634137401686\n",
            "epoch 8, batch 4090\n",
            "loss = 0.43677234649658203, avg loss = 0.9429484950082517\n",
            "epoch 8, batch 4100\n",
            "loss = 0.5560768246650696, avg loss = 0.9424384633142774\n",
            "epoch 8, batch 4110\n",
            "loss = 0.7993793487548828, avg loss = 0.9418666454634818\n",
            "epoch 8, batch 4120\n",
            "loss = 0.9166173934936523, avg loss = 0.9411592258267032\n",
            "epoch 8, batch 4130\n",
            "loss = 0.9073166847229004, avg loss = 0.9404356877538251\n",
            "epoch 8, batch 4140\n",
            "loss = 0.5822116136550903, avg loss = 0.940082178146079\n",
            "epoch 8, batch 4150\n",
            "loss = 0.7499312162399292, avg loss = 0.9396599113869379\n",
            "epoch 8, batch 4160\n",
            "loss = 0.6761668920516968, avg loss = 0.939311124678128\n",
            "epoch 8, batch 4170\n",
            "loss = 0.4982670545578003, avg loss = 0.9389148413062953\n",
            "epoch 8, batch 4180\n",
            "loss = 0.7462714910507202, avg loss = 0.9382717010221984\n",
            "epoch 8, batch 4190\n",
            "loss = 0.8157085180282593, avg loss = 0.9380693555447253\n",
            "epoch 8, batch 4200\n",
            "loss = 0.8942981958389282, avg loss = 0.9375111994714964\n",
            "epoch 8, batch 4210\n",
            "loss = 0.6099377870559692, avg loss = 0.9371842290330104\n",
            "epoch 8, batch 4220\n",
            "loss = 0.9978460073471069, avg loss = 0.9368573835110777\n",
            "epoch 8, batch 4230\n",
            "loss = 0.8286998867988586, avg loss = 0.9365184723908174\n",
            "epoch 8, batch 4240\n",
            "loss = 0.3484513759613037, avg loss = 0.9362633575105442\n",
            "epoch 8, batch 4250\n",
            "loss = 0.7075965404510498, avg loss = 0.9359833585374495\n",
            "epoch 8, batch 4260\n",
            "loss = 1.3013325929641724, avg loss = 0.9357884590474652\n",
            "epoch 8, batch 4270\n",
            "loss = 0.5962458848953247, avg loss = 0.9354556202120747\n",
            "epoch 8, batch 4280\n",
            "loss = 0.6058213114738464, avg loss = 0.9348451163654572\n",
            "epoch 8, batch 4290\n",
            "loss = 0.9753939509391785, avg loss = 0.9346463538966813\n",
            "epoch 8, batch 4300\n",
            "loss = 1.0382046699523926, avg loss = 0.9342340792750203\n",
            "epoch 8, batch 4310\n",
            "loss = 0.9223663806915283, avg loss = 0.9342282379586293\n",
            "epoch 8, batch 4320\n",
            "loss = 0.7889924049377441, avg loss = 0.9338869069323495\n",
            "epoch 8, batch 4330\n",
            "loss = 1.0030577182769775, avg loss = 0.933843312458959\n",
            "epoch 8, batch 4340\n",
            "loss = 1.0387029647827148, avg loss = 0.9335863076528097\n",
            "epoch 8, batch 4350\n",
            "loss = 0.7269949913024902, avg loss = 0.9331198172939235\n",
            "epoch 8, batch 4360\n",
            "loss = 0.6503679752349854, avg loss = 0.9327486852782035\n",
            "epoch 8, batch 4370\n",
            "loss = 0.44046375155448914, avg loss = 0.9320767477802608\n",
            "epoch 8, batch 4380\n",
            "loss = 0.7441798448562622, avg loss = 0.9314551574726627\n",
            "epoch 8, batch 4390\n",
            "loss = 0.6233168840408325, avg loss = 0.9308510412252031\n",
            "epoch 8, batch 4400\n",
            "loss = 0.5161690711975098, avg loss = 0.9304419529912147\n",
            "epoch 8, batch 4410\n",
            "loss = 0.5808303356170654, avg loss = 0.9299750547019803\n",
            "epoch 8, batch 4420\n",
            "loss = 0.5527992248535156, avg loss = 0.9297111156164791\n",
            "epoch 8, batch 4430\n",
            "loss = 0.5220610499382019, avg loss = 0.9294290962391459\n",
            "epoch 8, batch 4440\n",
            "loss = 1.186453104019165, avg loss = 0.9290421183984559\n",
            "epoch 8, batch 4450\n",
            "loss = 0.6778069138526917, avg loss = 0.9287659094574746\n",
            "epoch 8, batch 4460\n",
            "loss = 0.6740827560424805, avg loss = 0.9284272135640473\n",
            "epoch 8, batch 4470\n",
            "loss = 0.6647242307662964, avg loss = 0.9278184179091613\n",
            "epoch 8, batch 4480\n",
            "loss = 0.7634873390197754, avg loss = 0.9273158725417618\n",
            "epoch 8, batch 4490\n",
            "loss = 0.5266737937927246, avg loss = 0.9269704741929846\n",
            "epoch 8, batch 4500\n",
            "loss = 0.6651890277862549, avg loss = 0.9265206034183502\n",
            "epoch 8, batch 4510\n",
            "loss = 0.5676321983337402, avg loss = 0.9261315586297316\n",
            "epoch 8, batch 4520\n",
            "loss = 0.760582447052002, avg loss = 0.9258531598258862\n",
            "epoch 8, batch 4530\n",
            "loss = 0.9169130325317383, avg loss = 0.9256665049272921\n",
            "epoch 8, batch 4540\n",
            "loss = 1.2407673597335815, avg loss = 0.9257194745645649\n",
            "epoch 8, batch 4550\n",
            "loss = 0.6646349430084229, avg loss = 0.9254072929018147\n",
            "epoch 8, batch 4560\n",
            "loss = 0.2916957437992096, avg loss = 0.9250714062598714\n",
            "epoch 8, batch 4570\n",
            "loss = 0.781844973564148, avg loss = 0.9246498693196465\n",
            "epoch 8, batch 4580\n",
            "loss = 0.8164867758750916, avg loss = 0.924464154666428\n",
            "epoch 9, batch 4590\n",
            "loss = 0.6627059578895569, avg loss = 0.9239765538921283\n",
            "epoch 9, batch 4600\n",
            "loss = 0.6130109429359436, avg loss = 0.9234180409266897\n",
            "epoch 9, batch 4610\n",
            "loss = 0.6744462847709656, avg loss = 0.92295118514408\n",
            "epoch 9, batch 4620\n",
            "loss = 0.3407844305038452, avg loss = 0.9224085462912595\n",
            "epoch 9, batch 4630\n",
            "loss = 0.7411624789237976, avg loss = 0.922105328178689\n",
            "epoch 9, batch 4640\n",
            "loss = 1.0084649324417114, avg loss = 0.9216721672725318\n",
            "epoch 9, batch 4650\n",
            "loss = 0.4068537950515747, avg loss = 0.9213357448609927\n",
            "epoch 9, batch 4660\n",
            "loss = 0.9952377080917358, avg loss = 0.9209571104480729\n",
            "epoch 9, batch 4670\n",
            "loss = 0.8579761981964111, avg loss = 0.9205698128590236\n",
            "epoch 9, batch 4680\n",
            "loss = 0.7552778720855713, avg loss = 0.9204691984237005\n",
            "epoch 9, batch 4690\n",
            "loss = 0.8889650702476501, avg loss = 0.9201629605660561\n",
            "epoch 9, batch 4700\n",
            "loss = 0.5671111345291138, avg loss = 0.9197966161909256\n",
            "epoch 9, batch 4710\n",
            "loss = 0.8746907114982605, avg loss = 0.9195335114299619\n",
            "epoch 9, batch 4720\n",
            "loss = 0.5901298522949219, avg loss = 0.9189126457356043\n",
            "epoch 9, batch 4730\n",
            "loss = 0.520911455154419, avg loss = 0.9183604348317009\n",
            "epoch 9, batch 4740\n",
            "loss = 0.7091491222381592, avg loss = 0.9179672393774936\n",
            "epoch 9, batch 4750\n",
            "loss = 0.5671120882034302, avg loss = 0.9174279923470396\n",
            "epoch 9, batch 4760\n",
            "loss = 0.5673860311508179, avg loss = 0.9168994420184559\n",
            "epoch 9, batch 4770\n",
            "loss = 0.5764692425727844, avg loss = 0.9168685255404289\n",
            "epoch 9, batch 4780\n",
            "loss = 0.956463098526001, avg loss = 0.9165491784248642\n",
            "epoch 9, batch 4790\n",
            "loss = 0.6985190510749817, avg loss = 0.9159937558722894\n",
            "epoch 9, batch 4800\n",
            "loss = 0.6069823503494263, avg loss = 0.9155499905565133\n",
            "epoch 9, batch 4810\n",
            "loss = 0.5293861627578735, avg loss = 0.9150786802482457\n",
            "epoch 9, batch 4820\n",
            "loss = 0.9636633992195129, avg loss = 0.9150221019643223\n",
            "epoch 9, batch 4830\n",
            "loss = 0.7420940399169922, avg loss = 0.9147767980924304\n",
            "epoch 9, batch 4840\n",
            "loss = 0.7269923686981201, avg loss = 0.9142451156669658\n",
            "epoch 9, batch 4850\n",
            "loss = 0.8093607425689697, avg loss = 0.9139831590191605\n",
            "epoch 9, batch 4860\n",
            "loss = 0.6276088356971741, avg loss = 0.913722847521673\n",
            "epoch 9, batch 4870\n",
            "loss = 0.5939611196517944, avg loss = 0.9133483617059749\n",
            "epoch 9, batch 4880\n",
            "loss = 1.0747746229171753, avg loss = 0.9133202873139841\n",
            "epoch 9, batch 4890\n",
            "loss = 0.7546234130859375, avg loss = 0.9130198523036541\n",
            "epoch 9, batch 4900\n",
            "loss = 0.7432593703269958, avg loss = 0.9126427777963025\n",
            "epoch 9, batch 4910\n",
            "loss = 1.311105489730835, avg loss = 0.9123266794500672\n",
            "epoch 9, batch 4920\n",
            "loss = 0.9270613193511963, avg loss = 0.9119044626964544\n",
            "epoch 9, batch 4930\n",
            "loss = 0.5545516014099121, avg loss = 0.9115683950801167\n",
            "epoch 9, batch 4940\n",
            "loss = 0.9555817246437073, avg loss = 0.9112645341890302\n",
            "epoch 9, batch 4950\n",
            "loss = 0.4535709023475647, avg loss = 0.9108351026972135\n",
            "epoch 9, batch 4960\n",
            "loss = 0.7790610790252686, avg loss = 0.9103820885351348\n",
            "epoch 9, batch 4970\n",
            "loss = 0.5347514748573303, avg loss = 0.9100428264715542\n",
            "epoch 9, batch 4980\n",
            "loss = 0.6713433265686035, avg loss = 0.909742931755312\n",
            "epoch 9, batch 4990\n",
            "loss = 0.5000461339950562, avg loss = 0.909358300967422\n",
            "epoch 9, batch 5000\n",
            "loss = 1.1192660331726074, avg loss = 0.9090631174355746\n",
            "epoch 9, batch 5010\n",
            "loss = 1.1363762617111206, avg loss = 0.9087173426252402\n",
            "epoch 9, batch 5020\n",
            "loss = 0.4718362092971802, avg loss = 0.9083622228962729\n",
            "epoch 9, batch 5030\n",
            "loss = 0.4322735071182251, avg loss = 0.907903162631434\n",
            "epoch 9, batch 5040\n",
            "loss = 0.7762047052383423, avg loss = 0.9075320562288638\n",
            "epoch 9, batch 5050\n",
            "loss = 0.42850032448768616, avg loss = 0.9073228612070037\n",
            "epoch 9, batch 5060\n",
            "loss = 0.9438141584396362, avg loss = 0.9070182061684225\n",
            "epoch 9, batch 5070\n",
            "loss = 1.3594982624053955, avg loss = 0.9065772436573896\n",
            "epoch 9, batch 5080\n",
            "loss = 0.3452824354171753, avg loss = 0.9060710656155986\n",
            "epoch 9, batch 5090\n",
            "loss = 1.0749377012252808, avg loss = 0.9059855617714537\n",
            "epoch 10, batch 5100\n",
            "loss = 1.252506971359253, avg loss = 0.9061271777719844\n",
            "epoch 10, batch 5110\n",
            "loss = 0.6659959554672241, avg loss = 0.906077672150387\n",
            "epoch 10, batch 5120\n",
            "loss = 0.786825954914093, avg loss = 0.9057818647735985\n",
            "epoch 10, batch 5130\n",
            "loss = 0.9237863421440125, avg loss = 0.905463527869179\n",
            "epoch 10, batch 5140\n",
            "loss = 0.5517289638519287, avg loss = 0.9050923357242971\n",
            "epoch 10, batch 5150\n",
            "loss = 0.7425777912139893, avg loss = 0.9048472867920561\n",
            "epoch 10, batch 5160\n",
            "loss = 0.7028025388717651, avg loss = 0.9046654749430658\n",
            "epoch 10, batch 5170\n",
            "loss = 0.8448392152786255, avg loss = 0.9041369865808773\n",
            "epoch 10, batch 5180\n",
            "loss = 0.6438302993774414, avg loss = 0.9038636981779314\n",
            "epoch 10, batch 5190\n",
            "loss = 0.993376612663269, avg loss = 0.9034072076568025\n",
            "epoch 10, batch 5200\n",
            "loss = 0.5570775270462036, avg loss = 0.902734364153674\n",
            "epoch 10, batch 5210\n",
            "loss = 0.9582662582397461, avg loss = 0.9025627982107325\n",
            "epoch 10, batch 5220\n",
            "loss = 0.5353534817695618, avg loss = 0.9023203266392037\n",
            "epoch 10, batch 5230\n",
            "loss = 0.7433581948280334, avg loss = 0.9020135996816947\n",
            "epoch 10, batch 5240\n",
            "loss = 0.5506188869476318, avg loss = 0.9017332235052613\n",
            "epoch 10, batch 5250\n",
            "loss = 0.6556373834609985, avg loss = 0.9012955279946328\n",
            "epoch 10, batch 5260\n",
            "loss = 0.61794114112854, avg loss = 0.9010180908265902\n",
            "epoch 10, batch 5270\n",
            "loss = 0.4868788719177246, avg loss = 0.9005427086347647\n",
            "epoch 10, batch 5280\n",
            "loss = 1.2694766521453857, avg loss = 0.900333357023809\n",
            "epoch 10, batch 5290\n",
            "loss = 0.5341771841049194, avg loss = 0.8998574674326666\n",
            "epoch 10, batch 5300\n",
            "loss = 0.7024527788162231, avg loss = 0.8995726988422421\n",
            "epoch 10, batch 5310\n",
            "loss = 0.6906185150146484, avg loss = 0.8989629089916493\n",
            "epoch 10, batch 5320\n",
            "loss = 0.6450481414794922, avg loss = 0.8985208508803656\n",
            "epoch 10, batch 5330\n",
            "loss = 1.0914170742034912, avg loss = 0.8983675269567273\n",
            "epoch 10, batch 5340\n",
            "loss = 0.9057602882385254, avg loss = 0.8981485769068926\n",
            "epoch 10, batch 5350\n",
            "loss = 1.0804386138916016, avg loss = 0.8980624526989794\n",
            "epoch 10, batch 5360\n",
            "loss = 0.7018078565597534, avg loss = 0.8978120481484194\n",
            "epoch 10, batch 5370\n",
            "loss = 0.5472623109817505, avg loss = 0.8974654459670269\n",
            "epoch 10, batch 5380\n",
            "loss = 0.5871854424476624, avg loss = 0.8970374124560879\n",
            "epoch 10, batch 5390\n",
            "loss = 1.296703577041626, avg loss = 0.8966243259456693\n",
            "epoch 10, batch 5400\n",
            "loss = 0.7199068665504456, avg loss = 0.8963527064163376\n",
            "epoch 10, batch 5410\n",
            "loss = 0.6357158422470093, avg loss = 0.896037255155952\n",
            "epoch 10, batch 5420\n",
            "loss = 0.4708155691623688, avg loss = 0.8954871609504592\n",
            "epoch 10, batch 5430\n",
            "loss = 0.49713706970214844, avg loss = 0.8952607658000502\n",
            "epoch 10, batch 5440\n",
            "loss = 0.38965487480163574, avg loss = 0.8948374935891479\n",
            "epoch 10, batch 5450\n",
            "loss = 0.4057566225528717, avg loss = 0.894574544290337\n",
            "epoch 10, batch 5460\n",
            "loss = 0.5847393870353699, avg loss = 0.8942642024994552\n",
            "epoch 10, batch 5470\n",
            "loss = 0.8258544206619263, avg loss = 0.8941395125261609\n",
            "epoch 10, batch 5480\n",
            "loss = 0.8134448528289795, avg loss = 0.8939543301361973\n",
            "epoch 10, batch 5490\n",
            "loss = 0.5434207916259766, avg loss = 0.8938409317576603\n",
            "epoch 10, batch 5500\n",
            "loss = 1.03647780418396, avg loss = 0.893619184973565\n",
            "epoch 10, batch 5510\n",
            "loss = 0.4411420226097107, avg loss = 0.8933187014529796\n",
            "epoch 10, batch 5520\n",
            "loss = 1.2282662391662598, avg loss = 0.8931170584795916\n",
            "epoch 10, batch 5530\n",
            "loss = 0.48017367720603943, avg loss = 0.8928927069142542\n",
            "epoch 10, batch 5540\n",
            "loss = 0.44008755683898926, avg loss = 0.8923922385845589\n",
            "epoch 10, batch 5550\n",
            "loss = 1.5513123273849487, avg loss = 0.8921773807825268\n",
            "epoch 10, batch 5560\n",
            "loss = 0.6127888560295105, avg loss = 0.8917777587585956\n",
            "epoch 10, batch 5570\n",
            "loss = 0.4916565418243408, avg loss = 0.8915040588972812\n",
            "epoch 10, batch 5580\n",
            "loss = 0.9276673793792725, avg loss = 0.8913238754168847\n",
            "epoch 10, batch 5590\n",
            "loss = 0.6314389705657959, avg loss = 0.8910134884427187\n",
            "epoch 11, batch 5600\n",
            "loss = 0.4183472692966461, avg loss = 0.8906622907758823\n",
            "epoch 11, batch 5610\n",
            "loss = 0.4603140950202942, avg loss = 0.8905878062155795\n",
            "epoch 11, batch 5620\n",
            "loss = 0.37651413679122925, avg loss = 0.8902357777322102\n",
            "epoch 11, batch 5630\n",
            "loss = 0.9254112839698792, avg loss = 0.8897871689702224\n",
            "epoch 11, batch 5640\n",
            "loss = 0.6223875284194946, avg loss = 0.8894755439053402\n",
            "epoch 11, batch 5650\n",
            "loss = 0.3394785523414612, avg loss = 0.8892454885196897\n",
            "epoch 11, batch 5660\n",
            "loss = 0.8137977719306946, avg loss = 0.8888784440504157\n",
            "epoch 11, batch 5670\n",
            "loss = 1.0325634479522705, avg loss = 0.8886357303465695\n",
            "epoch 11, batch 5680\n",
            "loss = 0.6709541082382202, avg loss = 0.8882422268731703\n",
            "epoch 11, batch 5690\n",
            "loss = 0.6293958425521851, avg loss = 0.887983588230107\n",
            "epoch 11, batch 5700\n",
            "loss = 0.8093271255493164, avg loss = 0.8876695875248365\n",
            "epoch 11, batch 5710\n",
            "loss = 0.717495322227478, avg loss = 0.8874597697588901\n",
            "epoch 11, batch 5720\n",
            "loss = 0.6287105083465576, avg loss = 0.88711010161136\n",
            "epoch 11, batch 5730\n",
            "loss = 0.5924275517463684, avg loss = 0.8870417536319238\n",
            "epoch 11, batch 5740\n",
            "loss = 0.9174675941467285, avg loss = 0.8868560176667228\n",
            "epoch 11, batch 5750\n",
            "loss = 0.8680267333984375, avg loss = 0.8866526316948559\n",
            "epoch 11, batch 5760\n",
            "loss = 0.9583287239074707, avg loss = 0.8863768009908705\n",
            "epoch 11, batch 5770\n",
            "loss = 0.8805042505264282, avg loss = 0.8862217945929624\n",
            "epoch 11, batch 5780\n",
            "loss = 0.49452582001686096, avg loss = 0.8860355575578641\n",
            "epoch 11, batch 5790\n",
            "loss = 0.6155171394348145, avg loss = 0.8856702957514654\n",
            "epoch 11, batch 5800\n",
            "loss = 0.6520763635635376, avg loss = 0.8855598686301502\n",
            "epoch 11, batch 5810\n",
            "loss = 0.6651860475540161, avg loss = 0.8852215456906161\n",
            "epoch 11, batch 5820\n",
            "loss = 0.5765897035598755, avg loss = 0.8848313314219316\n",
            "epoch 11, batch 5830\n",
            "loss = 0.8558136224746704, avg loss = 0.8845905884180224\n",
            "epoch 11, batch 5840\n",
            "loss = 1.0410252809524536, avg loss = 0.8845777008656974\n",
            "epoch 11, batch 5850\n",
            "loss = 1.1804797649383545, avg loss = 0.8844292610246911\n",
            "epoch 11, batch 5860\n",
            "loss = 0.6110427379608154, avg loss = 0.8841499054416658\n",
            "epoch 11, batch 5870\n",
            "loss = 0.4868435561656952, avg loss = 0.8839577013858335\n",
            "epoch 11, batch 5880\n",
            "loss = 0.5958793759346008, avg loss = 0.8838949805442371\n",
            "epoch 11, batch 5890\n",
            "loss = 0.7493675947189331, avg loss = 0.8834540318779913\n",
            "epoch 11, batch 5900\n",
            "loss = 0.5438240170478821, avg loss = 0.8833042497781374\n",
            "epoch 11, batch 5910\n",
            "loss = 0.916077733039856, avg loss = 0.8830764597871178\n",
            "epoch 11, batch 5920\n",
            "loss = 0.7154546976089478, avg loss = 0.8825758260926484\n",
            "epoch 11, batch 5930\n",
            "loss = 0.47386229038238525, avg loss = 0.8823664038091847\n",
            "epoch 11, batch 5940\n",
            "loss = 0.659515380859375, avg loss = 0.8823791199335547\n",
            "epoch 11, batch 5950\n",
            "loss = 0.930934488773346, avg loss = 0.8822461778251063\n",
            "epoch 11, batch 5960\n",
            "loss = 0.8165956735610962, avg loss = 0.8820384094704118\n",
            "epoch 11, batch 5970\n",
            "loss = 0.6195911169052124, avg loss = 0.8819220529054876\n",
            "epoch 11, batch 5980\n",
            "loss = 0.5280195474624634, avg loss = 0.8817118910468342\n",
            "epoch 11, batch 5990\n",
            "loss = 0.6835591197013855, avg loss = 0.8813405244721594\n",
            "epoch 11, batch 6000\n",
            "loss = 0.42655616998672485, avg loss = 0.8810881179595987\n",
            "epoch 11, batch 6010\n",
            "loss = 0.669808566570282, avg loss = 0.8807207396517379\n",
            "epoch 11, batch 6020\n",
            "loss = 0.5359623432159424, avg loss = 0.8805800453744259\n",
            "epoch 11, batch 6030\n",
            "loss = 0.6286006569862366, avg loss = 0.8802874964193919\n",
            "epoch 11, batch 6040\n",
            "loss = 0.6956470608711243, avg loss = 0.8800404629096488\n",
            "epoch 11, batch 6050\n",
            "loss = 0.6965552568435669, avg loss = 0.8797521170530438\n",
            "epoch 11, batch 6060\n",
            "loss = 0.9037963151931763, avg loss = 0.8794928668429552\n",
            "epoch 11, batch 6070\n",
            "loss = 0.666174054145813, avg loss = 0.8791837053965698\n",
            "epoch 11, batch 6080\n",
            "loss = 0.7788700461387634, avg loss = 0.8787591005700003\n",
            "epoch 11, batch 6090\n",
            "loss = 0.658349871635437, avg loss = 0.8783692709502132\n",
            "epoch 11, batch 6100\n",
            "loss = 0.677642822265625, avg loss = 0.8780368087110949\n",
            "epoch 12, batch 6110\n",
            "loss = 0.8796037435531616, avg loss = 0.8776894692386426\n",
            "epoch 12, batch 6120\n",
            "loss = 0.8162047863006592, avg loss = 0.8777024481981214\n",
            "epoch 12, batch 6130\n",
            "loss = 0.32720208168029785, avg loss = 0.87718673796434\n",
            "epoch 12, batch 6140\n",
            "loss = 0.5771605968475342, avg loss = 0.876787209901534\n",
            "epoch 12, batch 6150\n",
            "loss = 0.5633862018585205, avg loss = 0.8765371811898743\n",
            "epoch 12, batch 6160\n",
            "loss = 0.8924016356468201, avg loss = 0.8761955932193956\n",
            "epoch 12, batch 6170\n",
            "loss = 0.9134820699691772, avg loss = 0.8759547336054196\n",
            "epoch 12, batch 6180\n",
            "loss = 0.42583736777305603, avg loss = 0.8757552687621233\n",
            "epoch 12, batch 6190\n",
            "loss = 0.5956816673278809, avg loss = 0.8752872377369246\n",
            "epoch 12, batch 6200\n",
            "loss = 0.5866426229476929, avg loss = 0.8749754453594646\n",
            "epoch 12, batch 6210\n",
            "loss = 0.8158612251281738, avg loss = 0.8748117860028709\n",
            "epoch 12, batch 6220\n",
            "loss = 0.42892986536026, avg loss = 0.8745516954007831\n",
            "epoch 12, batch 6230\n",
            "loss = 0.4263566732406616, avg loss = 0.8744956339893334\n",
            "epoch 12, batch 6240\n",
            "loss = 0.9715957641601562, avg loss = 0.8741569041417768\n",
            "epoch 12, batch 6250\n",
            "loss = 0.7496122121810913, avg loss = 0.8737318460822106\n",
            "epoch 12, batch 6260\n",
            "loss = 0.5567605495452881, avg loss = 0.873414005246311\n",
            "epoch 12, batch 6270\n",
            "loss = 0.6552010774612427, avg loss = 0.8732526525760002\n",
            "epoch 12, batch 6280\n",
            "loss = 0.8441401124000549, avg loss = 0.8731840431571576\n",
            "epoch 12, batch 6290\n",
            "loss = 0.5475980639457703, avg loss = 0.8729515213916146\n",
            "epoch 12, batch 6300\n",
            "loss = 1.1875886917114258, avg loss = 0.8728579439790476\n",
            "epoch 12, batch 6310\n",
            "loss = 0.47032254934310913, avg loss = 0.8725413297723665\n",
            "epoch 12, batch 6320\n",
            "loss = 0.713768720626831, avg loss = 0.8724402453868261\n",
            "epoch 12, batch 6330\n",
            "loss = 0.9579272866249084, avg loss = 0.8720976536331395\n",
            "epoch 12, batch 6340\n",
            "loss = 0.8119405508041382, avg loss = 0.8717481152045802\n",
            "epoch 12, batch 6350\n",
            "loss = 0.47816839814186096, avg loss = 0.8715911791338695\n",
            "epoch 12, batch 6360\n",
            "loss = 0.6178299784660339, avg loss = 0.8713429439812899\n",
            "epoch 12, batch 6370\n",
            "loss = 0.6737584471702576, avg loss = 0.8711203153808038\n",
            "epoch 12, batch 6380\n",
            "loss = 0.6186977028846741, avg loss = 0.8706980155062712\n",
            "epoch 12, batch 6390\n",
            "loss = 0.7316171526908875, avg loss = 0.8704753990720882\n",
            "epoch 12, batch 6400\n",
            "loss = 0.629357635974884, avg loss = 0.8701887402753345\n",
            "epoch 12, batch 6410\n",
            "loss = 1.2232847213745117, avg loss = 0.8700011434472296\n",
            "epoch 12, batch 6420\n",
            "loss = 1.0051867961883545, avg loss = 0.8699178855158273\n",
            "epoch 12, batch 6430\n",
            "loss = 0.5738731622695923, avg loss = 0.8696678948972496\n",
            "epoch 12, batch 6440\n",
            "loss = 0.6624666452407837, avg loss = 0.8696034088985335\n",
            "epoch 12, batch 6450\n",
            "loss = 1.2251187562942505, avg loss = 0.8693397262507631\n",
            "epoch 12, batch 6460\n",
            "loss = 0.4447421431541443, avg loss = 0.8689690145153564\n",
            "epoch 12, batch 6470\n",
            "loss = 0.5658454895019531, avg loss = 0.8687796735114071\n",
            "epoch 12, batch 6480\n",
            "loss = 0.6878879070281982, avg loss = 0.8685517376610711\n",
            "epoch 12, batch 6490\n",
            "loss = 0.608435332775116, avg loss = 0.8683087328159019\n",
            "epoch 12, batch 6500\n",
            "loss = 0.7269752025604248, avg loss = 0.8681788387000561\n",
            "epoch 12, batch 6510\n",
            "loss = 0.5720186233520508, avg loss = 0.8680014394189356\n",
            "epoch 12, batch 6520\n",
            "loss = 0.6913822889328003, avg loss = 0.8677992229424188\n",
            "epoch 12, batch 6530\n",
            "loss = 0.6488115787506104, avg loss = 0.8674818061463319\n",
            "epoch 12, batch 6540\n",
            "loss = 0.7777038216590881, avg loss = 0.8672686504775413\n",
            "epoch 12, batch 6550\n",
            "loss = 0.5937894582748413, avg loss = 0.8670903102245949\n",
            "epoch 12, batch 6560\n",
            "loss = 0.6876041889190674, avg loss = 0.8668609387468456\n",
            "epoch 12, batch 6570\n",
            "loss = 0.7737523317337036, avg loss = 0.8665563372829915\n",
            "epoch 12, batch 6580\n",
            "loss = 0.49324831366539, avg loss = 0.8663232542891451\n",
            "epoch 12, batch 6590\n",
            "loss = 0.5279077291488647, avg loss = 0.8660961849623457\n",
            "epoch 12, batch 6600\n",
            "loss = 0.9580808877944946, avg loss = 0.8660339445440155\n",
            "epoch 12, batch 6610\n",
            "loss = 0.9227598905563354, avg loss = 0.8659206575709825\n",
            "epoch 13, batch 6620\n",
            "loss = 0.6315184235572815, avg loss = 0.8654864271939521\n",
            "epoch 13, batch 6630\n",
            "loss = 0.345520943403244, avg loss = 0.8652589963684434\n",
            "epoch 13, batch 6640\n",
            "loss = 0.2631450295448303, avg loss = 0.8648234761376158\n",
            "epoch 13, batch 6650\n",
            "loss = 0.4841526448726654, avg loss = 0.8644593690638256\n",
            "epoch 13, batch 6660\n",
            "loss = 0.3933318853378296, avg loss = 0.8640873395801485\n",
            "epoch 13, batch 6670\n",
            "loss = 0.6969958543777466, avg loss = 0.8641064984486557\n",
            "epoch 13, batch 6680\n",
            "loss = 0.7155101299285889, avg loss = 0.8640481271095083\n",
            "epoch 13, batch 6690\n",
            "loss = 0.39488622546195984, avg loss = 0.8637610957026481\n",
            "epoch 13, batch 6700\n",
            "loss = 1.2256574630737305, avg loss = 0.8637171245488657\n",
            "epoch 13, batch 6710\n",
            "loss = 0.4968630373477936, avg loss = 0.8634596770482162\n",
            "epoch 13, batch 6720\n",
            "loss = 0.5721359252929688, avg loss = 0.8631045129216676\n",
            "epoch 13, batch 6730\n",
            "loss = 0.6617592573165894, avg loss = 0.8629375601040662\n",
            "epoch 13, batch 6740\n",
            "loss = 0.7135860323905945, avg loss = 0.8626808138890331\n",
            "epoch 13, batch 6750\n",
            "loss = 0.624567985534668, avg loss = 0.8624611322327896\n",
            "epoch 13, batch 6760\n",
            "loss = 0.8737521171569824, avg loss = 0.8623067495099009\n",
            "epoch 13, batch 6770\n",
            "loss = 0.851807713508606, avg loss = 0.8620319374576981\n",
            "epoch 13, batch 6780\n",
            "loss = 0.6665055155754089, avg loss = 0.8617912467448233\n",
            "epoch 13, batch 6790\n",
            "loss = 0.4470992684364319, avg loss = 0.8614117959001278\n",
            "epoch 13, batch 6800\n",
            "loss = 0.616797685623169, avg loss = 0.8610959247302483\n",
            "epoch 13, batch 6810\n",
            "loss = 0.7747098207473755, avg loss = 0.860751603994513\n",
            "epoch 13, batch 6820\n",
            "loss = 1.047804355621338, avg loss = 0.8605969802135072\n",
            "epoch 13, batch 6830\n",
            "loss = 0.8872390985488892, avg loss = 0.8604648411906656\n",
            "epoch 13, batch 6840\n",
            "loss = 0.5995359420776367, avg loss = 0.8600619706733708\n",
            "epoch 13, batch 6850\n",
            "loss = 0.5444628000259399, avg loss = 0.8599683566837415\n",
            "epoch 13, batch 6860\n",
            "loss = 0.7151895761489868, avg loss = 0.8598225282141314\n",
            "epoch 13, batch 6870\n",
            "loss = 0.6354712247848511, avg loss = 0.8595042393565872\n",
            "epoch 13, batch 6880\n",
            "loss = 0.5135490894317627, avg loss = 0.8592478877258335\n",
            "epoch 13, batch 6890\n",
            "loss = 0.8245543241500854, avg loss = 0.8590481445582581\n",
            "epoch 13, batch 6900\n",
            "loss = 0.4345301687717438, avg loss = 0.8588312102379142\n",
            "epoch 13, batch 6910\n",
            "loss = 0.6268213391304016, avg loss = 0.8583900717573643\n",
            "epoch 13, batch 6920\n",
            "loss = 0.8650790452957153, avg loss = 0.8582607816818649\n",
            "epoch 13, batch 6930\n",
            "loss = 1.116946816444397, avg loss = 0.8582284650911844\n",
            "epoch 13, batch 6940\n",
            "loss = 0.5642485618591309, avg loss = 0.8580498332699884\n",
            "epoch 13, batch 6950\n",
            "loss = 0.7174979448318481, avg loss = 0.857751400404268\n",
            "epoch 13, batch 6960\n",
            "loss = 0.7280858755111694, avg loss = 0.8577604795602718\n",
            "epoch 13, batch 6970\n",
            "loss = 0.6274847984313965, avg loss = 0.8575310293387306\n",
            "epoch 13, batch 6980\n",
            "loss = 0.3954162001609802, avg loss = 0.8571521904735818\n",
            "epoch 13, batch 6990\n",
            "loss = 0.38378551602363586, avg loss = 0.8569484346734096\n",
            "epoch 13, batch 7000\n",
            "loss = 0.5393457412719727, avg loss = 0.8569286940715143\n",
            "epoch 13, batch 7010\n",
            "loss = 0.5539491772651672, avg loss = 0.8564799595385068\n",
            "epoch 13, batch 7020\n",
            "loss = 1.019102931022644, avg loss = 0.8562390744367726\n",
            "epoch 13, batch 7030\n",
            "loss = 0.9431027173995972, avg loss = 0.8558984921315147\n",
            "epoch 13, batch 7040\n",
            "loss = 0.933023989200592, avg loss = 0.8555854157184843\n",
            "epoch 13, batch 7050\n",
            "loss = 0.6608710289001465, avg loss = 0.8554221925054881\n",
            "epoch 13, batch 7060\n",
            "loss = 0.8619044423103333, avg loss = 0.8551182155885203\n",
            "epoch 13, batch 7070\n",
            "loss = 0.8393213748931885, avg loss = 0.8548370620043477\n",
            "epoch 13, batch 7080\n",
            "loss = 0.34197431802749634, avg loss = 0.8545010007896834\n",
            "epoch 13, batch 7090\n",
            "loss = 0.702078104019165, avg loss = 0.8542605651429577\n",
            "epoch 13, batch 7100\n",
            "loss = 0.9907421469688416, avg loss = 0.8543768180319121\n",
            "epoch 13, batch 7110\n",
            "loss = 0.902579665184021, avg loss = 0.8542060647772838\n",
            "epoch 13, batch 7120\n",
            "loss = 0.9860537052154541, avg loss = 0.8539764041960072\n",
            "epoch 14, batch 7130\n",
            "loss = 0.5593470335006714, avg loss = 0.8537555891639053\n",
            "epoch 14, batch 7140\n",
            "loss = 0.3690435290336609, avg loss = 0.8533159646187343\n",
            "epoch 14, batch 7150\n",
            "loss = 0.4516517221927643, avg loss = 0.8530260641987507\n",
            "epoch 14, batch 7160\n",
            "loss = 0.9984241127967834, avg loss = 0.8527636209825398\n",
            "epoch 14, batch 7170\n",
            "loss = 0.7366138696670532, avg loss = 0.8525866424792149\n",
            "epoch 14, batch 7180\n",
            "loss = 0.3763895332813263, avg loss = 0.8524173992984309\n",
            "epoch 14, batch 7190\n",
            "loss = 1.0289676189422607, avg loss = 0.8522828153530149\n",
            "epoch 14, batch 7200\n",
            "loss = 0.5905755758285522, avg loss = 0.8520640247625609\n",
            "epoch 14, batch 7210\n",
            "loss = 0.869615912437439, avg loss = 0.8520229266499183\n",
            "epoch 14, batch 7220\n",
            "loss = 0.6849888563156128, avg loss = 0.8516809056814852\n",
            "epoch 14, batch 7230\n",
            "loss = 0.5222249031066895, avg loss = 0.8515953031627469\n",
            "epoch 14, batch 7240\n",
            "loss = 0.37069427967071533, avg loss = 0.8512305612372265\n",
            "epoch 14, batch 7250\n",
            "loss = 0.9670599102973938, avg loss = 0.8509254588197017\n",
            "epoch 14, batch 7260\n",
            "loss = 0.7311927080154419, avg loss = 0.8506989456097449\n",
            "epoch 14, batch 7270\n",
            "loss = 0.6398581266403198, avg loss = 0.8503841300347649\n",
            "epoch 14, batch 7280\n",
            "loss = 0.4376642405986786, avg loss = 0.8501490311492439\n",
            "epoch 14, batch 7290\n",
            "loss = 0.5077558755874634, avg loss = 0.8498975196595218\n",
            "epoch 14, batch 7300\n",
            "loss = 0.4390013813972473, avg loss = 0.8497240671168451\n",
            "epoch 14, batch 7310\n",
            "loss = 0.9782060980796814, avg loss = 0.8496377324540214\n",
            "epoch 14, batch 7320\n",
            "loss = 0.7670037746429443, avg loss = 0.849535864259783\n",
            "epoch 14, batch 7330\n",
            "loss = 0.795746922492981, avg loss = 0.8493803862192622\n",
            "epoch 14, batch 7340\n",
            "loss = 0.8398330211639404, avg loss = 0.8491686131652921\n",
            "epoch 14, batch 7350\n",
            "loss = 0.9180716276168823, avg loss = 0.8490396256450893\n",
            "epoch 14, batch 7360\n",
            "loss = 1.2240760326385498, avg loss = 0.8487251979481105\n",
            "epoch 14, batch 7370\n",
            "loss = 0.41426023840904236, avg loss = 0.8484092143570229\n",
            "epoch 14, batch 7380\n",
            "loss = 0.5524306893348694, avg loss = 0.8481337571208716\n",
            "epoch 14, batch 7390\n",
            "loss = 0.5850170254707336, avg loss = 0.8479684900971324\n",
            "epoch 14, batch 7400\n",
            "loss = 0.7626575231552124, avg loss = 0.8479264502871681\n",
            "epoch 14, batch 7410\n",
            "loss = 0.5750800371170044, avg loss = 0.8477227469405987\n",
            "epoch 14, batch 7420\n",
            "loss = 0.6130404472351074, avg loss = 0.8475950148388381\n",
            "epoch 14, batch 7430\n",
            "loss = 0.9146305322647095, avg loss = 0.8472790570310436\n",
            "epoch 14, batch 7440\n",
            "loss = 0.42997434735298157, avg loss = 0.846926286327903\n",
            "epoch 14, batch 7450\n",
            "loss = 0.46223098039627075, avg loss = 0.8467558611119353\n",
            "epoch 14, batch 7460\n",
            "loss = 0.7625606656074524, avg loss = 0.8466644417464574\n",
            "epoch 14, batch 7470\n",
            "loss = 0.9095253944396973, avg loss = 0.8464375434031927\n",
            "epoch 14, batch 7480\n",
            "loss = 1.0211882591247559, avg loss = 0.8463100184771147\n",
            "epoch 14, batch 7490\n",
            "loss = 0.6004012227058411, avg loss = 0.8460257485130919\n",
            "epoch 14, batch 7500\n",
            "loss = 0.7576271295547485, avg loss = 0.8457299914916356\n",
            "epoch 14, batch 7510\n",
            "loss = 1.1494598388671875, avg loss = 0.8455560395625555\n",
            "epoch 14, batch 7520\n",
            "loss = 0.4487171769142151, avg loss = 0.8453773433461468\n",
            "epoch 14, batch 7530\n",
            "loss = 0.6680041551589966, avg loss = 0.8451196533710674\n",
            "epoch 14, batch 7540\n",
            "loss = 0.4078681766986847, avg loss = 0.8449130493109992\n",
            "epoch 14, batch 7550\n",
            "loss = 0.3654964566230774, avg loss = 0.8446490294649112\n",
            "epoch 14, batch 7560\n",
            "loss = 0.9824285507202148, avg loss = 0.8445198440953853\n",
            "epoch 14, batch 7570\n",
            "loss = 0.7361174821853638, avg loss = 0.8442137482813517\n",
            "epoch 14, batch 7580\n",
            "loss = 0.7481806874275208, avg loss = 0.8441628860412927\n",
            "epoch 14, batch 7590\n",
            "loss = 0.5759029388427734, avg loss = 0.8439512757562366\n",
            "epoch 14, batch 7600\n",
            "loss = 0.7990100979804993, avg loss = 0.8437037303416353\n",
            "epoch 14, batch 7610\n",
            "loss = 0.6266450881958008, avg loss = 0.8436097455635647\n",
            "epoch 14, batch 7620\n",
            "loss = 0.7578340768814087, avg loss = 0.8434812737183934\n",
            "epoch 14, batch 7630\n",
            "loss = 0.5628780126571655, avg loss = 0.8433609173151019\n",
            "epoch 15, batch 7640\n",
            "loss = 0.6521925926208496, avg loss = 0.8431137025278276\n",
            "epoch 15, batch 7650\n",
            "loss = 0.595848798751831, avg loss = 0.8429488897479438\n",
            "epoch 15, batch 7660\n",
            "loss = 1.0981823205947876, avg loss = 0.842741218489393\n",
            "epoch 15, batch 7670\n",
            "loss = 0.38410472869873047, avg loss = 0.8425661930671104\n",
            "epoch 15, batch 7680\n",
            "loss = 0.736284077167511, avg loss = 0.8425724811075876\n",
            "epoch 15, batch 7690\n",
            "loss = 0.43809130787849426, avg loss = 0.8423194390550857\n",
            "epoch 15, batch 7700\n",
            "loss = 0.5427929162979126, avg loss = 0.8419723490074084\n",
            "epoch 15, batch 7710\n",
            "loss = 0.7557927966117859, avg loss = 0.8417642010788973\n",
            "epoch 15, batch 7720\n",
            "loss = 0.6356921792030334, avg loss = 0.8416588523343128\n",
            "epoch 15, batch 7730\n",
            "loss = 0.9608261585235596, avg loss = 0.841352146644179\n",
            "epoch 15, batch 7740\n",
            "loss = 0.7658955454826355, avg loss = 0.8412085358717645\n",
            "epoch 15, batch 7750\n",
            "loss = 0.7456183433532715, avg loss = 0.8409827250742143\n",
            "epoch 15, batch 7760\n",
            "loss = 0.41577380895614624, avg loss = 0.84078764138148\n",
            "epoch 15, batch 7770\n",
            "loss = 0.7354855537414551, avg loss = 0.8407014932871786\n",
            "epoch 15, batch 7780\n",
            "loss = 0.7259639501571655, avg loss = 0.8403979928144146\n",
            "epoch 15, batch 7790\n",
            "loss = 0.7049538493156433, avg loss = 0.8402392816711911\n",
            "epoch 15, batch 7800\n",
            "loss = 0.5543524026870728, avg loss = 0.840047565752115\n",
            "epoch 15, batch 7810\n",
            "loss = 0.6981425881385803, avg loss = 0.8398030199787834\n",
            "epoch 15, batch 7820\n",
            "loss = 0.5263482332229614, avg loss = 0.8395859118922592\n",
            "epoch 15, batch 7830\n",
            "loss = 0.666780948638916, avg loss = 0.8393374328564562\n",
            "epoch 15, batch 7840\n",
            "loss = 0.8629571199417114, avg loss = 0.8391860978753896\n",
            "epoch 15, batch 7850\n",
            "loss = 0.4261985421180725, avg loss = 0.8389024469541136\n",
            "epoch 15, batch 7860\n",
            "loss = 1.0391135215759277, avg loss = 0.838698029097255\n",
            "epoch 15, batch 7870\n",
            "loss = 0.6550132036209106, avg loss = 0.8384043588950341\n",
            "epoch 15, batch 7880\n",
            "loss = 0.6010247468948364, avg loss = 0.8382439388955002\n",
            "epoch 15, batch 7890\n",
            "loss = 0.5803120732307434, avg loss = 0.8380717737404264\n",
            "epoch 15, batch 7900\n",
            "loss = 0.6770678758621216, avg loss = 0.8378164229626897\n",
            "epoch 15, batch 7910\n",
            "loss = 0.33847591280937195, avg loss = 0.8375884317266655\n",
            "epoch 15, batch 7920\n",
            "loss = 0.7026938796043396, avg loss = 0.8373797826995754\n",
            "epoch 15, batch 7930\n",
            "loss = 0.423691987991333, avg loss = 0.8371530297161802\n",
            "epoch 15, batch 7940\n",
            "loss = 0.8559554219245911, avg loss = 0.8369860131884702\n",
            "epoch 15, batch 7950\n",
            "loss = 0.7901273965835571, avg loss = 0.8369531841360548\n",
            "epoch 15, batch 7960\n",
            "loss = 0.7336175441741943, avg loss = 0.8368604191096883\n",
            "epoch 15, batch 7970\n",
            "loss = 0.8318132758140564, avg loss = 0.8366120438316984\n",
            "epoch 15, batch 7980\n",
            "loss = 0.7193593978881836, avg loss = 0.836411049218853\n",
            "epoch 15, batch 7990\n",
            "loss = 0.4820903241634369, avg loss = 0.8360956416410559\n",
            "epoch 15, batch 8000\n",
            "loss = 0.6028841137886047, avg loss = 0.835918631710112\n",
            "epoch 15, batch 8010\n",
            "loss = 0.9720184206962585, avg loss = 0.8357630027516206\n",
            "epoch 15, batch 8020\n",
            "loss = 0.6988070011138916, avg loss = 0.8355262040162919\n",
            "epoch 15, batch 8030\n",
            "loss = 0.6313970685005188, avg loss = 0.8352811277506509\n",
            "epoch 15, batch 8040\n",
            "loss = 1.0232312679290771, avg loss = 0.8351204820570365\n",
            "epoch 15, batch 8050\n",
            "loss = 0.8505223989486694, avg loss = 0.8349014467556284\n",
            "epoch 15, batch 8060\n",
            "loss = 0.45204341411590576, avg loss = 0.8346750101402735\n",
            "epoch 15, batch 8070\n",
            "loss = 0.986965537071228, avg loss = 0.8345711150835585\n",
            "epoch 15, batch 8080\n",
            "loss = 0.48724278807640076, avg loss = 0.834456906120966\n",
            "epoch 15, batch 8090\n",
            "loss = 0.925794243812561, avg loss = 0.8341534503716032\n",
            "epoch 15, batch 8100\n",
            "loss = 0.4882444441318512, avg loss = 0.8339187556321238\n",
            "epoch 15, batch 8110\n",
            "loss = 0.5830341577529907, avg loss = 0.8337400455399888\n",
            "epoch 15, batch 8120\n",
            "loss = 0.5118505358695984, avg loss = 0.8335797373187073\n",
            "epoch 15, batch 8130\n",
            "loss = 0.6277143955230713, avg loss = 0.8333433180460924\n",
            "epoch 15, batch 8140\n",
            "loss = 0.7252752780914307, avg loss = 0.8332459500695623\n",
            "epoch 16, batch 8150\n",
            "loss = 0.48832255601882935, avg loss = 0.8330591409886542\n",
            "epoch 16, batch 8160\n",
            "loss = 0.736190676689148, avg loss = 0.8327591104944255\n",
            "epoch 16, batch 8170\n",
            "loss = 0.5766720771789551, avg loss = 0.8323606579219113\n",
            "epoch 16, batch 8180\n",
            "loss = 0.6236439347267151, avg loss = 0.8321322557832909\n",
            "epoch 16, batch 8190\n",
            "loss = 0.772571325302124, avg loss = 0.831946368462728\n",
            "epoch 16, batch 8200\n",
            "loss = 0.3912513256072998, avg loss = 0.8317441785299197\n",
            "epoch 16, batch 8210\n",
            "loss = 0.3593607544898987, avg loss = 0.8316128332744127\n",
            "epoch 16, batch 8220\n",
            "loss = 0.6207458972930908, avg loss = 0.8313543074975048\n",
            "epoch 16, batch 8230\n",
            "loss = 0.673272967338562, avg loss = 0.8310045759957442\n",
            "epoch 16, batch 8240\n",
            "loss = 0.5107359886169434, avg loss = 0.830837718480565\n",
            "epoch 16, batch 8250\n",
            "loss = 0.8593824505805969, avg loss = 0.8306722078395612\n",
            "epoch 16, batch 8260\n",
            "loss = 0.5957654714584351, avg loss = 0.8305673993131728\n",
            "epoch 16, batch 8270\n",
            "loss = 0.7762851715087891, avg loss = 0.8303992651934491\n",
            "epoch 16, batch 8280\n",
            "loss = 0.5065305233001709, avg loss = 0.8300558168423061\n",
            "epoch 16, batch 8290\n",
            "loss = 0.48197418451309204, avg loss = 0.8297778045203631\n",
            "epoch 16, batch 8300\n",
            "loss = 0.62230384349823, avg loss = 0.8296005971999053\n",
            "epoch 16, batch 8310\n",
            "loss = 0.7930620312690735, avg loss = 0.8294465432492691\n",
            "epoch 16, batch 8320\n",
            "loss = 0.730332612991333, avg loss = 0.8292306000223526\n",
            "epoch 16, batch 8330\n",
            "loss = 1.1198625564575195, avg loss = 0.8290047512012942\n",
            "epoch 16, batch 8340\n",
            "loss = 0.9851351976394653, avg loss = 0.8288608471409594\n",
            "epoch 16, batch 8350\n",
            "loss = 0.8916640877723694, avg loss = 0.8286869106606809\n",
            "epoch 16, batch 8360\n",
            "loss = 0.30978310108184814, avg loss = 0.8284888530069846\n",
            "epoch 16, batch 8370\n",
            "loss = 0.8335527181625366, avg loss = 0.8285051036016345\n",
            "epoch 16, batch 8380\n",
            "loss = 0.47657036781311035, avg loss = 0.8283908377577126\n",
            "epoch 16, batch 8390\n",
            "loss = 0.7736190557479858, avg loss = 0.8282001925310446\n",
            "epoch 16, batch 8400\n",
            "loss = 0.6399604678153992, avg loss = 0.8280248856189705\n",
            "epoch 16, batch 8410\n",
            "loss = 0.6388492584228516, avg loss = 0.8277969822482462\n",
            "epoch 16, batch 8420\n",
            "loss = 0.898410439491272, avg loss = 0.8276341137934184\n",
            "epoch 16, batch 8430\n",
            "loss = 0.814871072769165, avg loss = 0.8274625817404382\n",
            "epoch 16, batch 8440\n",
            "loss = 0.3671969175338745, avg loss = 0.8271611520040657\n",
            "epoch 16, batch 8450\n",
            "loss = 0.21532617509365082, avg loss = 0.8269541960654879\n",
            "epoch 16, batch 8460\n",
            "loss = 0.7745181322097778, avg loss = 0.8269413114879853\n",
            "epoch 16, batch 8470\n",
            "loss = 0.8526736497879028, avg loss = 0.8268334489592836\n",
            "epoch 16, batch 8480\n",
            "loss = 1.1098952293395996, avg loss = 0.8268240209616159\n",
            "epoch 16, batch 8490\n",
            "loss = 1.043628454208374, avg loss = 0.8266682480982953\n",
            "epoch 16, batch 8500\n",
            "loss = 0.30509549379348755, avg loss = 0.8263664072699407\n",
            "epoch 16, batch 8510\n",
            "loss = 0.5953806042671204, avg loss = 0.8260925147371623\n",
            "epoch 16, batch 8520\n",
            "loss = 0.5582367181777954, avg loss = 0.8258591289129196\n",
            "epoch 16, batch 8530\n",
            "loss = 0.585863471031189, avg loss = 0.8256629427862195\n",
            "epoch 16, batch 8540\n",
            "loss = 0.6239691972732544, avg loss = 0.8254560619261142\n",
            "epoch 16, batch 8550\n",
            "loss = 0.41007930040359497, avg loss = 0.8251949405966447\n",
            "epoch 16, batch 8560\n",
            "loss = 0.7441307306289673, avg loss = 0.8250116452278796\n",
            "epoch 16, batch 8570\n",
            "loss = 0.6429235935211182, avg loss = 0.8247876290662286\n",
            "epoch 16, batch 8580\n",
            "loss = 0.8091356158256531, avg loss = 0.8246408037598177\n",
            "epoch 16, batch 8590\n",
            "loss = 0.7398456335067749, avg loss = 0.8245879300866749\n",
            "epoch 16, batch 8600\n",
            "loss = 0.772844672203064, avg loss = 0.8245215100656416\n",
            "epoch 16, batch 8610\n",
            "loss = 1.4943487644195557, avg loss = 0.8243642184394439\n",
            "epoch 16, batch 8620\n",
            "loss = 0.552288293838501, avg loss = 0.8241324870101675\n",
            "epoch 16, batch 8630\n",
            "loss = 0.36912137269973755, avg loss = 0.8240374020239293\n",
            "epoch 16, batch 8640\n",
            "loss = 0.705518901348114, avg loss = 0.8238555885834137\n",
            "epoch 16, batch 8650\n",
            "loss = 0.49126309156417847, avg loss = 0.8237108530732937\n",
            "epoch 17, batch 8660\n",
            "loss = 0.43257856369018555, avg loss = 0.823450930466484\n",
            "epoch 17, batch 8670\n",
            "loss = 0.7715328335762024, avg loss = 0.8231976437372732\n",
            "epoch 17, batch 8680\n",
            "loss = 0.8802894949913025, avg loss = 0.8230045507425949\n",
            "epoch 17, batch 8690\n",
            "loss = 0.7358449101448059, avg loss = 0.8227641131253045\n",
            "epoch 17, batch 8700\n",
            "loss = 0.44916707277297974, avg loss = 0.8225449074941805\n",
            "epoch 17, batch 8710\n",
            "loss = 0.5192234516143799, avg loss = 0.8224642300287563\n",
            "epoch 17, batch 8720\n",
            "loss = 1.1999458074569702, avg loss = 0.8223213524805433\n",
            "epoch 17, batch 8730\n",
            "loss = 0.6959640979766846, avg loss = 0.8221407971414231\n",
            "epoch 17, batch 8740\n",
            "loss = 0.8976497650146484, avg loss = 0.8220023532873296\n",
            "epoch 17, batch 8750\n",
            "loss = 0.18917986750602722, avg loss = 0.8216969833425113\n",
            "epoch 17, batch 8760\n",
            "loss = 0.5912283658981323, avg loss = 0.8215484154023672\n",
            "epoch 17, batch 8770\n",
            "loss = 0.6574521660804749, avg loss = 0.8214345018754255\n",
            "epoch 17, batch 8780\n",
            "loss = 1.147024154663086, avg loss = 0.8212224371833111\n",
            "epoch 17, batch 8790\n",
            "loss = 0.5773736238479614, avg loss = 0.8209825679185176\n",
            "epoch 17, batch 8800\n",
            "loss = 0.7687872648239136, avg loss = 0.8207947938736867\n",
            "epoch 17, batch 8810\n",
            "loss = 0.4772655963897705, avg loss = 0.8205672972944483\n",
            "epoch 17, batch 8820\n",
            "loss = 1.148309588432312, avg loss = 0.8204094839795512\n",
            "epoch 17, batch 8830\n",
            "loss = 0.8603852987289429, avg loss = 0.8203650022602702\n",
            "epoch 17, batch 8840\n",
            "loss = 0.38723301887512207, avg loss = 0.8200607897452504\n",
            "epoch 17, batch 8850\n",
            "loss = 0.6418673396110535, avg loss = 0.8198784193632292\n",
            "epoch 17, batch 8860\n",
            "loss = 0.9171435832977295, avg loss = 0.819837523974966\n",
            "epoch 17, batch 8870\n",
            "loss = 0.5056164264678955, avg loss = 0.8196260629858079\n",
            "epoch 17, batch 8880\n",
            "loss = 0.5269513130187988, avg loss = 0.8194909831609678\n",
            "epoch 17, batch 8890\n",
            "loss = 0.39688044786453247, avg loss = 0.8191971026587271\n",
            "epoch 17, batch 8900\n",
            "loss = 1.0788308382034302, avg loss = 0.819061765220393\n",
            "epoch 17, batch 8910\n",
            "loss = 0.3641339838504791, avg loss = 0.818877806180856\n",
            "epoch 17, batch 8920\n",
            "loss = 1.233832597732544, avg loss = 0.8187055341147654\n",
            "epoch 17, batch 8930\n",
            "loss = 0.549055814743042, avg loss = 0.8183945665367507\n",
            "epoch 17, batch 8940\n",
            "loss = 0.8443304300308228, avg loss = 0.8182825235479096\n",
            "epoch 17, batch 8950\n",
            "loss = 0.9345849752426147, avg loss = 0.8181852331341312\n",
            "epoch 17, batch 8960\n",
            "loss = 0.3679881691932678, avg loss = 0.8180186857070242\n",
            "epoch 17, batch 8970\n",
            "loss = 0.5072876214981079, avg loss = 0.8178601609059135\n",
            "epoch 17, batch 8980\n",
            "loss = 0.5988281965255737, avg loss = 0.8177356519551744\n",
            "epoch 17, batch 8990\n",
            "loss = 0.9481005668640137, avg loss = 0.8175767948285358\n",
            "epoch 17, batch 9000\n",
            "loss = 1.276104211807251, avg loss = 0.8173966696692838\n",
            "epoch 17, batch 9010\n",
            "loss = 1.0693670511245728, avg loss = 0.8172476622922042\n",
            "epoch 17, batch 9020\n",
            "loss = 0.924484372138977, avg loss = 0.8171296596427979\n",
            "epoch 17, batch 9030\n",
            "loss = 1.0370969772338867, avg loss = 0.8169104921857384\n",
            "epoch 17, batch 9040\n",
            "loss = 0.4247325658798218, avg loss = 0.8167216433129744\n",
            "epoch 17, batch 9050\n",
            "loss = 1.4928172826766968, avg loss = 0.8166241015156329\n",
            "epoch 17, batch 9060\n",
            "loss = 0.9613001346588135, avg loss = 0.816520947477807\n",
            "epoch 17, batch 9070\n",
            "loss = 0.8507710695266724, avg loss = 0.8164778131338569\n",
            "epoch 17, batch 9080\n",
            "loss = 0.6746034622192383, avg loss = 0.8162208810908154\n",
            "epoch 17, batch 9090\n",
            "loss = 0.5585979223251343, avg loss = 0.8159540835386849\n",
            "epoch 17, batch 9100\n",
            "loss = 0.7356351613998413, avg loss = 0.8158167169447783\n",
            "epoch 17, batch 9110\n",
            "loss = 0.9181686639785767, avg loss = 0.8156933742087706\n",
            "epoch 17, batch 9120\n",
            "loss = 1.0839197635650635, avg loss = 0.815518839327259\n",
            "epoch 17, batch 9130\n",
            "loss = 0.9428542852401733, avg loss = 0.8154157517153489\n",
            "epoch 17, batch 9140\n",
            "loss = 0.4778914153575897, avg loss = 0.8152787120976125\n",
            "epoch 17, batch 9150\n",
            "loss = 0.718082070350647, avg loss = 0.8151321055850045\n",
            "epoch 17, batch 9160\n",
            "loss = 0.6670894622802734, avg loss = 0.8148834705271445\n",
            "epoch 18, batch 9170\n",
            "loss = 0.55033278465271, avg loss = 0.814592397074858\n",
            "epoch 18, batch 9180\n",
            "loss = 0.5954224467277527, avg loss = 0.8143590643303976\n",
            "epoch 18, batch 9190\n",
            "loss = 0.5489593744277954, avg loss = 0.8140608150710608\n",
            "epoch 18, batch 9200\n",
            "loss = 0.4867076873779297, avg loss = 0.813835870800135\n",
            "epoch 18, batch 9210\n",
            "loss = 0.6796881556510925, avg loss = 0.8135501321263603\n",
            "epoch 18, batch 9220\n",
            "loss = 0.8180263042449951, avg loss = 0.8134633347408244\n",
            "epoch 18, batch 9230\n",
            "loss = 0.5646091103553772, avg loss = 0.8132310782858894\n",
            "epoch 18, batch 9240\n",
            "loss = 0.43206873536109924, avg loss = 0.8129542552370143\n",
            "epoch 18, batch 9250\n",
            "loss = 0.6308872103691101, avg loss = 0.8126995186306335\n",
            "epoch 18, batch 9260\n",
            "loss = 0.5376613736152649, avg loss = 0.8125810315120426\n",
            "epoch 18, batch 9270\n",
            "loss = 0.9214061498641968, avg loss = 0.8124760295789861\n",
            "epoch 18, batch 9280\n",
            "loss = 0.38960981369018555, avg loss = 0.8123244474240546\n",
            "epoch 18, batch 9290\n",
            "loss = 0.7521786093711853, avg loss = 0.8121409322894043\n",
            "epoch 18, batch 9300\n",
            "loss = 0.4168887138366699, avg loss = 0.8119967954886216\n",
            "epoch 18, batch 9310\n",
            "loss = 0.7096114158630371, avg loss = 0.8118358178934528\n",
            "epoch 18, batch 9320\n",
            "loss = 0.5192035436630249, avg loss = 0.8116345360475421\n",
            "epoch 18, batch 9330\n",
            "loss = 0.4366801381111145, avg loss = 0.8115224991373055\n",
            "epoch 18, batch 9340\n",
            "loss = 0.5726637244224548, avg loss = 0.8114232412944259\n",
            "epoch 18, batch 9350\n",
            "loss = 0.8986344337463379, avg loss = 0.8112783607250866\n",
            "epoch 18, batch 9360\n",
            "loss = 0.7459923028945923, avg loss = 0.8110073692396156\n",
            "epoch 18, batch 9370\n",
            "loss = 0.6688880920410156, avg loss = 0.8109481957449857\n",
            "epoch 18, batch 9380\n",
            "loss = 0.7061909437179565, avg loss = 0.8108102885358878\n",
            "epoch 18, batch 9390\n",
            "loss = 1.3494396209716797, avg loss = 0.8106961224946224\n",
            "epoch 18, batch 9400\n",
            "loss = 0.45820754766464233, avg loss = 0.8103935735371519\n",
            "epoch 18, batch 9410\n",
            "loss = 1.02052640914917, avg loss = 0.8102449276717132\n",
            "epoch 18, batch 9420\n",
            "loss = 0.7386766672134399, avg loss = 0.8100668224844204\n",
            "epoch 18, batch 9430\n",
            "loss = 0.7509783506393433, avg loss = 0.8099464415144946\n",
            "epoch 18, batch 9440\n",
            "loss = 0.8050571084022522, avg loss = 0.8099202335606944\n",
            "epoch 18, batch 9450\n",
            "loss = 0.8246068954467773, avg loss = 0.80982470391604\n",
            "epoch 18, batch 9460\n",
            "loss = 0.8001429438591003, avg loss = 0.8097493154081431\n",
            "epoch 18, batch 9470\n",
            "loss = 0.775941789150238, avg loss = 0.8096681993922815\n",
            "epoch 18, batch 9480\n",
            "loss = 0.7178592681884766, avg loss = 0.8095029796509049\n",
            "epoch 18, batch 9490\n",
            "loss = 0.5792752504348755, avg loss = 0.8093873775765316\n",
            "epoch 18, batch 9500\n",
            "loss = 0.5781008005142212, avg loss = 0.809180935850269\n",
            "epoch 18, batch 9510\n",
            "loss = 0.6033982038497925, avg loss = 0.8089931488695205\n",
            "epoch 18, batch 9520\n",
            "loss = 0.8732980489730835, avg loss = 0.8088573611990995\n",
            "epoch 18, batch 9530\n",
            "loss = 0.5635104775428772, avg loss = 0.8087506597402339\n",
            "epoch 18, batch 9540\n",
            "loss = 0.6131812334060669, avg loss = 0.8085752323519759\n",
            "epoch 18, batch 9550\n",
            "loss = 0.5938636064529419, avg loss = 0.8084449785666941\n",
            "epoch 18, batch 9560\n",
            "loss = 0.4953816533088684, avg loss = 0.8082479713352155\n",
            "epoch 18, batch 9570\n",
            "loss = 0.8022747039794922, avg loss = 0.8081087933096144\n",
            "epoch 18, batch 9580\n",
            "loss = 0.6029545068740845, avg loss = 0.8079731847958674\n",
            "epoch 18, batch 9590\n",
            "loss = 0.5110424757003784, avg loss = 0.8078836226923249\n",
            "epoch 18, batch 9600\n",
            "loss = 0.9007265567779541, avg loss = 0.8076850399126609\n",
            "epoch 18, batch 9610\n",
            "loss = 0.4016498029232025, avg loss = 0.8075169480212894\n",
            "epoch 18, batch 9620\n",
            "loss = 0.7319051027297974, avg loss = 0.8073402651568212\n",
            "epoch 18, batch 9630\n",
            "loss = 0.7520369291305542, avg loss = 0.8071809587263244\n",
            "epoch 18, batch 9640\n",
            "loss = 0.5741029381752014, avg loss = 0.807104422788897\n",
            "epoch 18, batch 9650\n",
            "loss = 0.8136944770812988, avg loss = 0.8069839477477296\n",
            "epoch 18, batch 9660\n",
            "loss = 0.41851720213890076, avg loss = 0.806796246011188\n",
            "epoch 18, batch 9670\n",
            "loss = 0.7128954529762268, avg loss = 0.8067641372795312\n",
            "epoch 19, batch 9680\n",
            "loss = 0.4679100215435028, avg loss = 0.8065354352709183\n",
            "epoch 19, batch 9690\n",
            "loss = 0.545148491859436, avg loss = 0.8063238326271744\n",
            "epoch 19, batch 9700\n",
            "loss = 0.6774975061416626, avg loss = 0.8061154299759373\n",
            "epoch 19, batch 9710\n",
            "loss = 0.6770634651184082, avg loss = 0.8058598636353176\n",
            "epoch 19, batch 9720\n",
            "loss = 0.5175626277923584, avg loss = 0.8057429120619111\n",
            "epoch 19, batch 9730\n",
            "loss = 1.1271238327026367, avg loss = 0.8056826146937838\n",
            "epoch 19, batch 9740\n",
            "loss = 0.5271362066268921, avg loss = 0.8054261755404776\n",
            "epoch 19, batch 9750\n",
            "loss = 1.0174942016601562, avg loss = 0.8052578881245394\n",
            "epoch 19, batch 9760\n",
            "loss = 1.0363166332244873, avg loss = 0.8050935032731685\n",
            "epoch 19, batch 9770\n",
            "loss = 0.7817338705062866, avg loss = 0.8049039956674117\n",
            "epoch 19, batch 9780\n",
            "loss = 0.8694195747375488, avg loss = 0.804983850819933\n",
            "epoch 19, batch 9790\n",
            "loss = 0.6625843048095703, avg loss = 0.8050183850058009\n",
            "epoch 19, batch 9800\n",
            "loss = 0.8528848886489868, avg loss = 0.8049292679252673\n",
            "epoch 19, batch 9810\n",
            "loss = 0.4176548421382904, avg loss = 0.804689578166674\n",
            "epoch 19, batch 9820\n",
            "loss = 0.5828678011894226, avg loss = 0.8045056893602165\n",
            "epoch 19, batch 9830\n",
            "loss = 0.4392639994621277, avg loss = 0.8043684207198578\n",
            "epoch 19, batch 9840\n",
            "loss = 0.8209235668182373, avg loss = 0.8041603326312895\n",
            "epoch 19, batch 9850\n",
            "loss = 0.5499408841133118, avg loss = 0.8039333624736912\n",
            "epoch 19, batch 9860\n",
            "loss = 0.4538705348968506, avg loss = 0.8037352529941901\n",
            "epoch 19, batch 9870\n",
            "loss = 0.37920746207237244, avg loss = 0.8034992277893976\n",
            "epoch 19, batch 9880\n",
            "loss = 0.46128523349761963, avg loss = 0.8032670940706121\n",
            "epoch 19, batch 9890\n",
            "loss = 0.7480809688568115, avg loss = 0.8031087328919988\n",
            "epoch 19, batch 9900\n",
            "loss = 0.5732073783874512, avg loss = 0.8029205333825313\n",
            "epoch 19, batch 9910\n",
            "loss = 0.3631013035774231, avg loss = 0.8027359148568269\n",
            "epoch 19, batch 9920\n",
            "loss = 0.5711616277694702, avg loss = 0.8025012212174554\n",
            "epoch 19, batch 9930\n",
            "loss = 0.8393146395683289, avg loss = 0.8023822549366639\n",
            "epoch 19, batch 9940\n",
            "loss = 0.6382702589035034, avg loss = 0.8022179807005994\n",
            "epoch 19, batch 9950\n",
            "loss = 0.6569767594337463, avg loss = 0.8020092338293641\n",
            "epoch 19, batch 9960\n",
            "loss = 0.9303685426712036, avg loss = 0.8018915126302156\n",
            "epoch 19, batch 9970\n",
            "loss = 0.8372646570205688, avg loss = 0.8017606908094919\n",
            "epoch 19, batch 9980\n",
            "loss = 0.7391926050186157, avg loss = 0.8017353049828437\n",
            "epoch 19, batch 9990\n",
            "loss = 0.5032780170440674, avg loss = 0.8016062388429651\n",
            "epoch 19, batch 10000\n",
            "loss = 0.6700743436813354, avg loss = 0.8015306585192681\n",
            "epoch 19, batch 10010\n",
            "loss = 0.3287660479545593, avg loss = 0.801345494984985\n",
            "epoch 19, batch 10020\n",
            "loss = 0.5138075351715088, avg loss = 0.8011897696825321\n",
            "epoch 19, batch 10030\n",
            "loss = 0.5862827301025391, avg loss = 0.8010171258407957\n",
            "epoch 19, batch 10040\n",
            "loss = 0.5960558652877808, avg loss = 0.8008716329190123\n",
            "epoch 19, batch 10050\n",
            "loss = 0.5064735412597656, avg loss = 0.8006699730033305\n",
            "epoch 19, batch 10060\n",
            "loss = 0.45933544635772705, avg loss = 0.8005784273532702\n",
            "epoch 19, batch 10070\n",
            "loss = 0.5085609555244446, avg loss = 0.8003808349311766\n",
            "epoch 19, batch 10080\n",
            "loss = 0.5686845779418945, avg loss = 0.8001653904864002\n",
            "epoch 19, batch 10090\n",
            "loss = 1.1836881637573242, avg loss = 0.8000532869866157\n",
            "epoch 19, batch 10100\n",
            "loss = 1.1388297080993652, avg loss = 0.7999548821136503\n",
            "epoch 19, batch 10110\n",
            "loss = 0.5439099669456482, avg loss = 0.7997635798449568\n",
            "epoch 19, batch 10120\n",
            "loss = 0.6102802157402039, avg loss = 0.799654752086745\n",
            "epoch 19, batch 10130\n",
            "loss = 0.9508199691772461, avg loss = 0.7995133654415784\n",
            "epoch 19, batch 10140\n",
            "loss = 0.6259987354278564, avg loss = 0.799329603226815\n",
            "epoch 19, batch 10150\n",
            "loss = 0.5284490585327148, avg loss = 0.7992815775677489\n",
            "epoch 19, batch 10160\n",
            "loss = 0.35749170184135437, avg loss = 0.7990531334961494\n",
            "epoch 19, batch 10170\n",
            "loss = 0.8159429430961609, avg loss = 0.7988963837673999\n",
            "epoch 19, batch 10180\n",
            "loss = 0.15365004539489746, avg loss = 0.7986788893905277\n",
            "epoch 20, batch 10190\n",
            "loss = 0.3741755485534668, avg loss = 0.7985072226794592\n",
            "epoch 20, batch 10200\n",
            "loss = 0.7329803705215454, avg loss = 0.7983843165402319\n",
            "epoch 20, batch 10210\n",
            "loss = 0.7119280099868774, avg loss = 0.7982349918474764\n",
            "epoch 20, batch 10220\n",
            "loss = 0.4034561812877655, avg loss = 0.7980124992400466\n",
            "epoch 20, batch 10230\n",
            "loss = 0.6791916489601135, avg loss = 0.7979081148684083\n",
            "epoch 20, batch 10240\n",
            "loss = 0.8815600872039795, avg loss = 0.7978088450530777\n",
            "epoch 20, batch 10250\n",
            "loss = 0.907755434513092, avg loss = 0.7978026362250491\n",
            "epoch 20, batch 10260\n",
            "loss = 0.6248345375061035, avg loss = 0.7975778076964745\n",
            "epoch 20, batch 10270\n",
            "loss = 0.7936030626296997, avg loss = 0.7974922973347035\n",
            "epoch 20, batch 10280\n",
            "loss = 0.6167123913764954, avg loss = 0.7972917201483064\n",
            "epoch 20, batch 10290\n",
            "loss = 0.5008535385131836, avg loss = 0.7972137773610413\n",
            "epoch 20, batch 10300\n",
            "loss = 0.7065707445144653, avg loss = 0.7969862219430868\n",
            "epoch 20, batch 10310\n",
            "loss = 0.576556384563446, avg loss = 0.7967211814223275\n",
            "epoch 20, batch 10320\n",
            "loss = 0.8838276863098145, avg loss = 0.7965341870535829\n",
            "epoch 20, batch 10330\n",
            "loss = 0.6287553310394287, avg loss = 0.796388123545792\n",
            "epoch 20, batch 10340\n",
            "loss = 0.6746777296066284, avg loss = 0.796225824224361\n",
            "epoch 20, batch 10350\n",
            "loss = 0.5129752159118652, avg loss = 0.7960690191935226\n",
            "epoch 20, batch 10360\n",
            "loss = 1.0201218128204346, avg loss = 0.7958853731888371\n",
            "epoch 20, batch 10370\n",
            "loss = 0.5074877738952637, avg loss = 0.7957569936690932\n",
            "epoch 20, batch 10380\n",
            "loss = 0.4995536804199219, avg loss = 0.7956425687567347\n",
            "epoch 20, batch 10390\n",
            "loss = 0.7897651195526123, avg loss = 0.795588752942893\n",
            "epoch 20, batch 10400\n",
            "loss = 0.881744384765625, avg loss = 0.7954569059409774\n",
            "epoch 20, batch 10410\n",
            "loss = 0.4165806174278259, avg loss = 0.7952283279725156\n",
            "epoch 20, batch 10420\n",
            "loss = 0.6556912660598755, avg loss = 0.7951424462066502\n",
            "epoch 20, batch 10430\n",
            "loss = 0.5213305950164795, avg loss = 0.7950347164704724\n",
            "epoch 20, batch 10440\n",
            "loss = 0.4877975285053253, avg loss = 0.7948545536062042\n",
            "epoch 20, batch 10450\n",
            "loss = 1.228590488433838, avg loss = 0.7946695778130344\n",
            "epoch 20, batch 10460\n",
            "loss = 0.37815648317337036, avg loss = 0.79449520763544\n",
            "epoch 20, batch 10470\n",
            "loss = 0.33972519636154175, avg loss = 0.7942894228179908\n",
            "epoch 20, batch 10480\n",
            "loss = 0.3422665596008301, avg loss = 0.7940718003442042\n",
            "epoch 20, batch 10490\n",
            "loss = 0.9621777534484863, avg loss = 0.7939870571783318\n",
            "epoch 20, batch 10500\n",
            "loss = 0.4780367314815521, avg loss = 0.7938083057829312\n",
            "epoch 20, batch 10510\n",
            "loss = 0.7911080718040466, avg loss = 0.7937784012814684\n",
            "epoch 20, batch 10520\n",
            "loss = 0.4342978000640869, avg loss = 0.7936189567379852\n",
            "epoch 20, batch 10530\n",
            "loss = 0.6936767101287842, avg loss = 0.7934848844778617\n",
            "epoch 20, batch 10540\n",
            "loss = 0.5859431028366089, avg loss = 0.793442704821221\n",
            "epoch 20, batch 10550\n",
            "loss = 0.6476960182189941, avg loss = 0.7932456842587458\n",
            "epoch 20, batch 10560\n",
            "loss = 0.46344369649887085, avg loss = 0.7931238780362588\n",
            "epoch 20, batch 10570\n",
            "loss = 0.45361319184303284, avg loss = 0.7930010692708991\n",
            "epoch 20, batch 10580\n",
            "loss = 0.4862043261528015, avg loss = 0.7927924501042397\n",
            "epoch 20, batch 10590\n",
            "loss = 0.5619363784790039, avg loss = 0.7926132053136825\n",
            "epoch 20, batch 10600\n",
            "loss = 0.5377940535545349, avg loss = 0.7924866938900272\n",
            "epoch 20, batch 10610\n",
            "loss = 0.44423916935920715, avg loss = 0.792275461944963\n",
            "epoch 20, batch 10620\n",
            "loss = 0.40664446353912354, avg loss = 0.7920881071038502\n",
            "epoch 20, batch 10630\n",
            "loss = 0.6476719975471497, avg loss = 0.7919264156038427\n",
            "epoch 20, batch 10640\n",
            "loss = 0.4636756181716919, avg loss = 0.7918363245456178\n",
            "epoch 20, batch 10650\n",
            "loss = 0.4373917281627655, avg loss = 0.7916428250032411\n",
            "epoch 20, batch 10660\n",
            "loss = 0.7245638966560364, avg loss = 0.7914928187055279\n",
            "epoch 20, batch 10670\n",
            "loss = 0.644355058670044, avg loss = 0.7914191496894531\n",
            "epoch 20, batch 10680\n",
            "loss = 0.6113316416740417, avg loss = 0.7913207559591711\n",
            "epoch 21, batch 10690\n",
            "loss = 0.4194474518299103, avg loss = 0.7911329536054935\n",
            "epoch 21, batch 10700\n",
            "loss = 0.4888654947280884, avg loss = 0.7909039715559126\n",
            "epoch 21, batch 10710\n",
            "loss = 0.7346747517585754, avg loss = 0.7907480431468435\n",
            "epoch 21, batch 10720\n",
            "loss = 0.7918142080307007, avg loss = 0.7904929249519621\n",
            "epoch 21, batch 10730\n",
            "loss = 0.7875730395317078, avg loss = 0.7903770252340104\n",
            "epoch 21, batch 10740\n",
            "loss = 0.7628635168075562, avg loss = 0.7902469725068832\n",
            "epoch 21, batch 10750\n",
            "loss = 0.6915805339813232, avg loss = 0.7901553814896317\n",
            "epoch 21, batch 10760\n",
            "loss = 0.4803818464279175, avg loss = 0.789944484557084\n",
            "epoch 21, batch 10770\n",
            "loss = 0.8197479248046875, avg loss = 0.7898429967137875\n",
            "epoch 21, batch 10780\n",
            "loss = 0.8590857982635498, avg loss = 0.7896345589081852\n",
            "epoch 21, batch 10790\n",
            "loss = 1.1035306453704834, avg loss = 0.7895042686204429\n",
            "epoch 21, batch 10800\n",
            "loss = 0.5902055501937866, avg loss = 0.7893873889095805\n",
            "epoch 21, batch 10810\n",
            "loss = 0.5546947717666626, avg loss = 0.7891960796096279\n",
            "epoch 21, batch 10820\n",
            "loss = 0.8503577709197998, avg loss = 0.7889883578636179\n",
            "epoch 21, batch 10830\n",
            "loss = 0.544593095779419, avg loss = 0.7887459805261066\n",
            "epoch 21, batch 10840\n",
            "loss = 0.4821706712245941, avg loss = 0.7885694983081954\n",
            "epoch 21, batch 10850\n",
            "loss = 0.589947521686554, avg loss = 0.7883949273041866\n",
            "epoch 21, batch 10860\n",
            "loss = 0.5242273807525635, avg loss = 0.788169567367923\n",
            "epoch 21, batch 10870\n",
            "loss = 0.5402286052703857, avg loss = 0.7879451261670521\n",
            "epoch 21, batch 10880\n",
            "loss = 0.9815880060195923, avg loss = 0.7878954428179628\n",
            "epoch 21, batch 10890\n",
            "loss = 0.3774939775466919, avg loss = 0.7876967964298798\n",
            "epoch 21, batch 10900\n",
            "loss = 0.6039440035820007, avg loss = 0.7874658099924206\n",
            "epoch 21, batch 10910\n",
            "loss = 0.9160100221633911, avg loss = 0.7874023224089695\n",
            "epoch 21, batch 10920\n",
            "loss = 0.4217807948589325, avg loss = 0.7872722636962876\n",
            "epoch 21, batch 10930\n",
            "loss = 0.5264260768890381, avg loss = 0.7871024827930432\n",
            "epoch 21, batch 10940\n",
            "loss = 0.8218480348587036, avg loss = 0.7870204897737045\n",
            "epoch 21, batch 10950\n",
            "loss = 0.8178669214248657, avg loss = 0.7869797659124413\n",
            "epoch 21, batch 10960\n",
            "loss = 0.61955326795578, avg loss = 0.7868767721986357\n",
            "epoch 21, batch 10970\n",
            "loss = 0.9651466608047485, avg loss = 0.7867523894990806\n",
            "epoch 21, batch 10980\n",
            "loss = 0.3970198631286621, avg loss = 0.7865741734011251\n",
            "epoch 21, batch 10990\n",
            "loss = 0.5077106952667236, avg loss = 0.7863572878076663\n",
            "epoch 21, batch 11000\n",
            "loss = 0.8454527258872986, avg loss = 0.7862050215425817\n",
            "epoch 21, batch 11010\n",
            "loss = 0.6991065740585327, avg loss = 0.7861197298935714\n",
            "epoch 21, batch 11020\n",
            "loss = 0.458030104637146, avg loss = 0.7859977025856448\n",
            "epoch 21, batch 11030\n",
            "loss = 0.7961618900299072, avg loss = 0.7858780685261716\n",
            "epoch 21, batch 11040\n",
            "loss = 0.4158252775669098, avg loss = 0.7856840741307731\n",
            "epoch 21, batch 11050\n",
            "loss = 0.5727123022079468, avg loss = 0.7855900072822204\n",
            "epoch 21, batch 11060\n",
            "loss = 0.46968504786491394, avg loss = 0.7854653109976547\n",
            "epoch 21, batch 11070\n",
            "loss = 0.4864603877067566, avg loss = 0.7853013150589145\n",
            "epoch 21, batch 11080\n",
            "loss = 0.5832809209823608, avg loss = 0.7852074652681604\n",
            "epoch 21, batch 11090\n",
            "loss = 0.6624314785003662, avg loss = 0.7851025747395615\n",
            "epoch 21, batch 11100\n",
            "loss = 1.0903339385986328, avg loss = 0.7849862824273002\n",
            "epoch 21, batch 11110\n",
            "loss = 0.45804935693740845, avg loss = 0.7847546363700413\n",
            "epoch 21, batch 11120\n",
            "loss = 0.42891812324523926, avg loss = 0.7846252232749792\n",
            "epoch 21, batch 11130\n",
            "loss = 0.7254155278205872, avg loss = 0.7845549476074402\n",
            "epoch 21, batch 11140\n",
            "loss = 0.6448695659637451, avg loss = 0.7844701950824561\n",
            "epoch 21, batch 11150\n",
            "loss = 0.471235990524292, avg loss = 0.7842440614932855\n",
            "epoch 21, batch 11160\n",
            "loss = 0.652787983417511, avg loss = 0.7840901097182625\n",
            "epoch 21, batch 11170\n",
            "loss = 0.6599514484405518, avg loss = 0.7838833025380663\n",
            "epoch 21, batch 11180\n",
            "loss = 0.5067874193191528, avg loss = 0.7836592282066938\n",
            "epoch 21, batch 11190\n",
            "loss = 0.37924349308013916, avg loss = 0.7834489582277921\n",
            "epoch 22, batch 11200\n",
            "loss = 0.5640286207199097, avg loss = 0.7833468989934772\n",
            "epoch 22, batch 11210\n",
            "loss = 0.4243634045124054, avg loss = 0.7832207276619618\n",
            "epoch 22, batch 11220\n",
            "loss = 0.4912342131137848, avg loss = 0.7830715976814854\n",
            "epoch 22, batch 11230\n",
            "loss = 0.7425923347473145, avg loss = 0.7829142782707779\n",
            "epoch 22, batch 11240\n",
            "loss = 0.5254340171813965, avg loss = 0.7827306704098538\n",
            "epoch 22, batch 11250\n",
            "loss = 0.36166515946388245, avg loss = 0.7825849822693401\n",
            "epoch 22, batch 11260\n",
            "loss = 1.034459114074707, avg loss = 0.7825253779058664\n",
            "epoch 22, batch 11270\n",
            "loss = 0.5189967155456543, avg loss = 0.7823635825895586\n",
            "epoch 22, batch 11280\n",
            "loss = 0.415452778339386, avg loss = 0.7821702917139475\n",
            "epoch 22, batch 11290\n",
            "loss = 0.366762638092041, avg loss = 0.7820403553129721\n",
            "epoch 22, batch 11300\n",
            "loss = 0.5200448036193848, avg loss = 0.7818299685207616\n",
            "epoch 22, batch 11310\n",
            "loss = 0.3943822979927063, avg loss = 0.7817070657006941\n",
            "epoch 22, batch 11320\n",
            "loss = 0.5901168584823608, avg loss = 0.7815810639384884\n",
            "epoch 22, batch 11330\n",
            "loss = 0.6544404625892639, avg loss = 0.7814472867854906\n",
            "epoch 22, batch 11340\n",
            "loss = 0.585913360118866, avg loss = 0.7812876726045705\n",
            "epoch 22, batch 11350\n",
            "loss = 0.4003620743751526, avg loss = 0.7811274991095853\n",
            "epoch 22, batch 11360\n",
            "loss = 0.6121034026145935, avg loss = 0.7809613747692759\n",
            "epoch 22, batch 11370\n",
            "loss = 0.6375714540481567, avg loss = 0.7807863390500753\n",
            "epoch 22, batch 11380\n",
            "loss = 0.5509680509567261, avg loss = 0.7806471985507828\n",
            "epoch 22, batch 11390\n",
            "loss = 0.514443576335907, avg loss = 0.780445945366262\n",
            "epoch 22, batch 11400\n",
            "loss = 0.47298964858055115, avg loss = 0.7802278166813286\n",
            "epoch 22, batch 11410\n",
            "loss = 0.7945463061332703, avg loss = 0.7801410160194773\n",
            "epoch 22, batch 11420\n",
            "loss = 1.149111270904541, avg loss = 0.7802141966536355\n",
            "epoch 22, batch 11430\n",
            "loss = 0.7385793924331665, avg loss = 0.7802173173607491\n",
            "epoch 22, batch 11440\n",
            "loss = 0.30355751514434814, avg loss = 0.7800604491813721\n",
            "epoch 22, batch 11450\n",
            "loss = 0.6868752241134644, avg loss = 0.7800319964253226\n",
            "epoch 22, batch 11460\n",
            "loss = 0.5629832744598389, avg loss = 0.7798446019009457\n",
            "epoch 22, batch 11470\n",
            "loss = 0.5523518919944763, avg loss = 0.7796981254542196\n",
            "epoch 22, batch 11480\n",
            "loss = 1.1261156797409058, avg loss = 0.7795788770937442\n",
            "epoch 22, batch 11490\n",
            "loss = 0.9212254881858826, avg loss = 0.7794440078945446\n",
            "epoch 22, batch 11500\n",
            "loss = 0.7089239358901978, avg loss = 0.7793108018157274\n",
            "epoch 22, batch 11510\n",
            "loss = 1.0466886758804321, avg loss = 0.7791347963552595\n",
            "epoch 22, batch 11520\n",
            "loss = 0.44329607486724854, avg loss = 0.7789643315171513\n",
            "epoch 22, batch 11530\n",
            "loss = 0.7988975048065186, avg loss = 0.7788441721282104\n",
            "epoch 22, batch 11540\n",
            "loss = 0.3783969581127167, avg loss = 0.7787452355969819\n",
            "epoch 22, batch 11550\n",
            "loss = 0.8431615829467773, avg loss = 0.7786064057935884\n",
            "epoch 22, batch 11560\n",
            "loss = 0.5280448794364929, avg loss = 0.7784598139085674\n",
            "epoch 22, batch 11570\n",
            "loss = 0.8942867517471313, avg loss = 0.778319066437082\n",
            "epoch 22, batch 11580\n",
            "loss = 0.5131798982620239, avg loss = 0.7782107522360504\n",
            "epoch 22, batch 11590\n",
            "loss = 0.6599385738372803, avg loss = 0.7780543534983532\n",
            "epoch 22, batch 11600\n",
            "loss = 0.9342827200889587, avg loss = 0.7779416612086111\n",
            "epoch 22, batch 11610\n",
            "loss = 0.18651758134365082, avg loss = 0.7778499096529325\n",
            "epoch 22, batch 11620\n",
            "loss = 0.5471953749656677, avg loss = 0.7776900620191725\n",
            "epoch 22, batch 11630\n",
            "loss = 0.3275004029273987, avg loss = 0.7774892369145888\n",
            "epoch 22, batch 11640\n",
            "loss = 0.568324089050293, avg loss = 0.7774112386315344\n",
            "epoch 22, batch 11650\n",
            "loss = 0.35930538177490234, avg loss = 0.7772196524439963\n",
            "epoch 22, batch 11660\n",
            "loss = 0.7211741805076599, avg loss = 0.7770650837755735\n",
            "epoch 22, batch 11670\n",
            "loss = 0.8106761574745178, avg loss = 0.7769557051532986\n",
            "epoch 22, batch 11680\n",
            "loss = 0.5222311615943909, avg loss = 0.776794070602484\n",
            "epoch 22, batch 11690\n",
            "loss = 0.5825846791267395, avg loss = 0.776689771870653\n",
            "epoch 22, batch 11700\n",
            "loss = 0.6601014137268066, avg loss = 0.7764505182601448\n",
            "epoch 23, batch 11710\n",
            "loss = 0.8209079504013062, avg loss = 0.7763428209277934\n",
            "epoch 23, batch 11720\n",
            "loss = 0.5231526494026184, avg loss = 0.7762064029688315\n",
            "epoch 23, batch 11730\n",
            "loss = 0.531891405582428, avg loss = 0.7760376232588078\n",
            "epoch 23, batch 11740\n",
            "loss = 0.4342905282974243, avg loss = 0.7758728538958746\n",
            "epoch 23, batch 11750\n",
            "loss = 0.7225171327590942, avg loss = 0.7756743374124486\n",
            "epoch 23, batch 11760\n",
            "loss = 0.5082473158836365, avg loss = 0.775542121986244\n",
            "epoch 23, batch 11770\n",
            "loss = 0.40243664383888245, avg loss = 0.7753457108264062\n",
            "epoch 23, batch 11780\n",
            "loss = 0.5122083425521851, avg loss = 0.775229100885537\n",
            "epoch 23, batch 11790\n",
            "loss = 0.48471295833587646, avg loss = 0.7750877310630121\n",
            "epoch 23, batch 11800\n",
            "loss = 0.760237991809845, avg loss = 0.7749542034733093\n",
            "epoch 23, batch 11810\n",
            "loss = 0.43885672092437744, avg loss = 0.7747771069041558\n",
            "epoch 23, batch 11820\n",
            "loss = 0.5442987680435181, avg loss = 0.7746057997601085\n",
            "epoch 23, batch 11830\n",
            "loss = 0.5399807691574097, avg loss = 0.7744244467854399\n",
            "epoch 23, batch 11840\n",
            "loss = 0.474727600812912, avg loss = 0.7743225588689785\n",
            "epoch 23, batch 11850\n",
            "loss = 0.7613248229026794, avg loss = 0.7741221149536125\n",
            "epoch 23, batch 11860\n",
            "loss = 0.8115166425704956, avg loss = 0.7739883565932864\n",
            "epoch 23, batch 11870\n",
            "loss = 0.6271714568138123, avg loss = 0.7739171049980527\n",
            "epoch 23, batch 11880\n",
            "loss = 0.3470722734928131, avg loss = 0.7737636451995132\n",
            "epoch 23, batch 11890\n",
            "loss = 0.8022321462631226, avg loss = 0.7736449616911835\n",
            "epoch 23, batch 11900\n",
            "loss = 0.5566871166229248, avg loss = 0.7735919550937764\n",
            "epoch 23, batch 11910\n",
            "loss = 0.3481096625328064, avg loss = 0.7733827795755153\n",
            "epoch 23, batch 11920\n",
            "loss = 0.6371956467628479, avg loss = 0.7732139240325298\n",
            "epoch 23, batch 11930\n",
            "loss = 1.1129066944122314, avg loss = 0.7730975990798028\n",
            "epoch 23, batch 11940\n",
            "loss = 0.5891724824905396, avg loss = 0.7729022606857857\n",
            "epoch 23, batch 11950\n",
            "loss = 0.5996375679969788, avg loss = 0.77277147421777\n",
            "epoch 23, batch 11960\n",
            "loss = 0.5516059398651123, avg loss = 0.7727256567033637\n",
            "epoch 23, batch 11970\n",
            "loss = 0.7563338279724121, avg loss = 0.7725694508929002\n",
            "epoch 23, batch 11980\n",
            "loss = 0.4673326313495636, avg loss = 0.7724905211136417\n",
            "epoch 23, batch 11990\n",
            "loss = 0.27406176924705505, avg loss = 0.772381856970433\n",
            "epoch 23, batch 12000\n",
            "loss = 0.7962302565574646, avg loss = 0.7722249135871728\n",
            "epoch 23, batch 12010\n",
            "loss = 0.6264028549194336, avg loss = 0.7720576191524184\n",
            "epoch 23, batch 12020\n",
            "loss = 0.6584873199462891, avg loss = 0.7718566386007429\n",
            "epoch 23, batch 12030\n",
            "loss = 0.5604602098464966, avg loss = 0.7716472120579342\n",
            "epoch 23, batch 12040\n",
            "loss = 0.22138549387454987, avg loss = 0.7715620753562629\n",
            "epoch 23, batch 12050\n",
            "loss = 0.7933874130249023, avg loss = 0.7714152296314101\n",
            "epoch 23, batch 12060\n",
            "loss = 0.5718627572059631, avg loss = 0.7712658790102349\n",
            "epoch 23, batch 12070\n",
            "loss = 0.8971514701843262, avg loss = 0.7712114615821107\n",
            "epoch 23, batch 12080\n",
            "loss = 0.6652436256408691, avg loss = 0.770997023645369\n",
            "epoch 23, batch 12090\n",
            "loss = 0.7944523096084595, avg loss = 0.7708510339740784\n",
            "epoch 23, batch 12100\n",
            "loss = 0.635773777961731, avg loss = 0.7707217273965847\n",
            "epoch 23, batch 12110\n",
            "loss = 0.6534261703491211, avg loss = 0.770473896486271\n",
            "epoch 23, batch 12120\n",
            "loss = 0.5731275081634521, avg loss = 0.7702955897405694\n",
            "epoch 23, batch 12130\n",
            "loss = 0.6222540140151978, avg loss = 0.7702559598803717\n",
            "epoch 23, batch 12140\n",
            "loss = 0.2830122709274292, avg loss = 0.7701946303383425\n",
            "epoch 23, batch 12150\n",
            "loss = 0.5386369228363037, avg loss = 0.7700156869944722\n",
            "epoch 23, batch 12160\n",
            "loss = 0.8964229822158813, avg loss = 0.7699349486428362\n",
            "epoch 23, batch 12170\n",
            "loss = 0.7158674001693726, avg loss = 0.769859954292351\n",
            "epoch 23, batch 12180\n",
            "loss = 0.7820642590522766, avg loss = 0.7696840881432708\n",
            "epoch 23, batch 12190\n",
            "loss = 0.4614645540714264, avg loss = 0.7695298748624139\n",
            "epoch 23, batch 12200\n",
            "loss = 0.7702913284301758, avg loss = 0.7693822538400771\n",
            "epoch 23, batch 12210\n",
            "loss = 0.5254071354866028, avg loss = 0.7692885604832721\n",
            "epoch 24, batch 12220\n",
            "loss = 0.6583021879196167, avg loss = 0.7691161989153602\n",
            "epoch 24, batch 12230\n",
            "loss = 0.4020187258720398, avg loss = 0.7689486077291402\n",
            "epoch 24, batch 12240\n",
            "loss = 0.4890235364437103, avg loss = 0.7687932910397649\n",
            "epoch 24, batch 12250\n",
            "loss = 0.6721463799476624, avg loss = 0.7685702571662105\n",
            "epoch 24, batch 12260\n",
            "loss = 0.767000675201416, avg loss = 0.7683454039714757\n",
            "epoch 24, batch 12270\n",
            "loss = 0.7147620916366577, avg loss = 0.7681473045314631\n",
            "epoch 24, batch 12280\n",
            "loss = 0.7324117422103882, avg loss = 0.7680757554169101\n",
            "epoch 24, batch 12290\n",
            "loss = 0.6584810614585876, avg loss = 0.7679338652358684\n",
            "epoch 24, batch 12300\n",
            "loss = 0.5918579697608948, avg loss = 0.7677519896396292\n",
            "epoch 24, batch 12310\n",
            "loss = 0.6822060346603394, avg loss = 0.7676003650169756\n",
            "epoch 24, batch 12320\n",
            "loss = 0.7248836755752563, avg loss = 0.7675220229929047\n",
            "epoch 24, batch 12330\n",
            "loss = 0.5968213081359863, avg loss = 0.7673662333387431\n",
            "epoch 24, batch 12340\n",
            "loss = 0.5769157409667969, avg loss = 0.7671687890381539\n",
            "epoch 24, batch 12350\n",
            "loss = 0.5260411500930786, avg loss = 0.7669732184991663\n",
            "epoch 24, batch 12360\n",
            "loss = 0.48865118622779846, avg loss = 0.7668354021319004\n",
            "epoch 24, batch 12370\n",
            "loss = 0.41868770122528076, avg loss = 0.7667237724726395\n",
            "epoch 24, batch 12380\n",
            "loss = 0.5674710869789124, avg loss = 0.7665759683269195\n",
            "epoch 24, batch 12390\n",
            "loss = 0.41539767384529114, avg loss = 0.76645232175655\n",
            "epoch 24, batch 12400\n",
            "loss = 0.431589275598526, avg loss = 0.7663301561436345\n",
            "epoch 24, batch 12410\n",
            "loss = 0.7750359177589417, avg loss = 0.7661527754365197\n",
            "epoch 24, batch 12420\n",
            "loss = 0.22577542066574097, avg loss = 0.7659459693060405\n",
            "epoch 24, batch 12430\n",
            "loss = 0.5300808548927307, avg loss = 0.7658101950479148\n",
            "epoch 24, batch 12440\n",
            "loss = 0.4644504189491272, avg loss = 0.7656084351145761\n",
            "epoch 24, batch 12450\n",
            "loss = 0.7112556099891663, avg loss = 0.7654537892413427\n",
            "epoch 24, batch 12460\n",
            "loss = 0.40787702798843384, avg loss = 0.7653195541393891\n",
            "epoch 24, batch 12470\n",
            "loss = 0.335869699716568, avg loss = 0.7651703791467304\n",
            "epoch 24, batch 12480\n",
            "loss = 0.8563381433486938, avg loss = 0.765030671367183\n",
            "epoch 24, batch 12490\n",
            "loss = 1.0068707466125488, avg loss = 0.7649022900146709\n",
            "epoch 24, batch 12500\n",
            "loss = 0.4330621361732483, avg loss = 0.7646869321095944\n",
            "epoch 24, batch 12510\n",
            "loss = 0.5507650971412659, avg loss = 0.7645277868464982\n",
            "epoch 24, batch 12520\n",
            "loss = 0.6977726221084595, avg loss = 0.7643823628025219\n",
            "epoch 24, batch 12530\n",
            "loss = 0.7444108724594116, avg loss = 0.7643737308437217\n",
            "epoch 24, batch 12540\n",
            "loss = 0.5307369828224182, avg loss = 0.7642641183089887\n",
            "epoch 24, batch 12550\n",
            "loss = 0.3256642818450928, avg loss = 0.7640405694291411\n",
            "epoch 24, batch 12560\n",
            "loss = 0.5616666078567505, avg loss = 0.7639251610430278\n",
            "epoch 24, batch 12570\n",
            "loss = 1.1775375604629517, avg loss = 0.7638730590518449\n",
            "epoch 24, batch 12580\n",
            "loss = 0.7478742599487305, avg loss = 0.7638374270892011\n",
            "epoch 24, batch 12590\n",
            "loss = 1.0134170055389404, avg loss = 0.7637838372607095\n",
            "epoch 24, batch 12600\n",
            "loss = 0.48204660415649414, avg loss = 0.7636860192259626\n",
            "epoch 24, batch 12610\n",
            "loss = 0.828410267829895, avg loss = 0.7635960824486284\n",
            "epoch 24, batch 12620\n",
            "loss = 0.3221104145050049, avg loss = 0.7634417602984256\n",
            "epoch 24, batch 12630\n",
            "loss = 0.7441033720970154, avg loss = 0.7633071547862281\n",
            "epoch 24, batch 12640\n",
            "loss = 0.5127997398376465, avg loss = 0.7631394068097483\n",
            "epoch 24, batch 12650\n",
            "loss = 0.614669680595398, avg loss = 0.763049923729284\n",
            "epoch 24, batch 12660\n",
            "loss = 0.49062401056289673, avg loss = 0.7629504039895384\n",
            "epoch 24, batch 12670\n",
            "loss = 0.48931923508644104, avg loss = 0.7628384430211363\n",
            "epoch 24, batch 12680\n",
            "loss = 0.4594469964504242, avg loss = 0.7626557598907019\n",
            "epoch 24, batch 12690\n",
            "loss = 0.6100585460662842, avg loss = 0.7624991754068456\n",
            "epoch 24, batch 12700\n",
            "loss = 0.579566240310669, avg loss = 0.7623877255266577\n",
            "epoch 24, batch 12710\n",
            "loss = 0.9055397510528564, avg loss = 0.7623061471560825\n",
            "epoch 24, batch 12720\n",
            "loss = 0.6228491067886353, avg loss = 0.7621882722824344\n",
            "epoch 25, batch 12730\n",
            "loss = 0.557862401008606, avg loss = 0.7619679778545089\n",
            "epoch 25, batch 12740\n",
            "loss = 0.7100006341934204, avg loss = 0.7618763417134199\n",
            "epoch 25, batch 12750\n",
            "loss = 0.5267446637153625, avg loss = 0.7616714492884337\n",
            "epoch 25, batch 12760\n",
            "loss = 0.5167208909988403, avg loss = 0.761564309288949\n",
            "epoch 25, batch 12770\n",
            "loss = 0.6430765390396118, avg loss = 0.761394794226953\n",
            "epoch 25, batch 12780\n",
            "loss = 0.491836279630661, avg loss = 0.7612872065874239\n",
            "epoch 25, batch 12790\n",
            "loss = 0.5615235567092896, avg loss = 0.7611953660449635\n",
            "epoch 25, batch 12800\n",
            "loss = 0.2950138449668884, avg loss = 0.7610705514636357\n",
            "epoch 25, batch 12810\n",
            "loss = 0.6007505059242249, avg loss = 0.7609776327088417\n",
            "epoch 25, batch 12820\n",
            "loss = 0.6709215641021729, avg loss = 0.7607983543969075\n",
            "epoch 25, batch 12830\n",
            "loss = 0.9695442318916321, avg loss = 0.7607443346946108\n",
            "epoch 25, batch 12840\n",
            "loss = 0.3696448802947998, avg loss = 0.7605522449966811\n",
            "epoch 25, batch 12850\n",
            "loss = 0.9315990805625916, avg loss = 0.7604875983697895\n",
            "epoch 25, batch 12860\n",
            "loss = 0.4922020435333252, avg loss = 0.7603279842640248\n",
            "epoch 25, batch 12870\n",
            "loss = 0.7685317993164062, avg loss = 0.7602414260157431\n",
            "epoch 25, batch 12880\n",
            "loss = 0.7316086292266846, avg loss = 0.7600116547532612\n",
            "epoch 25, batch 12890\n",
            "loss = 0.39131444692611694, avg loss = 0.7598954516142907\n",
            "epoch 25, batch 12900\n",
            "loss = 0.682170033454895, avg loss = 0.75979800451287\n",
            "epoch 25, batch 12910\n",
            "loss = 0.5568118095397949, avg loss = 0.7596933069534305\n",
            "epoch 25, batch 12920\n",
            "loss = 0.5520939826965332, avg loss = 0.7595292472629448\n",
            "epoch 25, batch 12930\n",
            "loss = 0.3063838481903076, avg loss = 0.7593990408131898\n",
            "epoch 25, batch 12940\n",
            "loss = 0.7118450403213501, avg loss = 0.7592736715315574\n",
            "epoch 25, batch 12950\n",
            "loss = 0.835057258605957, avg loss = 0.7591770491510285\n",
            "epoch 25, batch 12960\n",
            "loss = 0.6270628571510315, avg loss = 0.7590468875362457\n",
            "epoch 25, batch 12970\n",
            "loss = 0.6260690689086914, avg loss = 0.7588643038982874\n",
            "epoch 25, batch 12980\n",
            "loss = 0.613743782043457, avg loss = 0.7587436346810753\n",
            "epoch 25, batch 12990\n",
            "loss = 0.8463132381439209, avg loss = 0.7586036995512142\n",
            "epoch 25, batch 13000\n",
            "loss = 0.4799089729785919, avg loss = 0.7584638710812881\n",
            "epoch 25, batch 13010\n",
            "loss = 0.7146861553192139, avg loss = 0.758316770116931\n",
            "epoch 25, batch 13020\n",
            "loss = 0.6655439734458923, avg loss = 0.7581845310964435\n",
            "epoch 25, batch 13030\n",
            "loss = 0.454733669757843, avg loss = 0.7580718950535001\n",
            "epoch 25, batch 13040\n",
            "loss = 0.33449554443359375, avg loss = 0.7578916801939621\n",
            "epoch 25, batch 13050\n",
            "loss = 0.9100846648216248, avg loss = 0.7578038435318004\n",
            "epoch 25, batch 13060\n",
            "loss = 0.9682710766792297, avg loss = 0.7576589559945085\n",
            "epoch 25, batch 13070\n",
            "loss = 0.5161895751953125, avg loss = 0.7575185089676364\n",
            "epoch 25, batch 13080\n",
            "loss = 0.6733688116073608, avg loss = 0.7573457491359123\n",
            "epoch 25, batch 13090\n",
            "loss = 0.6763255000114441, avg loss = 0.7572398116005296\n",
            "epoch 25, batch 13100\n",
            "loss = 0.5973658561706543, avg loss = 0.7570632100708157\n",
            "epoch 25, batch 13110\n",
            "loss = 0.49746114015579224, avg loss = 0.7569436088954556\n",
            "epoch 25, batch 13120\n",
            "loss = 0.7431094646453857, avg loss = 0.7568355238894228\n",
            "epoch 25, batch 13130\n",
            "loss = 0.5582902431488037, avg loss = 0.7566792862397609\n",
            "epoch 25, batch 13140\n",
            "loss = 0.6574417948722839, avg loss = 0.7565634278322555\n",
            "epoch 25, batch 13150\n",
            "loss = 0.5632039904594421, avg loss = 0.7564667346280337\n",
            "epoch 25, batch 13160\n",
            "loss = 0.4745713174343109, avg loss = 0.7563175307116882\n",
            "epoch 25, batch 13170\n",
            "loss = 0.4642612338066101, avg loss = 0.7561907783648509\n",
            "epoch 25, batch 13180\n",
            "loss = 0.5314380526542664, avg loss = 0.7560431509565602\n",
            "epoch 25, batch 13190\n",
            "loss = 0.4791845381259918, avg loss = 0.7558488918907539\n",
            "epoch 25, batch 13200\n",
            "loss = 0.8186325430870056, avg loss = 0.755777697212091\n",
            "epoch 25, batch 13210\n",
            "loss = 0.5080514550209045, avg loss = 0.7556325737124677\n",
            "epoch 25, batch 13220\n",
            "loss = 0.4330012798309326, avg loss = 0.7554105535611714\n",
            "epoch 25, batch 13230\n",
            "loss = 0.672611653804779, avg loss = 0.755319143126656\n",
            "epoch 26, batch 13240\n",
            "loss = 0.665891170501709, avg loss = 0.7551958086706271\n",
            "epoch 26, batch 13250\n",
            "loss = 0.35860008001327515, avg loss = 0.755010483806988\n",
            "epoch 26, batch 13260\n",
            "loss = 0.44468241930007935, avg loss = 0.75487515920967\n",
            "epoch 26, batch 13270\n",
            "loss = 0.5181373953819275, avg loss = 0.7547022452907807\n",
            "epoch 26, batch 13280\n",
            "loss = 0.43653517961502075, avg loss = 0.754552887155708\n",
            "epoch 26, batch 13290\n",
            "loss = 0.4711177349090576, avg loss = 0.7544609883501621\n",
            "epoch 26, batch 13300\n",
            "loss = 0.8719923496246338, avg loss = 0.7544061767113837\n",
            "epoch 26, batch 13310\n",
            "loss = 0.47570276260375977, avg loss = 0.7542612097345734\n",
            "epoch 26, batch 13320\n",
            "loss = 0.43065330386161804, avg loss = 0.7541075574720765\n",
            "epoch 26, batch 13330\n",
            "loss = 0.5935028791427612, avg loss = 0.7539252544133537\n",
            "epoch 26, batch 13340\n",
            "loss = 0.7888204455375671, avg loss = 0.7539298090106366\n",
            "epoch 26, batch 13350\n",
            "loss = 0.5947450399398804, avg loss = 0.7539478980334064\n",
            "epoch 26, batch 13360\n",
            "loss = 0.6321806907653809, avg loss = 0.7538636198880787\n",
            "epoch 26, batch 13370\n",
            "loss = 0.6697603464126587, avg loss = 0.7537161650658546\n",
            "epoch 26, batch 13380\n",
            "loss = 0.6459833979606628, avg loss = 0.7535275184163777\n",
            "epoch 26, batch 13390\n",
            "loss = 0.7230328917503357, avg loss = 0.7533504465752079\n",
            "epoch 26, batch 13400\n",
            "loss = 0.6609331965446472, avg loss = 0.7532137718118393\n",
            "epoch 26, batch 13410\n",
            "loss = 0.7224582433700562, avg loss = 0.7531234786092212\n",
            "epoch 26, batch 13420\n",
            "loss = 0.3740707039833069, avg loss = 0.7529947610341579\n",
            "epoch 26, batch 13430\n",
            "loss = 0.3359016180038452, avg loss = 0.7528499611093762\n",
            "epoch 26, batch 13440\n",
            "loss = 0.5849640369415283, avg loss = 0.7527097632010866\n",
            "epoch 26, batch 13450\n",
            "loss = 0.3231235146522522, avg loss = 0.7525665747820223\n",
            "epoch 26, batch 13460\n",
            "loss = 0.6163138151168823, avg loss = 0.752451529891893\n",
            "epoch 26, batch 13470\n",
            "loss = 0.5427172183990479, avg loss = 0.7522674776718806\n",
            "epoch 26, batch 13480\n",
            "loss = 0.505996823310852, avg loss = 0.7521471302602606\n",
            "epoch 26, batch 13490\n",
            "loss = 0.5154738426208496, avg loss = 0.7519331388899005\n",
            "epoch 26, batch 13500\n",
            "loss = 0.4871857166290283, avg loss = 0.7518712468599832\n",
            "epoch 26, batch 13510\n",
            "loss = 0.6529935598373413, avg loss = 0.751731770124416\n",
            "epoch 26, batch 13520\n",
            "loss = 0.7945224046707153, avg loss = 0.7516173625386943\n",
            "epoch 26, batch 13530\n",
            "loss = 0.3837144672870636, avg loss = 0.7514213074656741\n",
            "epoch 26, batch 13540\n",
            "loss = 0.5154743194580078, avg loss = 0.7513430803452936\n",
            "epoch 26, batch 13550\n",
            "loss = 0.31524115800857544, avg loss = 0.7511590343042933\n",
            "epoch 26, batch 13560\n",
            "loss = 0.685152530670166, avg loss = 0.7509987510048446\n",
            "epoch 26, batch 13570\n",
            "loss = 0.7500517964363098, avg loss = 0.7508958165851602\n",
            "epoch 26, batch 13580\n",
            "loss = 0.4679371118545532, avg loss = 0.75080910168248\n",
            "epoch 26, batch 13590\n",
            "loss = 0.9142001867294312, avg loss = 0.7507236359190028\n",
            "epoch 26, batch 13600\n",
            "loss = 0.8152828216552734, avg loss = 0.7506136753092355\n",
            "epoch 26, batch 13610\n",
            "loss = 0.6945836544036865, avg loss = 0.7504530563950539\n",
            "epoch 26, batch 13620\n",
            "loss = 0.8106181621551514, avg loss = 0.750388942705946\n",
            "epoch 26, batch 13630\n",
            "loss = 0.6604875922203064, avg loss = 0.7503411227401267\n",
            "epoch 26, batch 13640\n",
            "loss = 0.4232345223426819, avg loss = 0.7502133539312483\n",
            "epoch 26, batch 13650\n",
            "loss = 0.5507405996322632, avg loss = 0.7500986631591241\n",
            "epoch 26, batch 13660\n",
            "loss = 0.6128866672515869, avg loss = 0.7499459030633004\n",
            "epoch 26, batch 13670\n",
            "loss = 0.4777703583240509, avg loss = 0.7498840833689143\n",
            "epoch 26, batch 13680\n",
            "loss = 0.5548616647720337, avg loss = 0.749778958350115\n",
            "epoch 26, batch 13690\n",
            "loss = 0.5715125799179077, avg loss = 0.7496825386532647\n",
            "epoch 26, batch 13700\n",
            "loss = 0.5183402299880981, avg loss = 0.7495082092883378\n",
            "epoch 26, batch 13710\n",
            "loss = 0.3887612819671631, avg loss = 0.74936385412424\n",
            "epoch 26, batch 13720\n",
            "loss = 0.40108874440193176, avg loss = 0.7491579122787053\n",
            "epoch 26, batch 13730\n",
            "loss = 0.6826736927032471, avg loss = 0.7490481478134299\n",
            "epoch 26, batch 13740\n",
            "loss = 0.33737432956695557, avg loss = 0.7488971874692641\n",
            "epoch 27, batch 13750\n",
            "loss = 0.7169537544250488, avg loss = 0.7487469928969036\n",
            "epoch 27, batch 13760\n",
            "loss = 0.4199572205543518, avg loss = 0.7486102732548187\n",
            "epoch 27, batch 13770\n",
            "loss = 1.0010871887207031, avg loss = 0.7484775422488595\n",
            "epoch 27, batch 13780\n",
            "loss = 0.39229995012283325, avg loss = 0.7483706584819343\n",
            "epoch 27, batch 13790\n",
            "loss = 0.4034765362739563, avg loss = 0.7481620947289415\n",
            "epoch 27, batch 13800\n",
            "loss = 0.5726767778396606, avg loss = 0.7480680289648581\n",
            "epoch 27, batch 13810\n",
            "loss = 1.2856636047363281, avg loss = 0.7479827160230156\n",
            "epoch 27, batch 13820\n",
            "loss = 0.597499668598175, avg loss = 0.7478501960850832\n",
            "epoch 27, batch 13830\n",
            "loss = 0.4112800359725952, avg loss = 0.7476583577169944\n",
            "epoch 27, batch 13840\n",
            "loss = 0.3689644932746887, avg loss = 0.7475197519697895\n",
            "epoch 27, batch 13850\n",
            "loss = 0.60406494140625, avg loss = 0.747421417806553\n",
            "epoch 27, batch 13860\n",
            "loss = 0.4651697874069214, avg loss = 0.7472965905547658\n",
            "epoch 27, batch 13870\n",
            "loss = 0.6331923007965088, avg loss = 0.7471700718420912\n",
            "epoch 27, batch 13880\n",
            "loss = 0.756679356098175, avg loss = 0.7469924826958682\n",
            "epoch 27, batch 13890\n",
            "loss = 0.5703135132789612, avg loss = 0.7468308967811071\n",
            "epoch 27, batch 13900\n",
            "loss = 0.5640910267829895, avg loss = 0.7466765541803065\n",
            "epoch 27, batch 13910\n",
            "loss = 0.5891980528831482, avg loss = 0.7465900245221033\n",
            "epoch 27, batch 13920\n",
            "loss = 0.4527251720428467, avg loss = 0.7464367002634139\n",
            "epoch 27, batch 13930\n",
            "loss = 1.0845296382904053, avg loss = 0.7463659934704884\n",
            "epoch 27, batch 13940\n",
            "loss = 0.4250679016113281, avg loss = 0.7461954905920083\n",
            "epoch 27, batch 13950\n",
            "loss = 0.7596601843833923, avg loss = 0.7460347978765391\n",
            "epoch 27, batch 13960\n",
            "loss = 0.5686743259429932, avg loss = 0.7459092118934779\n",
            "epoch 27, batch 13970\n",
            "loss = 0.5132853984832764, avg loss = 0.7458161994036215\n",
            "epoch 27, batch 13980\n",
            "loss = 0.4027783274650574, avg loss = 0.7456552101754835\n",
            "epoch 27, batch 13990\n",
            "loss = 0.5585918426513672, avg loss = 0.7455228760316596\n",
            "epoch 27, batch 14000\n",
            "loss = 0.46554693579673767, avg loss = 0.7453477308260543\n",
            "epoch 27, batch 14010\n",
            "loss = 0.51297527551651, avg loss = 0.7452011586490654\n",
            "epoch 27, batch 14020\n",
            "loss = 0.3324028551578522, avg loss = 0.7450511392243153\n",
            "epoch 27, batch 14030\n",
            "loss = 0.6029350757598877, avg loss = 0.7449032375781517\n",
            "epoch 27, batch 14040\n",
            "loss = 0.9387104511260986, avg loss = 0.744855084428378\n",
            "epoch 27, batch 14050\n",
            "loss = 0.5632148385047913, avg loss = 0.7447547004984367\n",
            "epoch 27, batch 14060\n",
            "loss = 0.5029870271682739, avg loss = 0.7446381067388173\n",
            "epoch 27, batch 14070\n",
            "loss = 0.7952889204025269, avg loss = 0.7445759125832302\n",
            "epoch 27, batch 14080\n",
            "loss = 0.6685093641281128, avg loss = 0.7444111214516769\n",
            "epoch 27, batch 14090\n",
            "loss = 0.339720755815506, avg loss = 0.7442666792600945\n",
            "epoch 27, batch 14100\n",
            "loss = 0.4053979516029358, avg loss = 0.7441078974158628\n",
            "epoch 27, batch 14110\n",
            "loss = 0.6761425733566284, avg loss = 0.7440739807055657\n",
            "epoch 27, batch 14120\n",
            "loss = 0.7767326235771179, avg loss = 0.7439997556474239\n",
            "epoch 27, batch 14130\n",
            "loss = 0.6162989139556885, avg loss = 0.7438737932906366\n",
            "epoch 27, batch 14140\n",
            "loss = 0.45385733246803284, avg loss = 0.7437659872187331\n",
            "epoch 27, batch 14150\n",
            "loss = 0.6839743852615356, avg loss = 0.7436740851096888\n",
            "epoch 27, batch 14160\n",
            "loss = 0.5039330720901489, avg loss = 0.7435092496385767\n",
            "epoch 27, batch 14170\n",
            "loss = 0.4547586441040039, avg loss = 0.7434412782818562\n",
            "epoch 27, batch 14180\n",
            "loss = 0.45054060220718384, avg loss = 0.7433952392986615\n",
            "epoch 27, batch 14190\n",
            "loss = 0.5318410396575928, avg loss = 0.7432601994269746\n",
            "epoch 27, batch 14200\n",
            "loss = 0.5052406787872314, avg loss = 0.7430889044733534\n",
            "epoch 27, batch 14210\n",
            "loss = 0.4232024550437927, avg loss = 0.7429746243303129\n",
            "epoch 27, batch 14220\n",
            "loss = 0.4241558015346527, avg loss = 0.7428741075391927\n",
            "epoch 27, batch 14230\n",
            "loss = 0.7184392213821411, avg loss = 0.7427439407938312\n",
            "epoch 27, batch 14240\n",
            "loss = 0.4035881757736206, avg loss = 0.7425917493671262\n",
            "epoch 27, batch 14250\n",
            "loss = 0.468005895614624, avg loss = 0.7424009403743242\n",
            "epoch 28, batch 14260\n",
            "loss = 0.7297437191009521, avg loss = 0.7422702737413817\n",
            "epoch 28, batch 14270\n",
            "loss = 0.7361787557601929, avg loss = 0.7421282789635341\n",
            "epoch 28, batch 14280\n",
            "loss = 0.4896005392074585, avg loss = 0.7419848929036732\n",
            "epoch 28, batch 14290\n",
            "loss = 0.7632542252540588, avg loss = 0.7418711851471533\n",
            "epoch 28, batch 14300\n",
            "loss = 0.48401373624801636, avg loss = 0.7416911737172753\n",
            "epoch 28, batch 14310\n",
            "loss = 0.5570840239524841, avg loss = 0.7414982280453796\n",
            "epoch 28, batch 14320\n",
            "loss = 0.7248030304908752, avg loss = 0.741375443576601\n",
            "epoch 28, batch 14330\n",
            "loss = 0.5992321968078613, avg loss = 0.7412005528048544\n",
            "epoch 28, batch 14340\n",
            "loss = 0.5503964424133301, avg loss = 0.7410696162672056\n",
            "epoch 28, batch 14350\n",
            "loss = 0.45894020795822144, avg loss = 0.7409032430112985\n",
            "epoch 28, batch 14360\n",
            "loss = 0.4264855980873108, avg loss = 0.7407231606501556\n",
            "epoch 28, batch 14370\n",
            "loss = 0.35449299216270447, avg loss = 0.740551692633141\n",
            "epoch 28, batch 14380\n",
            "loss = 0.5993254780769348, avg loss = 0.7404140237744726\n",
            "epoch 28, batch 14390\n",
            "loss = 0.24972490966320038, avg loss = 0.7402640499252259\n",
            "epoch 28, batch 14400\n",
            "loss = 0.5743104815483093, avg loss = 0.7401611592134254\n",
            "epoch 28, batch 14410\n",
            "loss = 0.8591253757476807, avg loss = 0.7400435122586968\n",
            "epoch 28, batch 14420\n",
            "loss = 0.3850247263908386, avg loss = 0.7398328767704484\n",
            "epoch 28, batch 14430\n",
            "loss = 0.5052606463432312, avg loss = 0.739676274617389\n",
            "epoch 28, batch 14440\n",
            "loss = 0.492059588432312, avg loss = 0.7395416801955313\n",
            "epoch 28, batch 14450\n",
            "loss = 0.5977436304092407, avg loss = 0.7394086527917212\n",
            "epoch 28, batch 14460\n",
            "loss = 0.5988394021987915, avg loss = 0.739298912620025\n",
            "epoch 28, batch 14470\n",
            "loss = 1.184768795967102, avg loss = 0.7391423959884877\n",
            "epoch 28, batch 14480\n",
            "loss = 0.5414575338363647, avg loss = 0.7390422417262559\n",
            "epoch 28, batch 14490\n",
            "loss = 0.407565176486969, avg loss = 0.7389119616586888\n",
            "epoch 28, batch 14500\n",
            "loss = 0.38234490156173706, avg loss = 0.738780995004136\n",
            "epoch 28, batch 14510\n",
            "loss = 0.3688858449459076, avg loss = 0.7386646932965307\n",
            "epoch 28, batch 14520\n",
            "loss = 0.36721089482307434, avg loss = 0.7385484876998857\n",
            "epoch 28, batch 14530\n",
            "loss = 0.5393146276473999, avg loss = 0.7384527417026712\n",
            "epoch 28, batch 14540\n",
            "loss = 0.5240817070007324, avg loss = 0.7383334870956213\n",
            "epoch 28, batch 14550\n",
            "loss = 0.7143595814704895, avg loss = 0.7382217306420975\n",
            "epoch 28, batch 14560\n",
            "loss = 0.4415546655654907, avg loss = 0.7380564989389053\n",
            "epoch 28, batch 14570\n",
            "loss = 0.5409903526306152, avg loss = 0.7378868213901392\n",
            "epoch 28, batch 14580\n",
            "loss = 0.8045833110809326, avg loss = 0.7377646626012888\n",
            "epoch 28, batch 14590\n",
            "loss = 0.462294340133667, avg loss = 0.73766525124568\n",
            "epoch 28, batch 14600\n",
            "loss = 0.6652734875679016, avg loss = 0.7375463170639864\n",
            "epoch 28, batch 14610\n",
            "loss = 0.3724675178527832, avg loss = 0.7373496149711867\n",
            "epoch 28, batch 14620\n",
            "loss = 1.0165055990219116, avg loss = 0.7373236518113705\n",
            "epoch 28, batch 14630\n",
            "loss = 0.4926367998123169, avg loss = 0.737204817319397\n",
            "epoch 28, batch 14640\n",
            "loss = 0.5933386087417603, avg loss = 0.7371975220057889\n",
            "epoch 28, batch 14650\n",
            "loss = 0.4003564119338989, avg loss = 0.7370473452242975\n",
            "epoch 28, batch 14660\n",
            "loss = 0.22520652413368225, avg loss = 0.7368955617518981\n",
            "epoch 28, batch 14670\n",
            "loss = 0.3876471221446991, avg loss = 0.7367912155789994\n",
            "epoch 28, batch 14680\n",
            "loss = 0.41823992133140564, avg loss = 0.7366800262519141\n",
            "epoch 28, batch 14690\n",
            "loss = 0.567206621170044, avg loss = 0.7365886499000862\n",
            "epoch 28, batch 14700\n",
            "loss = 1.070054292678833, avg loss = 0.7364363359735937\n",
            "epoch 28, batch 14710\n",
            "loss = 0.6091007590293884, avg loss = 0.7362998548107517\n",
            "epoch 28, batch 14720\n",
            "loss = 0.4989980161190033, avg loss = 0.7361828164359474\n",
            "epoch 28, batch 14730\n",
            "loss = 0.7459989786148071, avg loss = 0.7360828250747753\n",
            "epoch 28, batch 14740\n",
            "loss = 0.8521885871887207, avg loss = 0.736026631142019\n",
            "epoch 28, batch 14750\n",
            "loss = 0.6230989694595337, avg loss = 0.735902057391102\n",
            "epoch 28, batch 14760\n",
            "loss = 0.6123462319374084, avg loss = 0.7357717878409841\n",
            "epoch 29, batch 14770\n",
            "loss = 0.43514204025268555, avg loss = 0.735657313829269\n",
            "epoch 29, batch 14780\n",
            "loss = 0.41019946336746216, avg loss = 0.7354883784148464\n",
            "epoch 29, batch 14790\n",
            "loss = 0.9599500894546509, avg loss = 0.7353514220482438\n",
            "epoch 29, batch 14800\n",
            "loss = 0.49745917320251465, avg loss = 0.7351715854394275\n",
            "epoch 29, batch 14810\n",
            "loss = 0.4513865113258362, avg loss = 0.7350815630196559\n",
            "epoch 29, batch 14820\n",
            "loss = 1.109832525253296, avg loss = 0.735026226545635\n",
            "epoch 29, batch 14830\n",
            "loss = 0.3750905990600586, avg loss = 0.7348256674153694\n",
            "epoch 29, batch 14840\n",
            "loss = 0.4931105077266693, avg loss = 0.7346795675668595\n",
            "epoch 29, batch 14850\n",
            "loss = 0.4113631248474121, avg loss = 0.7344824563152461\n",
            "epoch 29, batch 14860\n",
            "loss = 0.4421066641807556, avg loss = 0.7343797998104249\n",
            "epoch 29, batch 14870\n",
            "loss = 0.4323531985282898, avg loss = 0.7343223694634261\n",
            "epoch 29, batch 14880\n",
            "loss = 0.6705169677734375, avg loss = 0.7342550218205458\n",
            "epoch 29, batch 14890\n",
            "loss = 0.7356771230697632, avg loss = 0.7342341030000279\n",
            "epoch 29, batch 14900\n",
            "loss = 0.5287310481071472, avg loss = 0.7341186091803864\n",
            "epoch 29, batch 14910\n",
            "loss = 0.5805169939994812, avg loss = 0.7339688515928989\n",
            "epoch 29, batch 14920\n",
            "loss = 0.4108295142650604, avg loss = 0.7338586911009799\n",
            "epoch 29, batch 14930\n",
            "loss = 0.22338421642780304, avg loss = 0.7337590888871176\n",
            "epoch 29, batch 14940\n",
            "loss = 0.5131905674934387, avg loss = 0.7336870071658966\n",
            "epoch 29, batch 14950\n",
            "loss = 0.43082523345947266, avg loss = 0.7335538843024934\n",
            "epoch 29, batch 14960\n",
            "loss = 0.5201894044876099, avg loss = 0.7334329439855036\n",
            "epoch 29, batch 14970\n",
            "loss = 0.35174989700317383, avg loss = 0.7332494550672626\n",
            "epoch 29, batch 14980\n",
            "loss = 0.503219723701477, avg loss = 0.7331413718186647\n",
            "epoch 29, batch 14990\n",
            "loss = 0.36577901244163513, avg loss = 0.732976240116489\n",
            "epoch 29, batch 15000\n",
            "loss = 0.5839554071426392, avg loss = 0.7328857634067535\n",
            "epoch 29, batch 15010\n",
            "loss = 0.45950913429260254, avg loss = 0.7328049810130465\n",
            "epoch 29, batch 15020\n",
            "loss = 0.5636103749275208, avg loss = 0.7326950598374188\n",
            "epoch 29, batch 15030\n",
            "loss = 0.7675440311431885, avg loss = 0.732528460773324\n",
            "epoch 29, batch 15040\n",
            "loss = 0.4305706322193146, avg loss = 0.7324324459035663\n",
            "epoch 29, batch 15050\n",
            "loss = 0.9072628021240234, avg loss = 0.7323121160387597\n",
            "epoch 29, batch 15060\n",
            "loss = 0.49250534176826477, avg loss = 0.7321102560813209\n",
            "epoch 29, batch 15070\n",
            "loss = 0.55723637342453, avg loss = 0.7319734132598391\n",
            "epoch 29, batch 15080\n",
            "loss = 0.48936235904693604, avg loss = 0.7318908676702717\n",
            "epoch 29, batch 15090\n",
            "loss = 0.4787369966506958, avg loss = 0.7318379736760343\n",
            "epoch 29, batch 15100\n",
            "loss = 0.42699742317199707, avg loss = 0.7316585280504447\n",
            "epoch 29, batch 15110\n",
            "loss = 0.7316024899482727, avg loss = 0.7315504380995512\n",
            "epoch 29, batch 15120\n",
            "loss = 0.3935319185256958, avg loss = 0.7313981492959317\n",
            "epoch 29, batch 15130\n",
            "loss = 0.6512066125869751, avg loss = 0.7313134138444679\n",
            "epoch 29, batch 15140\n",
            "loss = 0.4495461583137512, avg loss = 0.7311829261885294\n",
            "epoch 29, batch 15150\n",
            "loss = 0.6488144397735596, avg loss = 0.7310580214808876\n",
            "epoch 29, batch 15160\n",
            "loss = 0.5466264486312866, avg loss = 0.7310014960319197\n",
            "epoch 29, batch 15170\n",
            "loss = 0.44913727045059204, avg loss = 0.7308624669978236\n",
            "epoch 29, batch 15180\n",
            "loss = 0.3518139123916626, avg loss = 0.7306991621635962\n",
            "epoch 29, batch 15190\n",
            "loss = 0.20428350567817688, avg loss = 0.7305625368628241\n",
            "epoch 29, batch 15200\n",
            "loss = 0.6019123196601868, avg loss = 0.7304339031992775\n",
            "epoch 29, batch 15210\n",
            "loss = 0.3258920907974243, avg loss = 0.7302657997956956\n",
            "epoch 29, batch 15220\n",
            "loss = 0.3825260400772095, avg loss = 0.7301197606184167\n",
            "epoch 29, batch 15230\n",
            "loss = 0.29829126596450806, avg loss = 0.7299821150377246\n",
            "epoch 29, batch 15240\n",
            "loss = 0.6033859252929688, avg loss = 0.729859793499073\n",
            "epoch 29, batch 15250\n",
            "loss = 0.4544171988964081, avg loss = 0.7296938307109426\n",
            "epoch 29, batch 15260\n",
            "loss = 0.4744766056537628, avg loss = 0.7295506063443493\n",
            "epoch 29, batch 15270\n",
            "loss = 0.464729368686676, avg loss = 0.7294388074030186\n",
            "epoch 30, batch 15280\n",
            "loss = 0.2586955428123474, avg loss = 0.7293137057620973\n",
            "epoch 30, batch 15290\n",
            "loss = 0.5456352829933167, avg loss = 0.7292057881739655\n",
            "epoch 30, batch 15300\n",
            "loss = 0.5183714032173157, avg loss = 0.7290552334828314\n",
            "epoch 30, batch 15310\n",
            "loss = 0.5608456134796143, avg loss = 0.7289019644046282\n",
            "epoch 30, batch 15320\n",
            "loss = 0.595683217048645, avg loss = 0.7287254160129059\n",
            "epoch 30, batch 15330\n",
            "loss = 0.6299757361412048, avg loss = 0.7285878460895603\n",
            "epoch 30, batch 15340\n",
            "loss = 0.5847840309143066, avg loss = 0.7284710767138579\n",
            "epoch 30, batch 15350\n",
            "loss = 0.28651732206344604, avg loss = 0.7283732542424715\n",
            "epoch 30, batch 15360\n",
            "loss = 0.3762240409851074, avg loss = 0.7282672995041746\n",
            "epoch 30, batch 15370\n",
            "loss = 0.577709436416626, avg loss = 0.7281180981330927\n",
            "epoch 30, batch 15380\n",
            "loss = 0.4241723120212555, avg loss = 0.7279647560516477\n",
            "epoch 30, batch 15390\n",
            "loss = 0.6060926914215088, avg loss = 0.727827364611037\n",
            "epoch 30, batch 15400\n",
            "loss = 0.5080952048301697, avg loss = 0.727705995798498\n",
            "epoch 30, batch 15410\n",
            "loss = 0.2697802782058716, avg loss = 0.7275817424871177\n",
            "epoch 30, batch 15420\n",
            "loss = 0.5127540826797485, avg loss = 0.727549841800939\n",
            "epoch 30, batch 15430\n",
            "loss = 0.6389716863632202, avg loss = 0.727466435978649\n",
            "epoch 30, batch 15440\n",
            "loss = 0.5777857303619385, avg loss = 0.7273709329279439\n",
            "epoch 30, batch 15450\n",
            "loss = 0.37878918647766113, avg loss = 0.7272265024883462\n",
            "epoch 30, batch 15460\n",
            "loss = 0.48664945363998413, avg loss = 0.7271135369660321\n",
            "epoch 30, batch 15470\n",
            "loss = 0.6490188837051392, avg loss = 0.7269298515900844\n",
            "epoch 30, batch 15480\n",
            "loss = 0.27667689323425293, avg loss = 0.7267494037208323\n",
            "epoch 30, batch 15490\n",
            "loss = 0.5028560757637024, avg loss = 0.7266182831308778\n",
            "epoch 30, batch 15500\n",
            "loss = 0.419117271900177, avg loss = 0.7264576328166069\n",
            "epoch 30, batch 15510\n",
            "loss = 0.692513644695282, avg loss = 0.7263090724611881\n",
            "epoch 30, batch 15520\n",
            "loss = 0.8257601261138916, avg loss = 0.726209266949445\n",
            "epoch 30, batch 15530\n",
            "loss = 0.44000881910324097, avg loss = 0.726136425804378\n",
            "epoch 30, batch 15540\n",
            "loss = 0.5646754503250122, avg loss = 0.7260423506462667\n",
            "epoch 30, batch 15550\n",
            "loss = 0.480680912733078, avg loss = 0.7258869156816381\n",
            "epoch 30, batch 15560\n",
            "loss = 0.3696124851703644, avg loss = 0.7257270359067883\n",
            "epoch 30, batch 15570\n",
            "loss = 0.40779542922973633, avg loss = 0.7255321379159992\n",
            "epoch 30, batch 15580\n",
            "loss = 0.6775689125061035, avg loss = 0.725381901801895\n",
            "epoch 30, batch 15590\n",
            "loss = 0.5716636776924133, avg loss = 0.7252474871438386\n",
            "epoch 30, batch 15600\n",
            "loss = 0.44394466280937195, avg loss = 0.7250937606270115\n",
            "epoch 30, batch 15610\n",
            "loss = 0.35105812549591064, avg loss = 0.7250063749315416\n",
            "epoch 30, batch 15620\n",
            "loss = 0.4952389597892761, avg loss = 0.7248583319788935\n",
            "epoch 30, batch 15630\n",
            "loss = 0.3268836736679077, avg loss = 0.7247547540263114\n",
            "epoch 30, batch 15640\n",
            "loss = 0.5840790271759033, avg loss = 0.7247160318076534\n",
            "epoch 30, batch 15650\n",
            "loss = 0.45781463384628296, avg loss = 0.7246289762454673\n",
            "epoch 30, batch 15660\n",
            "loss = 0.44762879610061646, avg loss = 0.7245026707487469\n",
            "epoch 30, batch 15670\n",
            "loss = 0.6050929427146912, avg loss = 0.7244583593701662\n",
            "epoch 30, batch 15680\n",
            "loss = 1.0399398803710938, avg loss = 0.7243743227861289\n",
            "epoch 30, batch 15690\n",
            "loss = 0.5205920934677124, avg loss = 0.7242301490986477\n",
            "epoch 30, batch 15700\n",
            "loss = 0.3229893743991852, avg loss = 0.7241200721159482\n",
            "epoch 30, batch 15710\n",
            "loss = 0.3877324163913727, avg loss = 0.7239814307917689\n",
            "epoch 30, batch 15720\n",
            "loss = 0.5427275896072388, avg loss = 0.7238542843647965\n",
            "epoch 30, batch 15730\n",
            "loss = 0.413322389125824, avg loss = 0.7237580631475349\n",
            "epoch 30, batch 15740\n",
            "loss = 0.6640874147415161, avg loss = 0.7236811923244175\n",
            "epoch 30, batch 15750\n",
            "loss = 0.38425412774086, avg loss = 0.7235631626948478\n",
            "epoch 30, batch 15760\n",
            "loss = 0.3895818293094635, avg loss = 0.7234512205949516\n",
            "epoch 30, batch 15770\n",
            "loss = 0.3525383174419403, avg loss = 0.723291000060515\n",
            "epoch 31, batch 15780\n",
            "loss = 0.746077299118042, avg loss = 0.7231940529966687\n",
            "epoch 31, batch 15790\n",
            "loss = 0.6032984852790833, avg loss = 0.7230649045104086\n",
            "epoch 31, batch 15800\n",
            "loss = 0.5473324656486511, avg loss = 0.7229542943571188\n",
            "epoch 31, batch 15810\n",
            "loss = 0.6509228944778442, avg loss = 0.7228893535262343\n",
            "epoch 31, batch 15820\n",
            "loss = 0.29507705569267273, avg loss = 0.7226761517836683\n",
            "epoch 31, batch 15830\n",
            "loss = 0.5603502988815308, avg loss = 0.7225422288429413\n",
            "epoch 31, batch 15840\n",
            "loss = 0.5089742541313171, avg loss = 0.7224355785119714\n",
            "epoch 31, batch 15850\n",
            "loss = 0.32767152786254883, avg loss = 0.7222584598447999\n",
            "epoch 31, batch 15860\n",
            "loss = 0.6769686341285706, avg loss = 0.7221228717893249\n",
            "epoch 31, batch 15870\n",
            "loss = 0.6819809675216675, avg loss = 0.7219682019915157\n",
            "epoch 31, batch 15880\n",
            "loss = 0.4840400218963623, avg loss = 0.7218861118822314\n",
            "epoch 31, batch 15890\n",
            "loss = 0.4087335467338562, avg loss = 0.7217462292401726\n",
            "epoch 31, batch 15900\n",
            "loss = 1.2243274450302124, avg loss = 0.7216675421286304\n",
            "epoch 31, batch 15910\n",
            "loss = 0.9391524791717529, avg loss = 0.7216418612132576\n",
            "epoch 31, batch 15920\n",
            "loss = 0.4481504261493683, avg loss = 0.721457110840509\n",
            "epoch 31, batch 15930\n",
            "loss = 0.5209846496582031, avg loss = 0.7213455683159439\n",
            "epoch 31, batch 15940\n",
            "loss = 0.5228175520896912, avg loss = 0.7211864989134045\n",
            "epoch 31, batch 15950\n",
            "loss = 0.6218308210372925, avg loss = 0.7210898625037887\n",
            "epoch 31, batch 15960\n",
            "loss = 0.5848739743232727, avg loss = 0.7209064165611091\n",
            "epoch 31, batch 15970\n",
            "loss = 0.3047547936439514, avg loss = 0.7207628755380604\n",
            "epoch 31, batch 15980\n",
            "loss = 0.31484025716781616, avg loss = 0.7206565669708616\n",
            "epoch 31, batch 15990\n",
            "loss = 0.4228220283985138, avg loss = 0.7204916747772672\n",
            "epoch 31, batch 16000\n",
            "loss = 0.5215592384338379, avg loss = 0.7203778670728207\n",
            "epoch 31, batch 16010\n",
            "loss = 0.7377986311912537, avg loss = 0.720316826085386\n",
            "epoch 31, batch 16020\n",
            "loss = 0.6819993257522583, avg loss = 0.7201935943239339\n",
            "epoch 31, batch 16030\n",
            "loss = 0.5697669982910156, avg loss = 0.7200790774353727\n",
            "epoch 31, batch 16040\n",
            "loss = 0.44955724477767944, avg loss = 0.7199714563025204\n",
            "epoch 31, batch 16050\n",
            "loss = 0.37239426374435425, avg loss = 0.7198375903873058\n",
            "epoch 31, batch 16060\n",
            "loss = 0.5675934553146362, avg loss = 0.7197337023255092\n",
            "epoch 31, batch 16070\n",
            "loss = 0.8413859605789185, avg loss = 0.7196924596468558\n",
            "epoch 31, batch 16080\n",
            "loss = 0.23703017830848694, avg loss = 0.7195241680563386\n",
            "epoch 31, batch 16090\n",
            "loss = 0.39678600430488586, avg loss = 0.7194363416037699\n",
            "epoch 31, batch 16100\n",
            "loss = 0.6546807289123535, avg loss = 0.7193291035535173\n",
            "epoch 31, batch 16110\n",
            "loss = 0.3538787066936493, avg loss = 0.7191331213745991\n",
            "epoch 31, batch 16120\n",
            "loss = 0.6014564633369446, avg loss = 0.7189905021533777\n",
            "epoch 31, batch 16130\n",
            "loss = 0.5477726459503174, avg loss = 0.7188671386397114\n",
            "epoch 31, batch 16140\n",
            "loss = 0.5378714799880981, avg loss = 0.7187554772144652\n",
            "epoch 31, batch 16150\n",
            "loss = 0.6611666679382324, avg loss = 0.718663323837168\n",
            "epoch 31, batch 16160\n",
            "loss = 0.32037681341171265, avg loss = 0.7185274116289202\n",
            "epoch 31, batch 16170\n",
            "loss = 0.6160082817077637, avg loss = 0.7184139830743964\n",
            "epoch 31, batch 16180\n",
            "loss = 0.36741405725479126, avg loss = 0.7183154885108008\n",
            "epoch 31, batch 16190\n",
            "loss = 0.9020035266876221, avg loss = 0.7181992268842117\n",
            "epoch 31, batch 16200\n",
            "loss = 0.6629273891448975, avg loss = 0.7180724157558547\n",
            "epoch 31, batch 16210\n",
            "loss = 0.38553452491760254, avg loss = 0.717947296422253\n",
            "epoch 31, batch 16220\n",
            "loss = 0.3195764124393463, avg loss = 0.7178017410172928\n",
            "epoch 31, batch 16230\n",
            "loss = 0.5571165084838867, avg loss = 0.7177069404704733\n",
            "epoch 31, batch 16240\n",
            "loss = 0.41241899132728577, avg loss = 0.7175963265335031\n",
            "epoch 31, batch 16250\n",
            "loss = 0.6352770328521729, avg loss = 0.7174432887609188\n",
            "epoch 31, batch 16260\n",
            "loss = 0.3813078701496124, avg loss = 0.7172703315887651\n",
            "epoch 31, batch 16270\n",
            "loss = 0.6707563400268555, avg loss = 0.7171877247300262\n",
            "epoch 31, batch 16280\n",
            "loss = 0.515903115272522, avg loss = 0.7170913525676259\n",
            "epoch 32, batch 16290\n",
            "loss = 0.41948020458221436, avg loss = 0.7170108594544612\n",
            "epoch 32, batch 16300\n",
            "loss = 0.5331013202667236, avg loss = 0.7168468511762794\n",
            "epoch 32, batch 16310\n",
            "loss = 0.4320967197418213, avg loss = 0.7167324619798263\n",
            "epoch 32, batch 16320\n",
            "loss = 0.3838719129562378, avg loss = 0.7165917815768398\n",
            "epoch 32, batch 16330\n",
            "loss = 0.5596287846565247, avg loss = 0.7164233153299254\n",
            "epoch 32, batch 16340\n",
            "loss = 0.5619682669639587, avg loss = 0.7163245575135457\n",
            "epoch 32, batch 16350\n",
            "loss = 0.5093591213226318, avg loss = 0.7162354838775203\n",
            "epoch 32, batch 16360\n",
            "loss = 0.2956218719482422, avg loss = 0.7160965644096395\n",
            "epoch 32, batch 16370\n",
            "loss = 0.5280522108078003, avg loss = 0.7159392355498047\n",
            "epoch 32, batch 16380\n",
            "loss = 0.6182419061660767, avg loss = 0.7158344316331531\n",
            "epoch 32, batch 16390\n",
            "loss = 0.556718111038208, avg loss = 0.7156637666182157\n",
            "epoch 32, batch 16400\n",
            "loss = 0.2789984941482544, avg loss = 0.7154971561553638\n",
            "epoch 32, batch 16410\n",
            "loss = 0.4521346092224121, avg loss = 0.715385931605867\n",
            "epoch 32, batch 16420\n",
            "loss = 0.6322950720787048, avg loss = 0.7152349922937612\n",
            "epoch 32, batch 16430\n",
            "loss = 0.39272889494895935, avg loss = 0.7150425323256253\n",
            "epoch 32, batch 16440\n",
            "loss = 0.6817184686660767, avg loss = 0.7149126905657877\n",
            "epoch 32, batch 16450\n",
            "loss = 0.5230613350868225, avg loss = 0.7147404188289106\n",
            "epoch 32, batch 16460\n",
            "loss = 0.3746457099914551, avg loss = 0.7146453578455118\n",
            "epoch 32, batch 16470\n",
            "loss = 0.3563827574253082, avg loss = 0.7145040729956765\n",
            "epoch 32, batch 16480\n",
            "loss = 0.3333030641078949, avg loss = 0.7143264267114398\n",
            "epoch 32, batch 16490\n",
            "loss = 0.617624044418335, avg loss = 0.7142007169658809\n",
            "epoch 32, batch 16500\n",
            "loss = 0.3441333770751953, avg loss = 0.7140477936791652\n",
            "epoch 32, batch 16510\n",
            "loss = 0.6576170921325684, avg loss = 0.7139134750347799\n",
            "epoch 32, batch 16520\n",
            "loss = 0.4099017083644867, avg loss = 0.7138080499624296\n",
            "epoch 32, batch 16530\n",
            "loss = 0.5482251644134521, avg loss = 0.7136538384983703\n",
            "epoch 32, batch 16540\n",
            "loss = 0.6539264917373657, avg loss = 0.7135316630300617\n",
            "epoch 32, batch 16550\n",
            "loss = 0.295830100774765, avg loss = 0.713429997846079\n",
            "epoch 32, batch 16560\n",
            "loss = 0.6267566680908203, avg loss = 0.7133141422860216\n",
            "epoch 32, batch 16570\n",
            "loss = 0.4065800905227661, avg loss = 0.7132097579759147\n",
            "epoch 32, batch 16580\n",
            "loss = 0.5220478773117065, avg loss = 0.713143301667113\n",
            "epoch 32, batch 16590\n",
            "loss = 0.35109442472457886, avg loss = 0.7130370367293691\n",
            "epoch 32, batch 16600\n",
            "loss = 0.7047188878059387, avg loss = 0.7129140727248896\n",
            "epoch 32, batch 16610\n",
            "loss = 0.45025360584259033, avg loss = 0.7127411511999738\n",
            "epoch 32, batch 16620\n",
            "loss = 0.5360891222953796, avg loss = 0.7126077432467834\n",
            "epoch 32, batch 16630\n",
            "loss = 0.7639293074607849, avg loss = 0.7124766670834997\n",
            "epoch 32, batch 16640\n",
            "loss = 0.3992995619773865, avg loss = 0.7123251546810094\n",
            "epoch 32, batch 16650\n",
            "loss = 0.4512156844139099, avg loss = 0.7121754192151465\n",
            "epoch 32, batch 16660\n",
            "loss = 0.40885984897613525, avg loss = 0.7120309217431608\n",
            "epoch 32, batch 16670\n",
            "loss = 0.5621636509895325, avg loss = 0.7119644441385432\n",
            "epoch 32, batch 16680\n",
            "loss = 0.3864748775959015, avg loss = 0.7118151909325549\n",
            "epoch 32, batch 16690\n",
            "loss = 0.5494509935379028, avg loss = 0.7117182414347073\n",
            "epoch 32, batch 16700\n",
            "loss = 0.48211532831192017, avg loss = 0.7115992385818216\n",
            "epoch 32, batch 16710\n",
            "loss = 0.537064790725708, avg loss = 0.7115360204230733\n",
            "epoch 32, batch 16720\n",
            "loss = 0.3471837043762207, avg loss = 0.711431480319413\n",
            "epoch 32, batch 16730\n",
            "loss = 0.3617277145385742, avg loss = 0.7113475035165714\n",
            "epoch 32, batch 16740\n",
            "loss = 0.8787212371826172, avg loss = 0.7112930620078046\n",
            "epoch 32, batch 16750\n",
            "loss = 0.4102879762649536, avg loss = 0.7111713070593663\n",
            "epoch 32, batch 16760\n",
            "loss = 0.3652191758155823, avg loss = 0.7110083908936218\n",
            "epoch 32, batch 16770\n",
            "loss = 0.6169074773788452, avg loss = 0.7109705262752466\n",
            "epoch 32, batch 16780\n",
            "loss = 0.3648865222930908, avg loss = 0.710868907876144\n",
            "epoch 32, batch 16790\n",
            "loss = 0.723848819732666, avg loss = 0.7107740639956882\n",
            "epoch 33, batch 16800\n",
            "loss = 0.373781681060791, avg loss = 0.7106434840176786\n",
            "epoch 33, batch 16810\n",
            "loss = 0.47077417373657227, avg loss = 0.7105206724010288\n",
            "epoch 33, batch 16820\n",
            "loss = 0.5506004095077515, avg loss = 0.7103811657970924\n",
            "epoch 33, batch 16830\n",
            "loss = 0.393889844417572, avg loss = 0.7102199582740514\n",
            "epoch 33, batch 16840\n",
            "loss = 0.4085983633995056, avg loss = 0.7101212088062899\n",
            "epoch 33, batch 16850\n",
            "loss = 0.5179465413093567, avg loss = 0.7100026573731567\n",
            "epoch 33, batch 16860\n",
            "loss = 0.4215916693210602, avg loss = 0.7098404318571515\n",
            "epoch 33, batch 16870\n",
            "loss = 0.4239937365055084, avg loss = 0.7097023536961815\n",
            "epoch 33, batch 16880\n",
            "loss = 0.4648374617099762, avg loss = 0.7095812557785997\n",
            "epoch 33, batch 16890\n",
            "loss = 0.573087751865387, avg loss = 0.7094141843634431\n",
            "epoch 33, batch 16900\n",
            "loss = 0.6344579458236694, avg loss = 0.7092865187229489\n",
            "epoch 33, batch 16910\n",
            "loss = 0.5611896514892578, avg loss = 0.7092070167530647\n",
            "epoch 33, batch 16920\n",
            "loss = 0.4392986595630646, avg loss = 0.7091032480587632\n",
            "epoch 33, batch 16930\n",
            "loss = 0.40432244539260864, avg loss = 0.7089639545560799\n",
            "epoch 33, batch 16940\n",
            "loss = 0.3432427644729614, avg loss = 0.7088139410230739\n",
            "epoch 33, batch 16950\n",
            "loss = 0.3649587035179138, avg loss = 0.708739460015719\n",
            "epoch 33, batch 16960\n",
            "loss = 0.4202030897140503, avg loss = 0.7086112865492842\n",
            "epoch 33, batch 16970\n",
            "loss = 0.48343122005462646, avg loss = 0.7084487369640757\n",
            "epoch 33, batch 16980\n",
            "loss = 0.6571685075759888, avg loss = 0.7082957266637939\n",
            "epoch 33, batch 16990\n",
            "loss = 0.5560224056243896, avg loss = 0.708179512951499\n",
            "epoch 33, batch 17000\n",
            "loss = 0.9668782949447632, avg loss = 0.7080845527631395\n",
            "epoch 33, batch 17010\n",
            "loss = 0.573101282119751, avg loss = 0.7079656760528605\n",
            "epoch 33, batch 17020\n",
            "loss = 0.5268102288246155, avg loss = 0.7078643781685661\n",
            "epoch 33, batch 17030\n",
            "loss = 0.5211617350578308, avg loss = 0.70774001790822\n",
            "epoch 33, batch 17040\n",
            "loss = 0.37803396582603455, avg loss = 0.7075690035861283\n",
            "epoch 33, batch 17050\n",
            "loss = 0.3819921612739563, avg loss = 0.7074334058768589\n",
            "epoch 33, batch 17060\n",
            "loss = 0.5522845983505249, avg loss = 0.7073349224567274\n",
            "epoch 33, batch 17070\n",
            "loss = 0.4743238687515259, avg loss = 0.7072396472838446\n",
            "epoch 33, batch 17080\n",
            "loss = 0.27028828859329224, avg loss = 0.7070616665992022\n",
            "epoch 33, batch 17090\n",
            "loss = 0.2899268865585327, avg loss = 0.7069155131535896\n",
            "epoch 33, batch 17100\n",
            "loss = 0.5231610536575317, avg loss = 0.7067946166915503\n",
            "epoch 33, batch 17110\n",
            "loss = 0.3045925498008728, avg loss = 0.706657583702384\n",
            "epoch 33, batch 17120\n",
            "loss = 0.44995784759521484, avg loss = 0.7064900108674002\n",
            "epoch 33, batch 17130\n",
            "loss = 0.5551897287368774, avg loss = 0.7063840599416364\n",
            "epoch 33, batch 17140\n",
            "loss = 0.4011808931827545, avg loss = 0.7062078463433087\n",
            "epoch 33, batch 17150\n",
            "loss = 0.35065972805023193, avg loss = 0.7060888527746451\n",
            "epoch 33, batch 17160\n",
            "loss = 0.3764452338218689, avg loss = 0.7059466192286054\n",
            "epoch 33, batch 17170\n",
            "loss = 0.4542894661426544, avg loss = 0.7058276697151454\n",
            "epoch 33, batch 17180\n",
            "loss = 0.34938281774520874, avg loss = 0.70573098206756\n",
            "epoch 33, batch 17190\n",
            "loss = 0.5588381886482239, avg loss = 0.7056089667541611\n",
            "epoch 33, batch 17200\n",
            "loss = 0.538392186164856, avg loss = 0.7054650885386522\n",
            "epoch 33, batch 17210\n",
            "loss = 0.6383947730064392, avg loss = 0.7053437433621691\n",
            "epoch 33, batch 17220\n",
            "loss = 0.7810758352279663, avg loss = 0.7052135212375035\n",
            "epoch 33, batch 17230\n",
            "loss = 0.4761252701282501, avg loss = 0.7050817761010233\n",
            "epoch 33, batch 17240\n",
            "loss = 0.4306176006793976, avg loss = 0.7049538956380291\n",
            "epoch 33, batch 17250\n",
            "loss = 0.28864943981170654, avg loss = 0.7048272560817608\n",
            "epoch 33, batch 17260\n",
            "loss = 0.8116549849510193, avg loss = 0.7047317681624743\n",
            "epoch 33, batch 17270\n",
            "loss = 0.6609051823616028, avg loss = 0.7046124508875122\n",
            "epoch 33, batch 17280\n",
            "loss = 0.5992411375045776, avg loss = 0.7044964371818221\n",
            "epoch 33, batch 17290\n",
            "loss = 0.8179529309272766, avg loss = 0.7044418191534029\n",
            "epoch 33, batch 17300\n",
            "loss = 0.38896235823631287, avg loss = 0.7043873336204903\n",
            "epoch 34, batch 17310\n",
            "loss = 0.4379553198814392, avg loss = 0.7042983882934079\n",
            "epoch 34, batch 17320\n",
            "loss = 0.5190023183822632, avg loss = 0.7041999361652012\n",
            "epoch 34, batch 17330\n",
            "loss = 0.9672718644142151, avg loss = 0.7040617368775712\n",
            "epoch 34, batch 17340\n",
            "loss = 0.48837918043136597, avg loss = 0.7039519895396636\n",
            "epoch 34, batch 17350\n",
            "loss = 0.4560023546218872, avg loss = 0.703791525328709\n",
            "epoch 34, batch 17360\n",
            "loss = 0.7416213154792786, avg loss = 0.7036839382207957\n",
            "epoch 34, batch 17370\n",
            "loss = 0.4785080850124359, avg loss = 0.7036379969241843\n",
            "epoch 34, batch 17380\n",
            "loss = 0.4706460237503052, avg loss = 0.7035460131686563\n",
            "epoch 34, batch 17390\n",
            "loss = 0.5990842580795288, avg loss = 0.7034328414601728\n",
            "epoch 34, batch 17400\n",
            "loss = 0.5355731844902039, avg loss = 0.7033505412790625\n",
            "epoch 34, batch 17410\n",
            "loss = 0.4708120822906494, avg loss = 0.7032562730377053\n",
            "epoch 34, batch 17420\n",
            "loss = 0.7303102612495422, avg loss = 0.7031652107518316\n",
            "epoch 34, batch 17430\n",
            "loss = 0.3807007074356079, avg loss = 0.7030557862700434\n",
            "epoch 34, batch 17440\n",
            "loss = 0.3782157301902771, avg loss = 0.7028819566652383\n",
            "epoch 34, batch 17450\n",
            "loss = 0.7563323974609375, avg loss = 0.702780230263072\n",
            "epoch 34, batch 17460\n",
            "loss = 0.32030606269836426, avg loss = 0.7026429510036353\n",
            "epoch 34, batch 17470\n",
            "loss = 0.25753331184387207, avg loss = 0.702504022912462\n",
            "epoch 34, batch 17480\n",
            "loss = 0.5092005133628845, avg loss = 0.7023292027098431\n",
            "epoch 34, batch 17490\n",
            "loss = 0.5735228657722473, avg loss = 0.7021917305286098\n",
            "epoch 34, batch 17500\n",
            "loss = 0.2549394965171814, avg loss = 0.7020634820810386\n",
            "epoch 34, batch 17510\n",
            "loss = 0.6141153573989868, avg loss = 0.7019393470263835\n",
            "epoch 34, batch 17520\n",
            "loss = 0.6520682573318481, avg loss = 0.701825501486557\n",
            "epoch 34, batch 17530\n",
            "loss = 0.5214219093322754, avg loss = 0.7016889375606334\n",
            "epoch 34, batch 17540\n",
            "loss = 0.5325911045074463, avg loss = 0.7016076515599694\n",
            "epoch 34, batch 17550\n",
            "loss = 0.32002466917037964, avg loss = 0.7015007762878369\n",
            "epoch 34, batch 17560\n",
            "loss = 0.2506214678287506, avg loss = 0.7013265231272082\n",
            "epoch 34, batch 17570\n",
            "loss = 0.2652592658996582, avg loss = 0.7012040798424589\n",
            "epoch 34, batch 17580\n",
            "loss = 0.26083433628082275, avg loss = 0.70110350908951\n",
            "epoch 34, batch 17590\n",
            "loss = 0.3519483804702759, avg loss = 0.7009829042241138\n",
            "epoch 34, batch 17600\n",
            "loss = 0.5271042585372925, avg loss = 0.7008743433722041\n",
            "epoch 34, batch 17610\n",
            "loss = 0.6559870839118958, avg loss = 0.7008069612656989\n",
            "epoch 34, batch 17620\n",
            "loss = 0.3108792304992676, avg loss = 0.7006612794116461\n",
            "epoch 34, batch 17630\n",
            "loss = 0.572679877281189, avg loss = 0.700517239282568\n",
            "epoch 34, batch 17640\n",
            "loss = 0.3350057005882263, avg loss = 0.7003769438173157\n",
            "epoch 34, batch 17650\n",
            "loss = 0.30158132314682007, avg loss = 0.7001992201678476\n",
            "epoch 34, batch 17660\n",
            "loss = 0.9135625958442688, avg loss = 0.7001064926968088\n",
            "epoch 34, batch 17670\n",
            "loss = 0.7116727828979492, avg loss = 0.7000104994990087\n",
            "epoch 34, batch 17680\n",
            "loss = 0.45561689138412476, avg loss = 0.6998377591835091\n",
            "epoch 34, batch 17690\n",
            "loss = 0.4038921296596527, avg loss = 0.6997068902516581\n",
            "epoch 34, batch 17700\n",
            "loss = 0.3557516634464264, avg loss = 0.6995598922585701\n",
            "epoch 34, batch 17710\n",
            "loss = 0.40019690990448, avg loss = 0.6994575129608391\n",
            "epoch 34, batch 17720\n",
            "loss = 0.7860751152038574, avg loss = 0.6993368134247329\n",
            "epoch 34, batch 17730\n",
            "loss = 0.6196756362915039, avg loss = 0.699221608132645\n",
            "epoch 34, batch 17740\n",
            "loss = 0.6993491053581238, avg loss = 0.6990791871824554\n",
            "epoch 34, batch 17750\n",
            "loss = 0.33946603536605835, avg loss = 0.6989137425640939\n",
            "epoch 34, batch 17760\n",
            "loss = 1.1542848348617554, avg loss = 0.6988527428006401\n",
            "epoch 34, batch 17770\n",
            "loss = 0.7699583172798157, avg loss = 0.6987707245044649\n",
            "epoch 34, batch 17780\n",
            "loss = 0.4076637029647827, avg loss = 0.6986865416537924\n",
            "epoch 34, batch 17790\n",
            "loss = 0.2855517864227295, avg loss = 0.6985772319862587\n",
            "epoch 34, batch 17800\n",
            "loss = 0.3543890118598938, avg loss = 0.6984808609023523\n",
            "epoch 34, batch 17810\n",
            "loss = 0.2893100380897522, avg loss = 0.6983818142183841\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiModal(409, 256, nhead=8, nlayer=6)\n",
        "model.to(device)\n",
        "#criterion = nn.L1Loss()\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "MAX_EPOCH = 35\n",
        "\n",
        "batch_num = 0\n",
        "running_loss = 0\n",
        "model.train()\n",
        "for epoch in range(MAX_EPOCH):\n",
        "  for data_batch in train_loader:\n",
        "    batch_num += 1\n",
        "    text = data_batch['text'].to(device)\n",
        "    audio = data_batch['audio'].to(device)\n",
        "    vision = data_batch['vision'].to(device)\n",
        "    label = data_batch['label'].to(device)\n",
        "\n",
        "    '''\n",
        "    print(data_batch['text'].shape)\n",
        "    print(data_batch['audio'].shape)\n",
        "    print(data_batch['vision'].shape)\n",
        "    print(data_batch['label'].shape)\n",
        "    print(pred.shape)\n",
        "    '''\n",
        "\n",
        "    pred = model(text, audio, vision)\n",
        "    pred = pred.squeeze()\n",
        "    label = label.squeeze()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = criterion(pred, label)\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if batch_num % 10 == 0:\n",
        "      print(f\"epoch {epoch}, batch {batch_num}\")\n",
        "      print(f\"loss = {loss}, avg loss = {running_loss / batch_num}\")\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiWXRaNWl_i0",
        "outputId": "58488411-8efa-4742-fdf0-7a35fc668e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc_2 = 0.7576601671309192, acc_7 = 0.48582129481005887, MAE = 0.6630311481337725, f1 = 0.7540810070951669, corr=0.55597135224185\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error\n",
        "\n",
        "model.eval()\n",
        "total_sample = 0\n",
        "acc_2 = 0\n",
        "acc_7 = 0\n",
        "all_pred = np.array([])\n",
        "all_label = np.array([])\n",
        "with torch.no_grad():\n",
        "  for valid_batch in valid_loader:\n",
        "    text = valid_batch['text'].to(device)\n",
        "    audio = valid_batch['audio'].to(device)\n",
        "    vision = valid_batch['vision'].to(device)\n",
        "    label = valid_batch['label'].to(device)\n",
        "    #print(f\"text {text.shape}\")\n",
        "\n",
        "    pred = model(text, audio, vision).squeeze()\n",
        "\n",
        "    label = label.squeeze()\n",
        "\n",
        "    all_pred = np.append(all_pred, pred.cpu().detach().numpy())\n",
        "    all_label = np.append(all_label, label.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "mae = np.mean(np.abs(all_pred - all_label))\n",
        "binary_pred = all_pred[all_label != 0] > 0\n",
        "binary_label = all_label[all_label != 0] > 0\n",
        "f1 = f1_score(binary_pred , binary_label, average=\"weighted\")\n",
        "corr = np.corrcoef(all_pred, all_label)[0,1]\n",
        "pred_7 = np.clip(all_pred, a_min=-3, a_max=3)\n",
        "label_7 = np.clip(all_label, a_min=-3, a_max=3)\n",
        "print(f\"acc_2 = {np.mean(binary_pred == binary_label)}, acc_7 = {np.mean(np.round(pred_7) == np.round(label_7))}, MAE = {mae}, f1 = {f1}, corr={corr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2Kv0-kBzXpkV"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_dim, dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.input_dim = in_dim\n",
        "    self.dim = dim\n",
        "\n",
        "    ,\n",
        "\n",
        "    self.transformer = nn.Sequential(\n",
        "      nn.Linear(in_dim, dim),\n",
        "      nn.TransformerEncoder(\n",
        "          nn.TransformerEncoderLayer(d_model=dim, nhead=8, batch_first=True),\n",
        "          num_layers=4,\n",
        "      ),\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "      nn.Linear(dim, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    transformer_out = self.transformer(x)\n",
        "    seq_mean = transformer_out.permute(1, 0, 2).mean(dim=0) # from b, s, d to s, b, d\n",
        "\n",
        "    out = self.fc(seq_mean)\n",
        "    return out\n",
        "\n",
        "class LateFusion(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LateFusion, self).__init__()\n",
        "\n",
        "    dim = 512\n",
        "    self.textEncoder = Encoder(300, dim)\n",
        "    self.audioEncoder = Encoder(74, dim)\n",
        "    self.visionEncoder = Encoder(35, dim)\n",
        "\n",
        "    self.fc = nn.Linear(3, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    text = x['text']\n",
        "    audio = x['audio']\n",
        "    vision = x['vision']\n",
        "\n",
        "    text[torch.isinf(text)] = 0.0\n",
        "    audio[torch.isinf(audio)] = 0.0\n",
        "    vision[torch.isinf(vision)] = 0.0\n",
        "\n",
        "    text_out = self.textEncoder(text)\n",
        "    audio_out = self.audioEncoder(audio)\n",
        "    vision_out = self.visionEncoder(vision)\n",
        "\n",
        "    all = torch.cat((text_out, audio_out, vision_out), dim=1)\n",
        "\n",
        "    pred = self.fc(all)\n",
        "    print(pred.squeeze())\n",
        "    return pred\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}